[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prácticas de Estadística con R",
    "section": "",
    "text": "Prefacio\n¡Bienvenido a Prácticas de Estadística con R!\nEste libro presenta una recopilación de prácticas de Estadística Descriptiva e Inferencial con el lenguaje de programación R, con problemas aplicados a las Ciencias y las Ingenierías.\nNo es un libro para aprender a programar con R, ya que solo enseña el uso del lenguaje y de algunos de sus paquetes para resolver problemas de Estadística. Para quienes estén interesados en aprender a programar en este lenguaje, os recomiendo leer este manual de R.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#capítulos",
    "href": "index.html#capítulos",
    "title": "Prácticas de Estadística con R",
    "section": "Capítulos",
    "text": "Capítulos\n\n\n\n\n\n\n\nDistribuciones de frecuencias y representaciones gráficas\n\n\n\n\n\n\n\n\n\n\nDistribuciones de probabilidad\n\n\n\n\n\n\n\n\n\n\nEstadística Descriptiva\n\n\n\n\n\n\n\n\n\n\nIntervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n\n\n\n\n\n\n\n\n\n\nIntervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n\n\n\n\n\n\n\n\n\n\nIntervalos de confianza para medias y proporciones de una población\n\n\n\n\n\n\n\n\n\n\nIntroducción a R\n\n\n\n\n\n\n\n\n\n\nPreprocesamiento de datos\n\n\n\n\n\n\n\n\n\n\nRegresión\n\n\n\n\n\n\n\nNo hay resultados",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Prácticas de Estadística con R",
    "section": "Licencia",
    "text": "Licencia\nEsta obra está bajo una licencia Reconocimiento – No comercial – Compartir bajo la misma licencia 3.0 España de Creative Commons. Para ver una copia de esta licencia, visite https://creativecommons.org/licenses/by-nc-sa/3.0/es/.\nCon esta licencia eres libre de:\n\nCopiar, distribuir y mostrar este trabajo.\nRealizar modificaciones de este trabajo.\n\nBajo las siguientes condiciones:\n\nReconocimiento. Debe reconocer los créditos de la obra de la manera especificada por el autor o el licenciador (pero no de una manera que sugiera que tiene su apoyo o apoyan el uso que hace de su obra).\nNo comercial. No puede utilizar esta obra para fines comerciales.\nCompartir bajo la misma licencia. Si altera o transforma esta obra, o genera una obra derivada, sólo puede distribuir la obra generada bajo una licencia idéntica a ésta.\n\nAl reutilizar o distribuir la obra, tiene que dejar bien claro los términos de la licencia de esta obra.\nEstas condiciones pueden no aplicarse si se obtiene el permiso del titular de los derechos de autor.\nNada en esta licencia menoscaba o restringe los derechos morales del autor.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "\n1  Introducción a R\n",
    "section": "",
    "text": "1.1 Instalación de R\nR puede descargarse desde el sitio web oficial de R o desde el repositorio principal de paquetes de R CRAN. Basta con descargar el archivo de instalación correspondiente al sistema operativo de nuestro ordenador y realizar la instalación como cualquier otro programa.\nEl intérprete de R se arranca desde la terminal, aunque en Windows incorpora su propia aplicación, pero es muy básica. En general, para trabajos serios, conviene utilizar un entorno de desarrollo para R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "01-intro.html#entornos-de-desarrollo",
    "href": "01-intro.html#entornos-de-desarrollo",
    "title": "\n1  Introducción a R\n",
    "section": "\n1.2 Entornos de desarrollo",
    "text": "1.2 Entornos de desarrollo\nPor defecto el entorno de trabajo de R es en línea de comandos, lo que significa que los cálculos y los análisis se realizan mediante comandos o instrucciones que el usuario teclea en una ventana de texto. No obstante, existen distintas interfaces gráficas de usuario que facilitan su uso, sobre todo para usuarios noveles. Algunas de ellas, como las que se enumeran a continuación, son completos entornos de desarrollo que facilitan la gestión de cualquier proyecto:\n\nRStudio. Probablemente el entorno de desarrollo más extendido para programar con R ya que incorpora multitud de utilidades para facilitar la programación con R.\nRKWard. Es otra otro de los entornos de desarrollo más completos que además incluye a posibilidad de añadir nuevos menús y cuadros de diálogo personalizados.\nVisual Studio Code. Es un entorno de desarrollo de propósito general ampliamente extendido. Aunque no es un entorno de desarrollo específico para R, incluye una extensión con utilidades que facilitan mucho el desarrollo con R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "02-preprocesamiento-datos.html",
    "href": "02-preprocesamiento-datos.html",
    "title": "\n2  Preprocesamiento de datos\n",
    "section": "",
    "text": "2.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los paquetes readr y dplyr de la colección de paquetes tidyverse.\nlibrary(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preprocesamiento de datos</span>"
    ]
  },
  {
    "objectID": "02-preprocesamiento-datos.html#ejercicios-resueltos",
    "href": "02-preprocesamiento-datos.html#ejercicios-resueltos",
    "title": "\n2  Preprocesamiento de datos\n",
    "section": "",
    "text": "Ejercicio 2.1 La siguiente tabla contiene los ingresos y gastos de una empresa durante el primer trimestre del año.\n\n\n\n\nMes\nIngresos\nGastos\nImpuestos\n\n\n\nEnero\n45000\n33400\n6450\n\n\nFebrero\n41500\n35400\n6300\n\n\nMarzo\n51200\n35600\n7100\n\n\n\n\n\n\n\nCrear un data frame con los datos de la tabla.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(\n    Mes = c(\"Enero\", \"Febrero\", \"Marzo\"),\n    Ingresos = c(45000, 41500, 51200),\n    Gastos = c(33400, 35400, 35600)\n    )\ndf \n\n      Mes Ingresos Gastos\n1   Enero    45000  33400\n2 Febrero    41500  35400\n3   Marzo    51200  35600\n\n\n\n\n\n\n\nAñadir una nueva columna con los siguientes impuestos pagados.\n\n\n\n\nMes\nImpuestos\n\n\n\nEnero\n6450\n\n\nFebrero\n6300\n\n\nMarzo\n7100\n\n\n\n\n\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf$Impuestos &lt;- c(6450, 6300, 7100)\ndf\n\n      Mes Ingresos Gastos Impuestos\n1   Enero    45000  33400      6450\n2 Febrero    41500  35400      6300\n3   Marzo    51200  35600      7100\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon las funciones del paquete dplyr.\n\ndf &lt;- df |&gt;\n    mutate(Impuestos = c(6450, 6300, 7100))\ndf\n\n      Mes Ingresos Gastos Impuestos\n1   Enero    45000  33400      6450\n2 Febrero    41500  35400      6300\n3   Marzo    51200  35600      7100\n\n\n\n\n\n\n\nAñadir una nueva fila con los siguientes datos de Abril.\n\n\n\n\nMes\nIngresos\nGastos\nImpuestos\n\n\nAbril\n49700\n36300\n6850\n\n\n\n\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf &lt;- rbind(df, list(Mes = \"Abril\", Ingresos = 49700, Gastos = 36300, Impuestos = 6850))\ndf\n\n      Mes Ingresos Gastos Impuestos\n1   Enero    45000  33400      6450\n2 Febrero    41500  35400      6300\n3   Marzo    51200  35600      7100\n4   Abril    49700  36300      6850\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon las funciones del paquete dplyr.\n\ndf &lt;- df |&gt;\n    add_row(Mes = \"Abril\", Ingresos = 49700, Gastos = 36300, Impuestos = 6850)\ndf\n\n      Mes Ingresos Gastos Impuestos\n1   Enero    45000  33400      6450\n2 Febrero    41500  35400      6300\n3   Marzo    51200  35600      7100\n4   Abril    49700  36300      6850\n\n\n\n\n\n\n\nCambiar los ingresos de Marzo por 50400.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf[3, \"Ingresos\"] &lt;- 50400\ndf\n\n      Mes Ingresos Gastos Impuestos\n1   Enero    45000  33400      6450\n2 Febrero    41500  35400      6300\n3   Marzo    50400  35600      7100\n4   Abril    49700  36300      6850\n\n\n\n\n\n\n\nCrear una nueva columna con los beneficios de cada mes (ingresos - gastos - impuestos).\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf$Beneficios &lt;- df$Ingresos - df$Gastos - df$Impuestos\ndf\n\n      Mes Ingresos Gastos Impuestos Beneficios\n1   Enero    45000  33400      6450       5150\n2 Febrero    41500  35400      6300       -200\n3   Marzo    50400  35600      7100       7700\n4   Abril    49700  36300      6850       6550\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon las funciones del paquete dplyr.\n\ndf &lt;- df |&gt;\n    mutate(Beneficios = Ingresos - Gastos - Impuestos)\ndf\n\n      Mes Ingresos Gastos Impuestos Beneficios\n1   Enero    45000  33400      6450       5150\n2 Febrero    41500  35400      6300       -200\n3   Marzo    50400  35600      7100       7700\n4   Abril    49700  36300      6850       6550\n\n\n\n\n\n\n\nCrear una nueva columna con el factor Balance con dos posibles categorías: positivo si ha habido beneficios y negativo si ha habido pérdidas.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf$Balance &lt;- cut(df$Beneficios, breaks = c(-Inf, 0, Inf), labels = c(\"negativo\", \"positivo\"))\ndf\n\n      Mes Ingresos Gastos Impuestos Beneficios  Balance\n1   Enero    45000  33400      6450       5150 positivo\n2 Febrero    41500  35400      6300       -200 negativo\n3   Marzo    50400  35600      7100       7700 positivo\n4   Abril    49700  36300      6850       6550 positivo\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon las funciones del paquete dplyr.\n\ndf &lt;- df |&gt;\n    mutate(Balance = cut(Beneficios, breaks = c(-Inf, 0, Inf), labels = c(\"negativo\", \"positivo\")))\ndf\n\n      Mes Ingresos Gastos Impuestos Beneficios  Balance\n1   Enero    45000  33400      6450       5150 positivo\n2 Febrero    41500  35400      6300       -200 negativo\n3   Marzo    50400  35600      7100       7700 positivo\n4   Abril    49700  36300      6850       6550 positivo\n\n\n\n\n\n\n\nFiltrar el conjunto de datos para quedarse con los nombres de los meses y los beneficios de los meses con balance positivo.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf[df$Balance == \"positivo\", c(\"Mes\", \"Beneficios\")]\n\n    Mes Beneficios\n1 Enero       5150\n3 Marzo       7700\n4 Abril       6550\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon las funciones del paquete dplyr.\n\ndf |&gt;\n    filter(Balance == \"positivo\") |&gt; \n    select(Mes, Beneficios)\n\n    Mes Beneficios\n1 Enero       5150\n2 Marzo       7700\n3 Abril       6550\n\n\n\n\n\n\n\n\n\nEjercicio 2.2 El fichero colesterol.csv contiene información de una muestra de pacientes donde se han medido la edad, el sexo, el peso, la altura y el nivel de colesterol, además de su nombre.\n\n\nCrear un data frame con los datos de todos los pacientes del estudio a partir del fichero colesterol.csv.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf &lt;- read.csv(\"https://raw.githubusercontent.com/asalber/estadistica-practicas-r/main/datos/colesterol.csv\")\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon la función read_csv del paquete del paquete readr.\n\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/asalber/estadistica-practicas-r/main/datos/colesterol.csv\")\n\nRows: 14 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): nombre, sexo\ndbl (4): edad, peso, altura, colesterol\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\nMostrar el contenido del data frame.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nCon las funciones básicas de R.\n\ndf \n\n# A tibble: 14 × 6\n   nombre                           edad sexo   peso altura colesterol\n   &lt;chr&gt;                           &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 José Luis Martínez Izquierdo       18 H        85   1.79        182\n 2 Rosa Díaz Díaz                     32 M        65   1.73        232\n 3 Javier García Sánchez              24 H        NA   1.81        191\n 4 Carmen López Pinzón                35 M        65   1.7         200\n 5 Marisa López Collado               46 M        51   1.58        148\n 6 Antonio Ruiz Cruz                  68 H        66   1.74        249\n 7 Antonio Fernández Ocaña            51 H        62   1.72        276\n 8 Pilar Martín González              22 M        60   1.66         NA\n 9 Pedro Gálvez Tenorio               35 H        90   1.94        241\n10 Santiago Reillo Manzano            46 H        75   1.85        280\n11 Macarena Álvarez Luna              53 M        55   1.62        262\n12 José María de la Guía Sanz         58 H        78   1.87        198\n13 Miguel Angel Cuadrado Gutiérrez    27 H       109   1.98        210\n14 Carolina Rubio Moreno              20 M        61   1.77        194\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nCon la función glimpse del paquete dplyr. Esta función muestra las columnas del data frame en filas, de manera que permite ver todas las columnas de un data frame cuando este tiene muchas columnas.\n\nglimpse(df)\n\nRows: 14\nColumns: 6\n$ nombre     &lt;chr&gt; \"José Luis Martínez Izquierdo\", \"Rosa Díaz Díaz\", \"Javier G…\n$ edad       &lt;dbl&gt; 18, 32, 24, 35, 46, 68, 51, 22, 35, 46, 53, 58, 27, 20\n$ sexo       &lt;chr&gt; \"H\", \"M\", \"H\", \"M\", \"M\", \"H\", \"H\", \"M\", \"H\", \"H\", \"M\", \"H\",…\n$ peso       &lt;dbl&gt; 85, 65, NA, 65, 51, 66, 62, 60, 90, 75, 55, 78, 109, 61\n$ altura     &lt;dbl&gt; 1.79, 1.73, 1.81, 1.70, 1.58, 1.74, 1.72, 1.66, 1.94, 1.85,…\n$ colesterol &lt;dbl&gt; 182, 232, 191, 200, 148, 249, 276, NA, 241, 280, 262, 198, …\n\n\n\n\n\n\n\nCrear una nueva columna con el índice de masa corporal, usando la siguiente fórmula\n\\[\n\\mbox{IMC} = \\frac{\\mbox{Peso (kg)}}{\\mbox{Altura (cm)}^2}\n\\]\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- df |&gt;\n    mutate(imc = round(peso/altura^2))\ndf\n\n# A tibble: 14 × 7\n   nombre                           edad sexo   peso altura colesterol   imc\n   &lt;chr&gt;                           &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 José Luis Martínez Izquierdo       18 H        85   1.79        182    27\n 2 Rosa Díaz Díaz                     32 M        65   1.73        232    22\n 3 Javier García Sánchez              24 H        NA   1.81        191    NA\n 4 Carmen López Pinzón                35 M        65   1.7         200    22\n 5 Marisa López Collado               46 M        51   1.58        148    20\n 6 Antonio Ruiz Cruz                  68 H        66   1.74        249    22\n 7 Antonio Fernández Ocaña            51 H        62   1.72        276    21\n 8 Pilar Martín González              22 M        60   1.66         NA    22\n 9 Pedro Gálvez Tenorio               35 H        90   1.94        241    24\n10 Santiago Reillo Manzano            46 H        75   1.85        280    22\n11 Macarena Álvarez Luna              53 M        55   1.62        262    21\n12 José María de la Guía Sanz         58 H        78   1.87        198    22\n13 Miguel Angel Cuadrado Gutiérrez    27 H       109   1.98        210    28\n14 Carolina Rubio Moreno              20 M        61   1.77        194    19\n\n\n\n\n\n\n\nCrear una nueva columna con la variable obesidad recodificando la columna imc en las siguientes categorías.\n\n\nRango IMC\nCategoría\n\n\n\nMenor de 18.5\nBajo peso\n\n\nDe 18.5 a 24.5\nSaludable\n\n\nDe 24.5 a 30\nSobrepeso\n\n\nMayor de 30\nObeso\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- df |&gt;\n    mutate(Obesidad = cut(imc, breaks = c(0, 18.5, 24.5, 30, Inf), labels = c(\"Bajo peso\", \"Saludable\", \"Sobrepeso\", \"Obeso\")))\ndf\n\n# A tibble: 14 × 8\n   nombre                      edad sexo   peso altura colesterol   imc Obesidad\n   &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   \n 1 José Luis Martínez Izquie…    18 H        85   1.79        182    27 Sobrepe…\n 2 Rosa Díaz Díaz                32 M        65   1.73        232    22 Saludab…\n 3 Javier García Sánchez         24 H        NA   1.81        191    NA &lt;NA&gt;    \n 4 Carmen López Pinzón           35 M        65   1.7         200    22 Saludab…\n 5 Marisa López Collado          46 M        51   1.58        148    20 Saludab…\n 6 Antonio Ruiz Cruz             68 H        66   1.74        249    22 Saludab…\n 7 Antonio Fernández Ocaña       51 H        62   1.72        276    21 Saludab…\n 8 Pilar Martín González         22 M        60   1.66         NA    22 Saludab…\n 9 Pedro Gálvez Tenorio          35 H        90   1.94        241    24 Saludab…\n10 Santiago Reillo Manzano       46 H        75   1.85        280    22 Saludab…\n11 Macarena Álvarez Luna         53 M        55   1.62        262    21 Saludab…\n12 José María de la Guía Sanz    58 H        78   1.87        198    22 Saludab…\n13 Miguel Angel Cuadrado Gut…    27 H       109   1.98        210    28 Sobrepe…\n14 Carolina Rubio Moreno         20 M        61   1.77        194    19 Saludab…\n\n\n\n\n\n\n\nSeleccionar las columnas nombre, sexo y edad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    select(nombre, sexo, edad)\n\n# A tibble: 14 × 3\n   nombre                          sexo   edad\n   &lt;chr&gt;                           &lt;chr&gt; &lt;dbl&gt;\n 1 José Luis Martínez Izquierdo    H        18\n 2 Rosa Díaz Díaz                  M        32\n 3 Javier García Sánchez           H        24\n 4 Carmen López Pinzón             M        35\n 5 Marisa López Collado            M        46\n 6 Antonio Ruiz Cruz               H        68\n 7 Antonio Fernández Ocaña         H        51\n 8 Pilar Martín González           M        22\n 9 Pedro Gálvez Tenorio            H        35\n10 Santiago Reillo Manzano         H        46\n11 Macarena Álvarez Luna           M        53\n12 José María de la Guía Sanz      H        58\n13 Miguel Angel Cuadrado Gutiérrez H        27\n14 Carolina Rubio Moreno           M        20\n\n\n\n\n\n\n\nAnonimizar los datos eliminando la columna nombre.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    select(-nombre)\n\n# A tibble: 14 × 7\n    edad sexo   peso altura colesterol   imc Obesidad \n   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n 1    18 H        85   1.79        182    27 Sobrepeso\n 2    32 M        65   1.73        232    22 Saludable\n 3    24 H        NA   1.81        191    NA &lt;NA&gt;     \n 4    35 M        65   1.7         200    22 Saludable\n 5    46 M        51   1.58        148    20 Saludable\n 6    68 H        66   1.74        249    22 Saludable\n 7    51 H        62   1.72        276    21 Saludable\n 8    22 M        60   1.66         NA    22 Saludable\n 9    35 H        90   1.94        241    24 Saludable\n10    46 H        75   1.85        280    22 Saludable\n11    53 M        55   1.62        262    21 Saludable\n12    58 H        78   1.87        198    22 Saludable\n13    27 H       109   1.98        210    28 Sobrepeso\n14    20 M        61   1.77        194    19 Saludable\n\n\n\n\n\n\n\nReordenar las columnas poniendo la columna sexo antes que la columna edad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    select(nombre, sexo, edad, everything())\n\n# A tibble: 14 × 8\n   nombre                     sexo   edad  peso altura colesterol   imc Obesidad\n   &lt;chr&gt;                      &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   \n 1 José Luis Martínez Izquie… H        18    85   1.79        182    27 Sobrepe…\n 2 Rosa Díaz Díaz             M        32    65   1.73        232    22 Saludab…\n 3 Javier García Sánchez      H        24    NA   1.81        191    NA &lt;NA&gt;    \n 4 Carmen López Pinzón        M        35    65   1.7         200    22 Saludab…\n 5 Marisa López Collado       M        46    51   1.58        148    20 Saludab…\n 6 Antonio Ruiz Cruz          H        68    66   1.74        249    22 Saludab…\n 7 Antonio Fernández Ocaña    H        51    62   1.72        276    21 Saludab…\n 8 Pilar Martín González      M        22    60   1.66         NA    22 Saludab…\n 9 Pedro Gálvez Tenorio       H        35    90   1.94        241    24 Saludab…\n10 Santiago Reillo Manzano    H        46    75   1.85        280    22 Saludab…\n11 Macarena Álvarez Luna      M        53    55   1.62        262    21 Saludab…\n12 José María de la Guía Sanz H        58    78   1.87        198    22 Saludab…\n13 Miguel Angel Cuadrado Gut… H        27   109   1.98        210    28 Sobrepe…\n14 Carolina Rubio Moreno      M        20    61   1.77        194    19 Saludab…\n\n\n\n\n\n\n\nFiltrar el data frame para quedarse con las mujeres.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    filter(sexo == \"M\")\n\n# A tibble: 6 × 8\n  nombre                 edad sexo   peso altura colesterol   imc Obesidad \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n1 Rosa Díaz Díaz           32 M        65   1.73        232    22 Saludable\n2 Carmen López Pinzón      35 M        65   1.7         200    22 Saludable\n3 Marisa López Collado     46 M        51   1.58        148    20 Saludable\n4 Pilar Martín González    22 M        60   1.66         NA    22 Saludable\n5 Macarena Álvarez Luna    53 M        55   1.62        262    21 Saludable\n6 Carolina Rubio Moreno    20 M        61   1.77        194    19 Saludable\n\n\n\n\n\n\n\nFiltrar el data frame para quedarse con los hombres mayores de 30 años.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    filter( sexo == \"H\" & edad &gt; 30)\n\n# A tibble: 5 × 8\n  nombre                      edad sexo   peso altura colesterol   imc Obesidad \n  &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n1 Antonio Ruiz Cruz             68 H        66   1.74        249    22 Saludable\n2 Antonio Fernández Ocaña       51 H        62   1.72        276    21 Saludable\n3 Pedro Gálvez Tenorio          35 H        90   1.94        241    24 Saludable\n4 Santiago Reillo Manzano       46 H        75   1.85        280    22 Saludable\n5 José María de la Guía Sanz    58 H        78   1.87        198    22 Saludable\n\n\n\n\n\n\n\nFiltrar el data frame para eliminar las filas con datos perdidos en la columna colesterol.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    filter(!is.na(colesterol))\n\n# A tibble: 13 × 8\n   nombre                      edad sexo   peso altura colesterol   imc Obesidad\n   &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   \n 1 José Luis Martínez Izquie…    18 H        85   1.79        182    27 Sobrepe…\n 2 Rosa Díaz Díaz                32 M        65   1.73        232    22 Saludab…\n 3 Javier García Sánchez         24 H        NA   1.81        191    NA &lt;NA&gt;    \n 4 Carmen López Pinzón           35 M        65   1.7         200    22 Saludab…\n 5 Marisa López Collado          46 M        51   1.58        148    20 Saludab…\n 6 Antonio Ruiz Cruz             68 H        66   1.74        249    22 Saludab…\n 7 Antonio Fernández Ocaña       51 H        62   1.72        276    21 Saludab…\n 8 Pedro Gálvez Tenorio          35 H        90   1.94        241    24 Saludab…\n 9 Santiago Reillo Manzano       46 H        75   1.85        280    22 Saludab…\n10 Macarena Álvarez Luna         53 M        55   1.62        262    21 Saludab…\n11 José María de la Guía Sanz    58 H        78   1.87        198    22 Saludab…\n12 Miguel Angel Cuadrado Gut…    27 H       109   1.98        210    28 Sobrepe…\n13 Carolina Rubio Moreno         20 M        61   1.77        194    19 Saludab…\n\n\n\n\n\n\n\nOrdenar el data frame según la columna nombre.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    arrange(nombre)\n\n# A tibble: 14 × 8\n   nombre                      edad sexo   peso altura colesterol   imc Obesidad\n   &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   \n 1 Antonio Fernández Ocaña       51 H        62   1.72        276    21 Saludab…\n 2 Antonio Ruiz Cruz             68 H        66   1.74        249    22 Saludab…\n 3 Carmen López Pinzón           35 M        65   1.7         200    22 Saludab…\n 4 Carolina Rubio Moreno         20 M        61   1.77        194    19 Saludab…\n 5 Javier García Sánchez         24 H        NA   1.81        191    NA &lt;NA&gt;    \n 6 José Luis Martínez Izquie…    18 H        85   1.79        182    27 Sobrepe…\n 7 José María de la Guía Sanz    58 H        78   1.87        198    22 Saludab…\n 8 Macarena Álvarez Luna         53 M        55   1.62        262    21 Saludab…\n 9 Marisa López Collado          46 M        51   1.58        148    20 Saludab…\n10 Miguel Angel Cuadrado Gut…    27 H       109   1.98        210    28 Sobrepe…\n11 Pedro Gálvez Tenorio          35 H        90   1.94        241    24 Saludab…\n12 Pilar Martín González         22 M        60   1.66         NA    22 Saludab…\n13 Rosa Díaz Díaz                32 M        65   1.73        232    22 Saludab…\n14 Santiago Reillo Manzano       46 H        75   1.85        280    22 Saludab…\n\n\n\n\n\n\n\nOrdenar el data frame ascendentemente por la columna sexo y descendentemente por la columna edad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf |&gt;\n    arrange(sexo, desc(edad))\n\n# A tibble: 14 × 8\n   nombre                      edad sexo   peso altura colesterol   imc Obesidad\n   &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   \n 1 Antonio Ruiz Cruz             68 H        66   1.74        249    22 Saludab…\n 2 José María de la Guía Sanz    58 H        78   1.87        198    22 Saludab…\n 3 Antonio Fernández Ocaña       51 H        62   1.72        276    21 Saludab…\n 4 Santiago Reillo Manzano       46 H        75   1.85        280    22 Saludab…\n 5 Pedro Gálvez Tenorio          35 H        90   1.94        241    24 Saludab…\n 6 Miguel Angel Cuadrado Gut…    27 H       109   1.98        210    28 Sobrepe…\n 7 Javier García Sánchez         24 H        NA   1.81        191    NA &lt;NA&gt;    \n 8 José Luis Martínez Izquie…    18 H        85   1.79        182    27 Sobrepe…\n 9 Macarena Álvarez Luna         53 M        55   1.62        262    21 Saludab…\n10 Marisa López Collado          46 M        51   1.58        148    20 Saludab…\n11 Carmen López Pinzón           35 M        65   1.7         200    22 Saludab…\n12 Rosa Díaz Díaz                32 M        65   1.73        232    22 Saludab…\n13 Pilar Martín González         22 M        60   1.66         NA    22 Saludab…\n14 Carolina Rubio Moreno         20 M        61   1.77        194    19 Saludab…\n\n\n\n\n\n\n\n\n\nEjercicio 2.3 El fichero notas-curso2.csv contiene las notas de las asignaturas de un curso en varios grupos de alumnos.\n\n\nCrear un data frame con los datos del curso a partir del fichero notas-curso2.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- read_csv(\"https://raw.githubusercontent.com/asalber/estadistica-practicas-r/main/datos/notas-curso2.csv\")\n\nRows: 120 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): sexo, turno, grupo, trabaja\ndbl (5): notaA, notaB, notaC, notaD, notaE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf\n\n# A tibble: 120 × 9\n   sexo   turno  grupo trabaja notaA notaB notaC notaD notaE\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mujer  Tarde  C     N         5.2   6.3   3.4   2.3   2  \n 2 Hombre Mañana A     N         5.7   5.7   4.2   3.5   2.7\n 3 Hombre Mañana B     N         8.3   8.8   8.8   8     5.5\n 4 Hombre Mañana B     N         6.1   6.8   4     3.5   2.2\n 5 Hombre Mañana A     N         6.2   9     5     4.4   3.7\n 6 Hombre Mañana A     S         8.6   8.9   9.5   8.4   3.9\n 7 Mujer  Mañana A     N         6.7   7.9   5.6   4.8   4.2\n 8 Mujer  Tarde  C     S         4.1   5.2   1.7   0.3   1  \n 9 Hombre Tarde  C     N         5     5     3.3   2.7   6  \n10 Hombre Tarde  C     N         5.3   6.3   4.8   3.6   2.3\n# ℹ 110 more rows\n\n\n\n\n\n\n\nConvertir el data frame a formato largo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf_largo &lt;- df |&gt; pivot_longer(notaA:notaE, names_to = \"Asignatura\", values_to = \"Nota\")\ndf_largo\n\n# A tibble: 600 × 6\n   sexo   turno  grupo trabaja Asignatura  Nota\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;\n 1 Mujer  Tarde  C     N       notaA        5.2\n 2 Mujer  Tarde  C     N       notaB        6.3\n 3 Mujer  Tarde  C     N       notaC        3.4\n 4 Mujer  Tarde  C     N       notaD        2.3\n 5 Mujer  Tarde  C     N       notaE        2  \n 6 Hombre Mañana A     N       notaA        5.7\n 7 Hombre Mañana A     N       notaB        5.7\n 8 Hombre Mañana A     N       notaC        4.2\n 9 Hombre Mañana A     N       notaD        3.5\n10 Hombre Mañana A     N       notaE        2.7\n# ℹ 590 more rows\n\n\n\n\n\n\n\nCrear una nueva columna con la variable calificación que contenga las calificaciones de cada asignatura.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf_largo &lt;- df_largo |&gt;\n    mutate(Califiación = cut(Nota, breaks = c(0, 4.99, 6.99, 8.99, 10), labels = c(\"SS\", \"AP\", \"NT\", \"SB\")))\ndf_largo\n\n# A tibble: 600 × 7\n   sexo   turno  grupo trabaja Asignatura  Nota Califiación\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;fct&gt;      \n 1 Mujer  Tarde  C     N       notaA        5.2 AP         \n 2 Mujer  Tarde  C     N       notaB        6.3 AP         \n 3 Mujer  Tarde  C     N       notaC        3.4 SS         \n 4 Mujer  Tarde  C     N       notaD        2.3 SS         \n 5 Mujer  Tarde  C     N       notaE        2   SS         \n 6 Hombre Mañana A     N       notaA        5.7 AP         \n 7 Hombre Mañana A     N       notaB        5.7 AP         \n 8 Hombre Mañana A     N       notaC        4.2 SS         \n 9 Hombre Mañana A     N       notaD        3.5 SS         \n10 Hombre Mañana A     N       notaE        2.7 SS         \n# ℹ 590 more rows\n\n\n\n\n\n\n\nFiltrar el conjunto de datos para obtener las asignaturas y las notas de las mujeres del grupo A, ordenadas de mayor a menor.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf_largo |&gt;\n    filter(sexo == \"Mujer\", grupo == \"A\") |&gt;\n    select(Asignatura, Nota) |&gt;\n    arrange(desc(Nota))\n\n# A tibble: 75 × 2\n   Asignatura  Nota\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 notaB        9.2\n 2 notaE        9.2\n 3 notaB        8.8\n 4 notaB        8.6\n 5 notaB        8.6\n 6 notaA        8.3\n 7 notaB        8.2\n 8 notaB        8.1\n 9 notaA        8  \n10 notaB        8  \n# ℹ 65 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preprocesamiento de datos</span>"
    ]
  },
  {
    "objectID": "02-preprocesamiento-datos.html#ejercicios-propuestos",
    "href": "02-preprocesamiento-datos.html#ejercicios-propuestos",
    "title": "\n2  Preprocesamiento de datos\n",
    "section": "\n2.2 Ejercicios Propuestos",
    "text": "2.2 Ejercicios Propuestos\n\nEjercicio 2.4 La siguiente tabla recoge las notas de los alumnos de un curso con dos asignaturas.\n\n\nAlumno\nSexo\nFísica\nQuímica\n\n\n\nCarlos\nH\n6.7\n8.1\n\n\nMaría\nM\n7.2\n9.5\n\n\nCarmen\nM\n5.5\n5\n\n\nPedro\nH\n\n4.5\n\n\nLuis\nH\n3.5\n5\n\n\nSara\nM\n6.2\n4\n\n\n\n\n\nDefinir cuatro vectores con el nombre, el sexo y las notas de Física y Química.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nnombre &lt;- c(\"Carlos\", \"María\", \"Carmen\", \"Pedro\", \"Luis\", \"Sara\")\nsexo &lt;- c(\"H\", \"M\", \"M\", \"H\", \"H\", \"M\")\nfisica &lt;- c(6.7, 7.2, 5.5, NA, 3.5, 6.2)\nquimica &lt;- c(8.1, 9.5, 5, 4.5, 5, 4)\n\n\n\n\n\n\nConvertir el sexo en un factor y mostrar sus niveles.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nsexo &lt;- factor(sexo)\nlevels(sexo)\n\n[1] \"H\" \"M\"\n\n\n\n\n\n\n\nCrear un data frame con el nombre, sexo y las notas de Física y Química.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(nombre, sexo, fisica, quimica)\ndf\n\n  nombre sexo fisica quimica\n1 Carlos    H    6.7     8.1\n2  María    M    7.2     9.5\n3 Carmen    M    5.5     5.0\n4  Pedro    H     NA     4.5\n5   Luis    H    3.5     5.0\n6   Sara    M    6.2     4.0\n\n\n\n\n\n\n\nCrear una nueva columna con la nota media de Física y Química.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf$media &lt;- (df$fisica + df$quimica) / 2\ndf\n\n  nombre sexo fisica quimica media\n1 Carlos    H    6.7     8.1  7.40\n2  María    M    7.2     9.5  8.35\n3 Carmen    M    5.5     5.0  5.25\n4  Pedro    H     NA     4.5    NA\n5   Luis    H    3.5     5.0  4.25\n6   Sara    M    6.2     4.0  5.10\n\n\n\n\n\n\n\nCrear una nueva columna booleana aprobado que tenga el valor TRUE si la media es mayor o igual que 5 y FALSE en caso contrario.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf$aprobado &lt;- df$media &gt;= 5\ndf\n\n  nombre sexo fisica quimica media aprobado\n1 Carlos    H    6.7     8.1  7.40     TRUE\n2  María    M    7.2     9.5  8.35     TRUE\n3 Carmen    M    5.5     5.0  5.25     TRUE\n4  Pedro    H     NA     4.5    NA       NA\n5   Luis    H    3.5     5.0  4.25    FALSE\n6   Sara    M    6.2     4.0  5.10     TRUE\n\n\n\n\n\n\n\nFiltrar el data frame para quedarse con el nombre y la media de las mujeres que han aprobado.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf[df$sexo == \"M\" & df$media &gt;= 5, c(\"nombre\", \"media\")]\n\n  nombre media\n2  María  8.35\n3 Carmen  5.25\n6   Sara  5.10\n\n\n\n\n\n\n\n\n\nEjercicio 2.5 Se ha diseñado un ensayo clínico aleatorizado, doble-ciego y controlado con placebo, para estudiar el efecto de dos alternativas terapéuticas en el control de la hipertensión arterial. Se han reclutado 100 pacientes hipertensos y estos han sido distribuidos aleatoriamente en tres grupos de tratamiento. A uno de los grupos (control) se le administró un placebo, a otro grupo se le administró un inhibidor de la enzima conversora de la angiotensina (IECA) y al otro un tratamiento combinado de un diurético y un Antagonista del Calcio. Las variables respuesta final fueron las presiones arteriales sistólica y diastólica.\nLos datos con las claves de aleatorización han sido introducidos en una base de datos que reside en la central de aleatorización, mientras que los datos clínicos han sido archivados en dos archivos distintos, uno para cada uno de los dos centros participantes en el estudio.\nLas variables almacenadas en estos archivos clínicos son las siguientes:\n\nCLAVE: Clave de aleatorización\nNOMBRE: Iniciales del paciente\nF_NACIM: Fecha de Nacimiento\nF_INCLUS: Fecha de inclusión\nSEXO: Sexo (0: Hombre 1: Mujer)\nALTURA: Altura en cm.\nPESO: Peso en Kg.\nPAD_INI: Presión diastólica basal (inicial)\nPAD_FIN: Presión diastólica final\nPAS_INI: Presión sistólica basal (inicial)\nPAS_FIN: Presión sistólica final\n\nEl archivo de claves de aleatorización contiene sólo dos variables.\n\nCLAVE: Clave de aleatorización\nFARMACO: Fármaco administrado (0: Placebo, 1: IECA, 2:Ca Antagonista + diurético)\n\n\nCrear un data frame con los datos de los pacientes del hospital A (fichero de csv datos-hospital-a.csv).\nCrear un data frame con los datos de los pacientes del hospital B (fichero csv datos-hospital-b.csv).\n\nFusionar los datos de los dos hospitales en un nuevo data frame.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara fusionar las filas de dos data frames con las mismas columnas usar la función rbind.\n\n\n\n\nCrear un data frame con los datos de las claves de aleatorización (fichero csv claves-aleatorizacion.csv)\n\nFusionar el data frame con los datos clínicos y el data frame con claves de aleatorización en un nuevo data frame.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara fusionar las columnas de dos data frames usando una misma columna como clave en ambos data frames usar la función left_join del paquete dplyr.\n\n\n\n\nConvertir en un factor el sexo.\nCrear una nueva columna para la evolución de la presión arterial diastólica restando las columnas PAS_FIN y PAS_FIN.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preprocesamiento de datos</span>"
    ]
  },
  {
    "objectID": "03-frecuencias-graficos.html",
    "href": "03-frecuencias-graficos.html",
    "title": "\n3  Distribuciones de frecuencias y representaciones gráficas\n",
    "section": "",
    "text": "3.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:\nlibrary(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - ggplot2: para la representación gráfica.\nlibrary(knitr) # para el formateo de tablas.\nlibrary(kableExtra) # para personalizar el formato de las tablas.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones de frecuencias y representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "03-frecuencias-graficos.html#ejercicios-resueltos",
    "href": "03-frecuencias-graficos.html#ejercicios-resueltos",
    "title": "\n3  Distribuciones de frecuencias y representaciones gráficas\n",
    "section": "",
    "text": "Ejercicio 3.1 En una encuesta a 25 matrimonios sobre el número de hijos que tenían se obtuvieron los siguientes datos:\n\n\n\n1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2\n\n\n\n\nCrear un conjunto de datos con la variable hijos.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(hijos = c(1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2))\n\n\n\n\n\n\nConstruir la tabla de frecuencias.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara obtener las frecuencias absolutas se puede usar la función table, y para las frecuencias relativas la función prop.table ambas del paquete base de R.\n\n# Frecuencias absolutas.\nni &lt;- table(df$hijos)\n# Frecuencias relativas\nfi &lt;- prop.table(ni)\n# Frecuencias acumuladas.\nNi &lt;- cumsum(ni)\n# Frecuencias relativas acumuladas.\nFi &lt;- cumsum(fi)\n# Creación de un data frame con las frecuencias.\ntabla_frec &lt;- cbind(ni, fi, Ni, Fi)\ntabla_frec\n\n  ni   fi Ni   Fi\n0  2 0.08  2 0.08\n1  6 0.24  8 0.32\n2 14 0.56 22 0.88\n3  2 0.08 24 0.96\n4  1 0.04 25 1.00\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función count del paquete dplyr.\n\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(kableExtra)\ncount(df, hijos) |&gt; \n    mutate(fi = n/sum(n), Ni = cumsum(n), Fi = cumsum(n)/sum(n)) |&gt;\n    kable() |&gt;\n    kable_styling(bootstrap_options = \"hover\", full_width = F)\n\n\n\nhijos\nn\nfi\nNi\nFi\n\n\n\n0\n2\n0.08\n2\n0.08\n\n\n1\n6\n0.24\n8\n0.32\n\n\n2\n14\n0.56\n22\n0.88\n\n\n3\n2\n0.08\n24\n0.96\n\n\n4\n1\n0.04\n25\n1.00\n\n\n\n\n\n\n\n\n\n\nDibujar el diagrama de barras de las frecuencias absolutas, relativas, absolutas acumuladas y relativas acumuladas.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar un diagrama de barras se puede usar la función barplot del paquete graphics.\n\n# Diagrama de barras de frecuencias absolutas.\nbarplot(ni, col = \"steelblue\", main=\"Distribución del número de hijos\", xlab=\"Hijos\", ylab=\"Frecuencia absoluta\")\n\n\n\n\n\n\n# Diagrama de barras de frecuencias relativas.\nbarplot(fi, col = \"steelblue\", main=\"Distribución del número de hijos\", xlab=\"Hijos\", ylab=\"Frecuencia relativa\")\n\n\n\n\n\n\n# Diagrama de barras de frecuencias absolutas acumuladas.\nbarplot(Ni, col = \"steelblue\", main=\"Distribución acumulada del número de hijos\", xlab=\"Hijos\", ylab=\"Frecuencia absoluta acumulada\")\n\n\n\n\n\n\n# Diagrama de barras de frecuencias relativas acumuladas.\nbarplot(Fi, col = \"steelblue\", main=\"Distribución acumulada del número de hijos\", xlab=\"Hijos\", ylab=\"Frecuencia relativa acumulada\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función la función geom_bar del paquete ggplot2.\n\nlibrary(ggplot2)\n# Diagarma de barras de frecuencias absolutas\nggplot(df, aes(x = hijos)) +\n    geom_bar(fill = \"steelblue\") + \n    labs(title = \"Distribución del número de hijos\", y = \"Frecuencia absoluta\")\n\n\n\n\n\n\n# Diagarma de barras de frecuencias relativas\nggplot(df, aes(x = hijos)) +\n    geom_bar(aes(y = after_stat(count/sum(count))), fill = \"steelblue\") +\n    labs(title = \"Distribución del número de hijos\", y = \"Frecuencia relativa\")\n\n\n\n\n\n\n# Diagarma de barras de frecuencias acumuladas\nggplot(df, aes(x = hijos)) +\n    geom_bar(aes(y = after_stat(cumsum(count))), fill = \"steelblue\") +\n    labs(title = \"Distribución acumulada del número de hijos\", y = \"Frecuencia absoluta acumulada\")\n\n\n\n\n\n\n# Diagarma de barras de frecuencias acumuladas\nggplot(df, aes(x = hijos)) +\n    geom_bar(aes(y = after_stat(cumsum(count)/sum(count))), fill = \"steelblue\") +\n    labs(title = \"Distribución acumulada del número de hijos\", y = \"Frecuencia relativa acumulada\")\n\n\n\n\n\n\n\n\n\n\n\n\nDibujar el polígono de frecuencias relativas.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar un diagrama de lineas se puede usar la función plot del paquete graphics.\n\n# Frecuencias relativas.\nplot(names(fi), fi, type = \"l\", col = \"steelblue\", main=\"Distribución del número de hijos\", xlab=\"Hijos\", ylab=\"Frecuencia relativa\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función la función geom_line del paquete ggplot2.\n\nlibrary(ggplot2)\ncount(df, hijos) |&gt; \n    mutate(fi = n/sum(n)) |&gt;\n    ggplot(aes(x=hijos, y=fi)) +\n    geom_line(col = \"steelblue\") +\n    labs(title = \"Distribución del número de hijos\", y = \"Frecuencia relativa\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 3.2 En un servicio de atención al cliente se han registrado el número de llamadas de clientes cada día del mes de noviembre, obteniendo los siguientes datos:\n\n\n\n15, 23, 12, 10, 28, 50, 12, 17, 20, 21, 18, 13, 11, 12, 26, 30, 6, 16, 19, 22, 14, 17, 21, 28, 9, 16, 13, 11, 16, 20\n\n\n\n\nCrear un conjunto de datos con la variable llamadas.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(llamadas = c(15, 23, 12, 10, 28, 50, 12, 17, 20, 21, 18, 13, 11, 12, 26, 30, 6, 16, 19, 22, 14, 17, 21, 28, 9, 16, 13, 11, 16, 20))\n\n\n\n\n\n\nDibujar el diagrama de cajas. ¿Existe algún dato atípico? En el caso de que exista, eliminarlo y proceder con los siguientes apartados.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar un diagrama de cajas se puede usar la función boxplot del paquete graphics.\n\n# Frecuencias relativas.\nboxplot(df$llamadas, col = \"steelblue\", main=\"Distribución del número de llamadas\", horizontal = T, xlab=\"Número de llamadas\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función la función geom_boxplot del paquete ggplot2.\n\nlibrary(ggplot2)\nggplot(df, aes(x = llamadas)) +\n    geom_boxplot(fill = \"steelblue\") +\n    labs(title = \"Distribución del número de llamadas\", x = \"Número de llamadas\")\n\n\n\n\n\n\n\nHay un día con 50 llamadas, que es un valor atípico en comparación con el resto de días.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nLa función cut\n\n# Eliminación del dato atípico.\ndf &lt;- df[df$llamadas != 50, , drop = F]\n\n\n\n\n\n\n\n\n\nConstruir la tabla de frecuencias agrupando en 5 clases.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara agrupar los datos en intervalos se puede utilizar la función cut del paquete base de R, y para contar las frecuencias absolutas y relativas las funciones table, y prop.table respectivamente.\n\n# Frecuencias absolutas. Creación automática de 5 clases con intervalos cerrados a la izquierda.\n\n\nni &lt;- table(cut(df$llamadas, breaks = 5, right = F))\n# Creación manual de 5 clases.\nni &lt;- table(cut(df$llamadas, breaks = seq(5, 30, 5)))\n# Frecuencias relativas\nfi &lt;- prop.table(ni)\n# Frecuencias acumuladas.\nNi &lt;- cumsum(ni)\n# Frecuencias relativas acumuladas.\nFi &lt;- cumsum(fi)\n# Creación de un data frame con las frecuencias.\ntabla_frec &lt;- cbind(ni, fi, Ni, Fi)\ntabla_frec\n\n        ni        fi Ni        Fi\n(5,10]   3 0.1034483  3 0.1034483\n(10,15]  9 0.3103448 12 0.4137931\n(15,20]  9 0.3103448 21 0.7241379\n(20,25]  4 0.1379310 25 0.8620690\n(25,30]  4 0.1379310 29 1.0000000\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la fución count del paquete dplyr.\n\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(kableExtra)\nmutate(df, llamadas_int = cut(llamadas, breaks = seq(5, 30, 5))) |&gt; \n    count(llamadas_int) |&gt;\n    mutate(fi = n/sum(n), Ni = cumsum(n), Fi = cumsum(n)/sum(n)) |&gt;\n    kable() |&gt;\n    kable_styling(bootstrap_options = \"hover\", full_width = F)\n\n\n\nllamadas_int\nn\nfi\nNi\nFi\n\n\n\n(5,10]\n3\n0.1034483\n3\n0.1034483\n\n\n(10,15]\n9\n0.3103448\n12\n0.4137931\n\n\n(15,20]\n9\n0.3103448\n21\n0.7241379\n\n\n(20,25]\n4\n0.1379310\n25\n0.8620690\n\n\n(25,30]\n4\n0.1379310\n29\n1.0000000\n\n\n\n\n\n\n\n\n\n\nDibujar el histograma de frecuencias absolutas, relativas, absolutas acumuladas y relativas acumuladas correspondiente a la tabla anterior.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar un histograma se puede usar la función hist del paquete graphics.\n\n# Histograma de frecuencias absolutas.\nhisto &lt;- hist(df$llamadas, breaks = seq(5, 30, 5), col = \"steelblue\", main=\"Distribución del número de llamadas\", xlab=\"Llamadas\", ylab=\"Frecuencia absoluta\")\n\n\n\n\n\n\nni &lt;- histo$counts\n# Histograma de frecuencias relativas.\nhisto$counts &lt;- ni/sum(ni)\nplot(histo, col = \"steelblue\", main=\"Distribución del número de llamadas\", xlab=\"Llamadas\", ylab=\"Frecuencia relativa\")\n\n\n\n\n\n\n# Histograma de frecuencias absolutas acumuladas.\nhisto$counts &lt;- cumsum(ni)\nplot(histo, col = \"steelblue\", main=\"Distribución acumulada del número de llamadas\", xlab=\"Llamadas\", ylab=\"Frecuencia absoluta acumulada\")\n\n\n\n\n\n\n# Histograma de frecuencias relativas acumuladas.\nhisto$counts &lt;- cumsum(ni)/sum(ni)\nplot(histo, col = \"steelblue\", main=\"Distribución acumulada del número de llamadas\", xlab=\"Llamadas\", ylab=\"Frecuencia relativa acumulada\", )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función la función geom_histogram del paquete ggplot2.\n\nlibrary(ggplot2)\n# Histograma de frecuencias absolutas\nggplot(df, aes(x = llamadas)) +\n    geom_histogram(breaks = seq(5, 30, 5), fill = \"steelblue\", col = \"white\") + \n    labs(title = \"Distribución del número de llamadas\", x = \"Número de llamadas\", y = \"Frecuencia absoluta\")\n\n\n\n\n\n\n# Histograma de frecuencias relativas\nggplot(df, aes(x = llamadas)) +\n    geom_histogram(aes(y = after_stat(count/sum(count))), breaks = seq(5, 30, 5), fill = \"steelblue\", col = \"white\") +\n    labs(title = \"Distribución del número de llamadas\", x = \"Número de llamadas\", y = \"Frecuencia relativa\")\n\n\n\n\n\n\n# Histograma de frecuencias acumuladas\nggplot(df, aes(x = llamadas)) +\n    geom_histogram(aes(y = after_stat(cumsum(count))), breaks = seq(5, 30, 5), fill = \"steelblue\", col = \"white\") +\n    labs(title = \"Distribución acumulada del número de llamadas\", x = \"Número de llamadas\", y = \"Frecuencia absoluta acumulada\")\n\n\n\n\n\n\n# Histograma de frecuencias relativas acumuladas\nggplot(df, aes(x = llamadas)) +\n    geom_histogram(aes(y = after_stat(cumsum(count)/sum(count))),  breaks = seq(5, 30, 5), fill = \"steelblue\", col = \"white\") +\n    labs(title = \"Distribución acumulada del número de llamadas\", x = \"Número de llamadas\", y = \"Frecuencia relativa acumulada\")\n\n\n\n\n\n\n\n\n\n\n\n\nDibujar el polígono de frecuencias relativas acumuladas (ojiva).\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar la ojiva se puede usar la función plot del paquete graphics.\n\n# Ojiva\ncortes = seq(5, 30, 5)\nni &lt;- table(cut(df$llamadas, breaks = cortes))\nFi &lt;- c(0, cumsum(ni)/sum(ni))\nplot(cortes, Fi, type = \"l\", col = \"steelblue\", main = \"Distribución acumulada del número de llamadas\", xlab = \"Número de llamadas\", ylab = \"Frecuencia relativa acumulada\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función la función geom_line del paquete ggplot2.\n\nlibrary(ggplot2)\n# Ojiva\ncortes &lt;- seq(5, 30, 5)\ntabla_frec &lt;- mutate(df, llamadas_int = cut(df$llamadas, breaks = cortes)) |&gt; \n    count(llamadas_int) |&gt;\n    mutate(cortes = cortes[-1], Fi = cumsum(n)/sum(n)) |&gt;\n    select(cortes, Fi) \ntabla_frec &lt;- rbind(data.frame(cortes = cortes[1], Fi = 0), tabla_frec)\nggplot(tabla_frec, aes(x = cortes , y = Fi)) +\n    geom_line(col = \"steelblue\") +\n    labs(title = \"Distribución del número de llamadas\", x = \"Número de llamadas\", y = \"Frecuencia relativa acumulada\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 3.3 Los grupos sanguíneos de una muestra de 30 personas son:\n\n\n\nA, B, B, A, AB, 0, 0, A, B, B, A, A, A, A, AB, A, A, A, B, 0, B, B, B, A, A, A, 0, A, AB, 0\n\n\n\n\nCrear un conjunto de datos con la variable grupo_sanguíneo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(grupo_sanguineo = c(\"A\", \"B\", \"B\", \"A\", \"AB\", \"0\", \"0\", \"A\", \"B\", \"B\", \"A\", \"A\", \"A\", \"A\", \"AB\", \"A\", \"A\", \"A\", \"B\", \"0\", \"B\", \"B\", \"B\", \"A\", \"A\", \"A\", \"0\", \"A\", \"AB\", \"0\"))\n\n\n\n\n\n\nConstruir la tabla de frecuencias.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara obtener las frecuencias absolutas se puede usar la función table, y para las frecuencias relativas la función prop.table ambas del paquete base de R.\n\n# Frecuencias absolutas.\nni &lt;- table(df$grupo_sanguineo)\n# Frecuencias relativas\nfi &lt;- prop.table(ni)\ntabla_frec &lt;- cbind(ni, fi)\ntabla_frec\n\n   ni        fi\n0   5 0.1666667\nA  14 0.4666667\nAB  3 0.1000000\nB   8 0.2666667\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la fución count del paquete dplyr.\n\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(kableExtra)\ncount(df, grupo_sanguineo) |&gt; \n    mutate(fi = n/sum(n)) |&gt;\n    kable() |&gt;\n    kable_styling(bootstrap_options = \"hover\", full_width = F)\n\n\n\ngrupo_sanguineo\nn\nfi\n\n\n\n0\n5\n0.1666667\n\n\nA\n14\n0.4666667\n\n\nAB\n3\n0.1000000\n\n\nB\n8\n0.2666667\n\n\n\n\n\n\n\n\n\n\nDibujar el diagrama de sectores.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar el diagrama de sectores se puede usar la función pie del paquete graphics.\n\n# Diagrama de sectores\npie(ni, col = 1:length(ni), main = \"Distribución de los grupos sanguíneos\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar las fuciones geom_bar y coor_polar del paquete ggplot2.\n\nggplot(df, aes(x = \"\", fill = grupo_sanguineo)) +\n    # Añadir la capa de las barras.\n    geom_bar() +\n    # Añadir el sistema de coordenadas polares\n    coord_polar(theta = \"y\") +\n    labs(title = \"Distribución de los grupos sanguíneos\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 3.4 En un estudio de población se tomó una muestra de 27 personas, y se les preguntó por su edad y estado civil, obteniendo los siguientes resultados:\n\n\nEstado civil\nEdad\n\n\n\nSoltero\n31, 45, 35, 65, 21, 38, 62, 22, 31\n\n\nCasado\n62, 39, 62, 59, 21, 62\n\n\nViudo\n80, 68, 65, 40, 78, 69, 75\n\n\nDivorciado\n31, 65, 59, 49, 65\n\n\n\n\n\nCrear un conjunto de datos con la variables estado_civil y edad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(\n    edad = c(31, 45, 35, 65, 21, 38, 62, 22, 31, 62, 39, 62, 59, 21, 62, 80, 68, 65, 40, 78, 69, 75, 31, 65, 59, 49, 65), \n    estado_civil = rep(c(\"Soltero\", \"Casado\", \"Viudo\", \"Divorciado\"), c(9, 6, 7, 5)))\n\n\n\n\n\n\nCalcular los tamaños muestrales según estado_civil.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nUsando la función table del paquete base de R podemos obtener las frecuencias absolutas del estado civil que es el tamaño muestral de cada grupo.\n\ntable(df$estado_civil)\n\n\n    Casado Divorciado    Soltero      Viudo \n         6          5          9          7 \n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nUsando las funciones groub_by, summarise y n del paquete dplyr.\n\nlibrary(dplyr)\ndf |&gt; group_by(estado_civil) |&gt;\n    summarise(n = n())\n\n# A tibble: 4 × 2\n  estado_civil     n\n  &lt;chr&gt;        &lt;int&gt;\n1 Casado           6\n2 Divorciado       5\n3 Soltero          9\n4 Viudo            7\n\n\n\n\n\n\n\nConstruir la tabla de frecuencias de la variable edad para cada categoría de la variable estado_civil.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara dividir la muestra en grupos se puede usar la función group-by del paquete dplyr.\n\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(kableExtra)\nmutate(df, edad_int = cut(edad, breaks = seq(20, 80, 10))) |&gt;\n    group_by(estado_civil) |&gt;\n    count(edad_int) |&gt; \n    mutate(fi = n/sum(n), Ni = cumsum(n), Fi = cumsum(n)/sum(n)) |&gt;\n    kable() |&gt;\n    kable_styling(bootstrap_options = \"hover\", full_width = F)\n\n\n\nestado_civil\nedad_int\nn\nfi\nNi\nFi\n\n\n\nCasado\n(20,30]\n1\n0.1666667\n1\n0.1666667\n\n\nCasado\n(30,40]\n1\n0.1666667\n2\n0.3333333\n\n\nCasado\n(50,60]\n1\n0.1666667\n3\n0.5000000\n\n\nCasado\n(60,70]\n3\n0.5000000\n6\n1.0000000\n\n\nDivorciado\n(30,40]\n1\n0.2000000\n1\n0.2000000\n\n\nDivorciado\n(40,50]\n1\n0.2000000\n2\n0.4000000\n\n\nDivorciado\n(50,60]\n1\n0.2000000\n3\n0.6000000\n\n\nDivorciado\n(60,70]\n2\n0.4000000\n5\n1.0000000\n\n\nSoltero\n(20,30]\n2\n0.2222222\n2\n0.2222222\n\n\nSoltero\n(30,40]\n4\n0.4444444\n6\n0.6666667\n\n\nSoltero\n(40,50]\n1\n0.1111111\n7\n0.7777778\n\n\nSoltero\n(60,70]\n2\n0.2222222\n9\n1.0000000\n\n\nViudo\n(30,40]\n1\n0.1428571\n1\n0.1428571\n\n\nViudo\n(60,70]\n3\n0.4285714\n4\n0.5714286\n\n\nViudo\n(70,80]\n3\n0.4285714\n7\n1.0000000\n\n\n\n\n\n\n\n\n\n\nDibujar los diagramas de cajas de la edad según el estado civil. ¿Existen datos atípicos? ¿En qué grupo hay mayor dispersión?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = edad, fill = estado_civil)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nDibujar los histogramas de la edad según el estado civil.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nggplot(df, aes(x = edad, fill = estado_civil)) +\n    geom_histogram(breaks = seq(20, 80, 10), position = \"identity\", alpha=0.4)\n\n\n\n\n\n\n\nPara dibujar cada histograma por separado se puede usar la función facet_wrap o facet_grid del paquete ggplot2.\n\nggplot(df, aes(x = edad, fill = estado_civil)) +\n    geom_histogram(breaks = seq(20, 80, 10)) +\n    # Añadir la faceta del estado civil\n    facet_grid(rows = vars(estado_civil))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones de frecuencias y representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "03-frecuencias-graficos.html#ejercicios-propuestos",
    "href": "03-frecuencias-graficos.html#ejercicios-propuestos",
    "title": "\n3  Distribuciones de frecuencias y representaciones gráficas\n",
    "section": "\n3.2 Ejercicios propuestos",
    "text": "3.2 Ejercicios propuestos\n\nEjercicio 3.5 El conjunto de datos neonatos contiene información sobre una muestra de 320 recién nacidos en un hospital durante un año que cumplieron el tiempo normal de gestación.\n\nConstruir la tabla de frecuencias de la puntuación Apgar al minuto de nacer. Si se considera que una puntuación Apgar de 3 o menos indica que el neonato está deprimido, ¿qué porcentaje de niños está deprimido en la muestra?\nComparar las distribuciones de frecuencias de las puntuaciones Apgar al minuto de nacer según si la madre es mayor o menor de 20 años. ¿En qué grupo hay más neonatos deprimidos?\nConstruir la tabla de frecuencias para el peso de los neonatos, agrupando en clases de amplitud \\(0.5\\) desde el \\(2\\) hasta el \\(4.5\\). ¿En qué intervalo de peso hay más neonatos?\nComparar la distribución de frecuencias relativas del peso de los neonatos según si la madre fuma o no. Si se considera como peso bajo un peso menor de \\(2.5\\) kg, ¿En qué grupo hay un mayor porcentaje de niños con peso bajo?\nConstruir el diagrama de barras de la puntuación Apgar al minuto. ¿Qué puntuación Apgar es la más frecuente?\nConstruir el diagrama de frecuencias relativas acumuladas de la puntuación Apgar al minuto. ¿Por debajo de que puntuación estarán la mitad de los niños?\nComparar mediante diagramas de barras de frecuencias relativas las distribuciones de las puntuaciones Apgar al minuto según si la madre ha fumado o no durante el embarazo. ¿Qué se puede concluir?\nConstruir el histograma de pesos, agrupando en clases de amplitud \\(0.5\\) desde el \\(2\\) hasta el \\(4.5\\). ¿En qué intervalo de peso hay más niños?\nComparar la distribución de frecuencias relativas del peso de los neonatos según si la madre fuma o no. ¿En qué grupo se aprecia menor peso de los niños de la muestra?\nComparar la distribución de frecuencias relativas del peso de los neonatos según si la madre fumaba o no antes del embarazo. ¿Qué se puede concluir?\nConstruir el diagrama de caja y bigotes del peso. ¿Entre qué valores se considera que el peso de un neonato es normal? ¿Existen datos atípicos?\nComparar el diagrama de cajas y bigotes del peso, según si la madre fumó o no durante el embarazo y si era mayor o no de 20 años. ¿En qué grupo el peso tiene más dispersión central? ¿En qué grupo pesan menos los niños de la muestra?\nComparar el diagrama de cajas de la puntuación Apgar al minuto y a los cinco minutos. ¿En qué variable hay más dispersión central?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones de frecuencias y representaciones gráficas</span>"
    ]
  },
  {
    "objectID": "04-descriptiva.html",
    "href": "04-descriptiva.html",
    "title": "\n4  Estadística Descriptiva\n",
    "section": "",
    "text": "4.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estadística Descriptiva</span>"
    ]
  },
  {
    "objectID": "04-descriptiva.html#ejercicios-resueltos",
    "href": "04-descriptiva.html#ejercicios-resueltos",
    "title": "\n4  Estadística Descriptiva\n",
    "section": "",
    "text": "library(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.\nlibrary(vtable) # para resúmenes estadísticos.\nlibrary(skimr) # para resúmenes estadísticos.\nlibrary(summarytools) # para resúmenes estadísticos.\nlibrary(knitr) # para el formateo de tablas.\nlibrary(kableExtra) # para personalizar el formato de las tablas.\n\nEjercicio 4.1 En una encuesta a 25 matrimonios sobre el número de hijos que tenían se obtuvieron los siguientes datos:\n\n\n\n1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2\n\n\n\n\nCrear un conjunto de datos con la variable hijos.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(hijos = c(1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2))\n\n\n\n\n\n\nCalcular el tamaño muestral.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nnrow(df)\n\n[1] 25\n\n\n\n\n\n\n\nCalcular la media.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmean(df$hijos)\n\n[1] 1.76\n\n\n\n\n\n\n\nCalcular la mediana.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmedian(df$hijos)\n\n[1] 2\n\n\n\n\n\n\n\nCalcular la moda.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl paquete base de R no tiene implementada ninguna función para calcular la moda, así que definiremos nuestra propia función.\n\nmoda &lt;- function(x) {\nu &lt;- unique(x) # Vector con los valores de la muestra sin repetir (sin ordenar).\ntab &lt;- tabulate(match(x, u)) # Frecuencias absolutas de los valores en u.\nu[tab == max(tab)] # Valor con la mayor frecuencia.\n}\n\nmoda(df$hijos)\n\n[1] 2\n\n\n\n\n\n\n\nCalcular el mínimo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmin(df$hijos)\n\n[1] 0\n\n\n\n\n\n\n\nCalcular el máximo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmax(df$hijos)\n\n[1] 4\n\n\n\n\n\n\n\nCalcular los cuartiles.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nquantile(df$hijos, prob=c(0.25, 0.5, 0.75))\n\n25% 50% 75% \n  1   2   2 \n\n\n\n\n\n\n\nCalcular los percentiles 5 y 95.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nquantile(df$hijos, prob=c(0.05, 0.95))\n\n 5% 95% \n0.2 3.0 \n\n\n\n\n\n\n\nCalcular el rango.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmax(df$hijos) - min(df$hijos)\n\n[1] 4\n\n\n\n\n\n\n\nCalcular el rango intecuartílico.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nIQR(df$hijos)\n\n[1] 1\n\n\n\n\n\n\n\nCalcular la varianza\n\n\n\n\n\n\nSolución\n\n\n\n\n\nR dispone de la función var para calcular la cuasivarianza o varianza corregida \\(\\sum \\frac{(x_i-\\bar x)^2}{n-1}\\), pero no dispone de una función para calcular la varianza, de manera que para calcularla hay que corregir la cuasivarianza.\n\nn &lt;- nrow(df)\n# Cuasivarianza\nprint(paste(\"Cuasivarianza:\", var(df$hijos)))\n\n[1] \"Cuasivarianza: 0.773333333333333\"\n\n# Varianza\nprint(paste(\"Varianza: \", var(df$hijos)*(n-1)/n))\n\n[1] \"Varianza:  0.7424\"\n\n\n\n\n\n\n\nCalcular la desviación típica.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nR dispone de la función sd para calcular la cuasidesviación típica o desviación típica corregida \\(\\sqrt{\\sum \\frac{(x_i-\\bar x)^2}{n-1}}\\), pero no dispone de una función para calcular la desviación típica, de manera que para calcularla hay que corregir la cuasidesviación típica.\n\nn &lt;- nrow(df)\n# Cuasidesviación típica\nprint(paste(\"Cuasidesviación típica:\", sd(df$hijos)))\n\n[1] \"Cuasidesviación típica: 0.879393730551528\"\n\n# Desviación típica\nprint(paste(\"Desviación típica: \", sd(df$hijos)*sqrt((n-1)/n)))\n\n[1] \"Desviación típica:  0.861626369141521\"\n\n\n\n\n\n\n\nCalcular el coeficiente de variación.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nsd(df$hijos) / abs(mean(df$hijos))\n\n[1] 0.4996555\n\n\n\n\n\n\n\nCalcular el coeficiente de asimetría.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular el coeficiente de asimetría se utiliza el paquete moments.\n\nlibrary(moments)\nskewness(df$hijos)\n\n[1] 0.1068549\n\n\nComo \\(g_1\\) está próxima a \\(0\\), la distribución es casi simétrica.\n\n\n\n\n\nCalcular el coeficiente de apuntamiento.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular el coeficiente de apuntamiento se utiliza el paquete moments.\n\nlibrary(moments)\nkurtosis(df$hijos)\n\n[1] 3.71169\n\n\nComo \\(g_2&gt;0\\), la distribución es más apuntada de lo normal (leptocúrtica). Como además \\(g_2\\not\\in(-2,2)\\) se puede concluir que la muestra es demasiado apuntada para provenir de una población normal.\n\n\n\n\n\n\n\nEjercicio 4.2 El fichero colesterol.csv contiene información de una muestra de pacientes donde se han medido la edad, el sexo, el peso, la altura y el nivel de colesterol, además de su nombre.\n\n\nCrear un data frame con los datos de todos los pacientes del estudio a partir del fichero colesterol.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- read.csv(\"https://raw.githubusercontent.com/asalber/estadistica-practicas-r/main/datos/colesterol.csv\")\ndf\n\n                            nombre edad sexo peso altura colesterol\n1     José Luis Martínez Izquierdo   18    H   85   1.79        182\n2                   Rosa Díaz Díaz   32    M   65   1.73        232\n3            Javier García Sánchez   24    H   NA   1.81        191\n4              Carmen López Pinzón   35    M   65   1.70        200\n5             Marisa López Collado   46    M   51   1.58        148\n6                Antonio Ruiz Cruz   68    H   66   1.74        249\n7          Antonio Fernández Ocaña   51    H   62   1.72        276\n8            Pilar Martín González   22    M   60   1.66         NA\n9             Pedro Gálvez Tenorio   35    H   90   1.94        241\n10         Santiago Reillo Manzano   46    H   75   1.85        280\n11           Macarena Álvarez Luna   53    M   55   1.62        262\n12      José María de la Guía Sanz   58    H   78   1.87        198\n13 Miguel Angel Cuadrado Gutiérrez   27    H  109   1.98        210\n14           Carolina Rubio Moreno   20    M   61   1.77        194\n\n\n\n\n\n\n\nCalcular el tamaño muestral según el sexo.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\n\ntable(df$sexo)\n\n\nH M \n8 6 \n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\n\nlibrary(dplyr)\ncount(df, sexo)\n\n  sexo n\n1    H 8\n2    M 6\n\n\n\n\n\n\n\nCalcular la media y la desviación típica del nivel de colesterol sin tener en cuenta los datos perdidos.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nprint(paste(\"Media:\", mean(df$colesterol, na.rm = TRUE)))\n\n[1] \"Media: 220.230769230769\"\n\nprint(paste(\"Desviación típica:\", sd(df$colesterol, na.rm = TRUE)))\n\n[1] \"Desviación típica: 39.8479481825473\"\n\n\n\n\n\n\n\nRealizar un resumen estadístico con la media, el mínimo, los cuartiles y el máximo.\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nUsando el paquete base de R.\n\nsummary(df)\n\n    nombre               edad           sexo                peso       \n Length:14          Min.   :18.00   Length:14          Min.   : 51.00  \n Class :character   1st Qu.:24.75   Class :character   1st Qu.: 61.00  \n Mode  :character   Median :35.00   Mode  :character   Median : 65.00  \n                    Mean   :38.21                      Mean   : 70.92  \n                    3rd Qu.:49.75                      3rd Qu.: 78.00  \n                    Max.   :68.00                      Max.   :109.00  \n                                                       NA's   :1       \n     altura        colesterol   \n Min.   :1.580   Min.   :148.0  \n 1st Qu.:1.705   1st Qu.:194.0  \n Median :1.755   Median :210.0  \n Mean   :1.769   Mean   :220.2  \n 3rd Qu.:1.840   3rd Qu.:249.0  \n Max.   :1.980   Max.   :280.0  \n                 NA's   :1      \n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nUsando la función st del paquete vtable.\n\nlibrary(vtable)\nst(df)\n\n\nSummary Statistics\n\nVariable\nN\nMean\nStd. Dev.\nMin\nPctl. 25\nPctl. 75\nMax\n\n\n\nedad\n14\n38\n16\n18\n25\n50\n68\n\n\nsexo\n14\n\n\n\n\n\n\n\n\n... H\n8\n57%\n\n\n\n\n\n\n\n... M\n6\n43%\n\n\n\n\n\n\n\npeso\n13\n71\n16\n51\n61\n78\n109\n\n\naltura\n14\n1.8\n0.12\n1.6\n1.7\n1.8\n2\n\n\ncolesterol\n13\n220\n40\n148\n194\n249\n280\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 3\n\n\n\n\n\nUsando la función skim del paquete skimr.\n\nlibrary(skimr)\nskim(df)\n\n\n\nData summary\n\n\n\n\nName\n\n\ndf\n\n\n\n\nNumber of rows\n\n\n14\n\n\n\n\nNumber of columns\n\n\n6\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\ncharacter\n\n\n2\n\n\n\n\nnumeric\n\n\n4\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\nVariable type: character\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmin\n\n\nmax\n\n\nempty\n\n\nn_unique\n\n\nwhitespace\n\n\n\n\n\nnombre\n\n\n0\n\n\n1\n\n\n14\n\n\n31\n\n\n0\n\n\n14\n\n\n0\n\n\n\n\nsexo\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n2\n\n\n0\n\n\n\n\nVariable type: numeric\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\n\n\n\nedad\n\n\n0\n\n\n1.00\n\n\n38.21\n\n\n15.62\n\n\n18.00\n\n\n24.75\n\n\n35.00\n\n\n49.75\n\n\n68.00\n\n\n▇▅▃▅▂\n\n\n\n\npeso\n\n\n1\n\n\n0.93\n\n\n70.92\n\n\n16.13\n\n\n51.00\n\n\n61.00\n\n\n65.00\n\n\n78.00\n\n\n109.00\n\n\n▇▅▅▂▂\n\n\n\n\naltura\n\n\n0\n\n\n1.00\n\n\n1.77\n\n\n0.12\n\n\n1.58\n\n\n1.70\n\n\n1.75\n\n\n1.84\n\n\n1.98\n\n\n▆▇▆▃▃\n\n\n\n\ncolesterol\n\n\n1\n\n\n0.93\n\n\n220.23\n\n\n39.85\n\n\n148.00\n\n\n194.00\n\n\n210.00\n\n\n249.00\n\n\n280.00\n\n\n▂▇▂▅▅\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 4\n\n\n\n\n\nUsando las funciones descr y dfSummary del paquete summarytools.\n\nlibrary(summarytools)\ndescr(df) |&gt;\nkable() |&gt;\nkable_styling()\n\n\n\n\naltura\ncolesterol\nedad\npeso\n\n\n\nMean\n1.7685714\n220.2307692\n38.2142857\n70.9230769\n\n\nStd.Dev\n0.1150155\n39.8479482\n15.6213787\n16.1269006\n\n\nMin\n1.5800000\n148.0000000\n18.0000000\n51.0000000\n\n\nQ1\n1.7000000\n194.0000000\n24.0000000\n61.0000000\n\n\nMedian\n1.7550000\n210.0000000\n35.0000000\n65.0000000\n\n\nQ3\n1.8500000\n249.0000000\n51.0000000\n78.0000000\n\n\nMax\n1.9800000\n280.0000000\n68.0000000\n109.0000000\n\n\nMAD\n0.1111950\n41.5128000\n17.7912000\n14.8260000\n\n\nIQR\n0.1350000\n55.0000000\n25.0000000\n17.0000000\n\n\nCV\n0.0650330\n0.1809372\n0.4087837\n0.2273858\n\n\nSkewness\n0.2052057\n-0.0022401\n0.3238511\n0.9149779\n\n\nSE.Skewness\n0.5973799\n0.6163361\n0.5973799\n0.6163361\n\n\nKurtosis\n-0.9852205\n-1.2502343\n-1.2886761\n-0.1208155\n\n\nN.Valid\n14.0000000\n13.0000000\n14.0000000\n13.0000000\n\n\nPct.Valid\n100.0000000\n92.8571429\n100.0000000\n92.8571429\n\n\n\n\nprint(dfSummary(df, plain.ascii = FALSE, style = \"grid\"), method = \"render\")\n\n\nData Frame Summary\ndf\nDimensions: 14 x 6\n  Duplicates: 0\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n1\nnombre [character]\n\n\n1. Antonio Fernández Ocaña\n\n\n2. Antonio Ruiz Cruz\n\n\n3. Carmen López Pinzón\n\n\n4. Carolina Rubio Moreno\n\n\n5. Javier García Sánchez\n\n\n6. José Luis Martínez Izquie\n\n\n7. José María de la Guía San\n\n\n8. Macarena Álvarez Luna\n\n\n9. Marisa López Collado\n\n\n10. Miguel Angel Cuadrado Gut\n\n\n[ 4 others ]\n\n\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n1\n(\n7.1%\n)\n\n\n4\n(\n28.6%\n)\n\n\n\n14 (100.0%)\n0 (0.0%)\n\n\n2\nedad [integer]\n\n\nMean (sd) : 38.2 (15.6)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 35 ≤ 68\n\n\nIQR (CV) : 25 (0.4)\n\n\n12 distinct values\n\n14 (100.0%)\n0 (0.0%)\n\n\n3\nsexo [character]\n\n\n1. H\n\n\n2. M\n\n\n\n\n8\n(\n57.1%\n)\n\n\n6\n(\n42.9%\n)\n\n\n\n14 (100.0%)\n0 (0.0%)\n\n\n4\npeso [numeric]\n\n\nMean (sd) : 70.9 (16.1)\n\n\nmin ≤ med ≤ max:\n\n\n51 ≤ 65 ≤ 109\n\n\nIQR (CV) : 17 (0.2)\n\n\n12 distinct values\n\n13 (92.9%)\n1 (7.1%)\n\n\n5\naltura [numeric]\n\n\nMean (sd) : 1.8 (0.1)\n\n\nmin ≤ med ≤ max:\n\n\n1.6 ≤ 1.8 ≤ 2\n\n\nIQR (CV) : 0.1 (0.1)\n\n\n14 distinct values\n\n14 (100.0%)\n0 (0.0%)\n\n\n6\ncolesterol [numeric]\n\n\nMean (sd) : 220.2 (39.8)\n\n\nmin ≤ med ≤ max:\n\n\n148 ≤ 210 ≤ 280\n\n\nIQR (CV) : 55 (0.2)\n\n\n13 distinct values\n\n13 (92.9%)\n1 (7.1%)\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-02-15\n\n\n\n\n\n\n\n\n¿En qué variable es más representativa la media?\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nUsando la función sumtable del paquete vtable.\n\nlibrary(vtable)\nsumtable(df, summ = c('mean(x)', 'sd(x)', 'sd(x)/mean(x)'),\nsumm.names = c(\"Media\", \"Desviación Típica\", \"Coef. Variación\"))\n\nWarning in sumtable(df, summ = c(\"mean(x)\", \"sd(x)\", \"sd(x)/mean(x)\"), summ.names = c(\"Media\", : Factor variables ignore custom summ options. Cols 1 and 2 are count and percentage.\nBeware combining factors with a custom summ unless factor.numeric = TRUE.\n\n\n\nSummary Statistics\n\nVariable\nMedia\nDesviación Típica\nCoef. Variación\n\n\n\nedad\n38\n16\n0.41\n\n\nsexo\n14\n\n\n\n\n... H\n8\n57%\n\n\n\n... M\n6\n43%\n\n\n\npeso\n71\n16\n0.23\n\n\naltura\n1.8\n0.12\n0.065\n\n\ncolesterol\n220\n40\n0.18\n\n\n\n\n\nLa variable con el coeficiente de variación más pequeño es la altura, por lo que es la que tiene la media más representativa.\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nUsando las funciones summarise y across del paquete dplyr.\n\nlibrary(dplyr)\nsummarise(df, across(.cols = where(is.numeric), .fns = list(Media = ~ mean(.x, na.rm = T), `Desviación Típica` = ~ sd(.x, na.rm = T), `Coef. Variación` = ~ sd(.x, na.rm=T) / mean(.x, na.rm=T)))) |&gt;\nkable() |&gt;\nkable_styling()\n\n\n\nedad_Media\nedad_Desviación Típica\nedad_Coef. Variación\npeso_Media\npeso_Desviación Típica\npeso_Coef. Variación\naltura_Media\naltura_Desviación Típica\naltura_Coef. Variación\ncolesterol_Media\ncolesterol_Desviación Típica\ncolesterol_Coef. Variación\n\n\n38.21429\n15.62138\n0.4087837\n70.92308\n16.1269\n0.2273858\n1.768571\n0.1150155\n0.065033\n220.2308\n39.84795\n0.1809372\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 3\n\n\n\n\n\nUsando las funciones group_by y summarise del paquete dplyr y pivotando el data frame a formato largo.\n\nlibrary(tidyverse)\ndf |&gt; select(where(is.numeric)) |&gt; \n    pivot_longer(everything(), names_to = \"Variable\", values_to = \"Valor\") |&gt;\n    group_by(Variable) |&gt;\n    summarise(\"Media\" = mean(Valor, na.rm = T), \n    \"Desviación Típica\" = sd(Valor, na.rm = T),\n    \"Coef. Variación\" = sd(Valor, na.rm = T) / mean(Valor, na.rm = T)) |&gt;\n    kable() |&gt;\n    kable_styling()\n\n\n\nVariable\nMedia\nDesviación Típica\nCoef. Variación\n\n\n\naltura\n1.768571\n0.1150155\n0.0650330\n\n\ncolesterol\n220.230769\n39.8479482\n0.1809372\n\n\nedad\n38.214286\n15.6213787\n0.4087837\n\n\npeso\n70.923077\n16.1269006\n0.2273858\n\n\n\n\n\nLa variable con el coeficiente de variación más pequeño es la altura, por lo que es la que tiene la media más representativa.\n\n\n\n\n\nRealizar un resumen estadístico con el coeficiente de asimetría y el coeficiente de apuntamiento del peso y la estatura según el sexo. ¿Qué grupo tiene peso más normal, los hombres o las mujeres? ¿Y una estatura más normal?\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nUsando la función sumtable del paquete vtable.\n\nlibrary(vtable)\nsumtable(df, vars = c(\"peso\", \"altura\"), group = \"sexo\", summ = c('skewness(x)', 'kurtosis(x)'),\nsumm.names = c(\"Coef. Asimetría\", \"Coef. Apuntamiento\"))\n\nWarning in sumtable(df, vars = c(\"peso\", \"altura\"), group = \"sexo\", summ = c(\"skewness(x)\", : Factor variables ignore custom summ options. Cols 1 and 2 are count and percentage.\nBeware combining factors with a custom summ unless factor.numeric = TRUE.\n\n\n\nSummary Statistics\n\n\n\n\n\n\n\n\n\n\nsexo\n\n\nH\n\n\nM\n\n\n\nVariable\nCoef. Asimetría\nCoef. Apuntamiento\nCoef. Asimetría\nCoef. Apuntamiento\n\n\n\n\npeso\n0.61\n2.5\n-0.47\n1.9\n\n\naltura\n0.27\n1.9\n-0.07\n1.8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nUsando las funciones group_by y summarise del paquete dplyr.\n\nlibrary(dplyr)\ndf |&gt; select(sexo, peso, altura) |&gt;\ngroup_by(sexo) |&gt;\nsummarise(across(.cols = everything(), .fns = list(\"Coef. Asimetría\" = ~ skewness(.x, na.rm = T), \"Coef. Apuntamiento\" = ~ kurtosis(.x, na.rm = T)))) |&gt;\nkable() |&gt;\nkable_styling()\n\n\n\nsexo\npeso_Coef. Asimetría\npeso_Coef. Apuntamiento\naltura_Coef. Asimetría\naltura_Coef. Apuntamiento\n\n\n\nH\n0.6107239\n2.508255\n0.2668417\n1.904435\n\n\nM\n-0.4661293\n1.852431\n-0.0699589\n1.756341\n\n\n\n\n\nLas mujeres tienen un peso más normal ya que tanto el coeficiente de asimetría como el de apuntamiento están más próximos a 0. Lo mismo ocurre con la altura.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estadística Descriptiva</span>"
    ]
  },
  {
    "objectID": "04-descriptiva.html#ejercicios-propuestos",
    "href": "04-descriptiva.html#ejercicios-propuestos",
    "title": "\n4  Estadística Descriptiva\n",
    "section": "\n4.2 Ejercicios propuestos",
    "text": "4.2 Ejercicios propuestos\n\nEjercicio 4.3 El fichero renta-media-comunidades-autonomas.csv contiene información sobre la renta neta media por persona de las comunidades autónomas desde 2008 a 2021.\n\n\nCrear un data frame con los datos de las rentas medias por persona de las comunidades a partir del fichero renta-media-comunidades-autonomas.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 19 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): Comunidad\ndbl (14): 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\nRows: 19 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): Comunidad\ndbl (14): 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\nRows: 19 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): Comunidad\ndbl (14): 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndf &lt;- read_csv2(\"https://aprendeconalf.es/estadistica-practicas-r/datos/renta-media-comunidades-autonomas.csv\")\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 19 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): Comunidad\ndbl (14): 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf\n\n# A tibble: 19 × 15\n   Comunidad      `2021` `2020` `2019` `2018` `2017` `2016` `2015` `2014` `2013`\n   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Andalucía        9915   9990   9160   9258   9116   8398   7942   8079   8408\n 2 Aragón          13345  13097  12300  11990  12110  11649  12427  12037  12022\n 3 Asturias Prin…  12861  12786  12523  12085  12244  12060  11427  11251  11211\n 4 Balears Illes   11235  12658  12410  13240  12665  12222  10828  10660  10386\n 5 Canarias        10161   9935   9487   8964   8863   8702   8640   8302   8513\n 6 Cantabria       12848  12748  12205  11239  11293  10670  10494   9824   9843\n 7 Castilla y Le…  12656  12697  12003  11949  11239  10815  10570  10406  10760\n 8 Castilla - La…  10257  10485   9715   9533   9045   8731   8498   8545   8425\n 9 Cataluña        14159  14170  13527  13338  12712  12660  12283  12205  12111\n10 Comunitat Val…  11237  11332  10611  10232   9801   9265   9098   9144   9375\n11 Extremadura      9500   9147   8796   8503   8250   8674   8469   7729   8224\n12 Galicia         11453  11469  11218  11239  10753  10439  10212  10235  10106\n13 Madrid Comuni…  14836  14580  14199  13279  13099  12647  12534  12597  12823\n14 Murcia Región…   9931   9850   8956   9111   8702   8273   7924   7767   8253\n15 Navarra Comun…  15269  15094  13937  13585  13583  13408  13300  13221  13608\n16 País Vasco      15544  15813  15300  14722  14397  14345  13836  14281  14312\n17 Rioja La        12913  13504  12697  12029  12131  11589  11132  11120  10686\n18 Ceuta           10397   9853  10164   9784   9676   9435   8512   8712   9336\n19 Melilla         12012  11427  11733  12507  10161  10883  10027  11619  11313\n# ℹ 5 more variables: `2012` &lt;dbl&gt;, `2011` &lt;dbl&gt;, `2010` &lt;dbl&gt;, `2009` &lt;dbl&gt;,\n#   `2008` &lt;dbl&gt;\n\n\n\n\n\n\nRealizar un resumen estadístico con la media y la desviación típica, mínimo, cuartiles y máximo de todas las rentas medias.\nRealizar un resumen estadístico con la media y la desviación típica de las rentas medias de cada año.\n¿Qué año presenta una menor variabilidad relativa?\n¿En qué comunidad autónoma hay menos dispersión relativa con respecto a la media?\n¿En qué comunidad autónoma es más representativa la media de las rentas?\n¿Qué comunidad autónoma presenta una distribución de las rentas más normal a lo largo de los años?\n¿Qué comunidades autónomas tienen una renta media por debajo del percentil 10? ¿Y cuáles tienen una renta media por encima del percentil 90?\nCrear la variable riqueza que clasifique las comunidades según la media de sus rentas en baja (por debajo del primer cuartil), media (entre el primer y el tercer cuartil) y alta (por encima del tercer cuartil).\nHacer un resumen estadístico con la media, cuartiles, desviación típica, coeficiente de variación, coeficiente de asimetría y coeficiente de curtosis de las rentas medias según la riqueza.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estadística Descriptiva</span>"
    ]
  },
  {
    "objectID": "05-regresion.html",
    "href": "05-regresion.html",
    "title": "\n5  Regresión\n",
    "section": "",
    "text": "5.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:\nTambién se necesita conocer las ecuaciones de los principales modelos de regresión, que se resumen en la siguiente tabla.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regresión</span>"
    ]
  },
  {
    "objectID": "05-regresion.html#ejercicios-resueltos",
    "href": "05-regresion.html#ejercicios-resueltos",
    "title": "\n5  Regresión\n",
    "section": "",
    "text": "library(tidyverse) \n# Incluye los siguientes paquetes:\n# - readr: para la lectura de ficheros csv. \n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - tidyr: para la organización de los datos.\n# - purrr: para aplicar funciones a vectores. \nlibrary(broom) # para convertir las listas con los resúmenes de los modelos de regresión a formato organizado.\nlibrary(knitr) # para el formateo de tablas.\nlibrary(kableExtra) # para personalizar el formato de las tablas.\n\n\n\nModelo\nEcuación general\n\n\n\nLineal\n\\(y=a+bx\\)\n\n\nParabólico\n\\(y=a+bx+cx^2\\)\n\n\nPolinómico de grado \\(n\\)\n\n\\(y=a_0+a_1x+\\cdots+a_nx^n\\)\n\n\nPotencial\n\\(y=ax^b\\)\n\n\nExponencial\n\\(y=e^{a+bx}\\)\n\n\nLogarítmico\n\\(y=a+b\\log x\\)\n\n\nInverso\n\\(y=a+b/x\\)\n\n\nCurva S o Sigmoidal\n\\(y= e^{a+b/x}\\)\n\n\n\n\nEjercicio 5.1 Se han medido dos variables \\(X\\) e \\(Y\\) en 10 individuos obteniendo los siguientes resultados:\n\\[\n\\begin{array}{lrrrrrrrrrr}\n\\hline\nX & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\\\\nY & 2 & 5 & 8 & 11 & 14 & 17 & 20 & 23 & 26 & 29\\\\\n\\hline\n\\end{array}\n\\]\n\n\nCrear un conjunto de datos con las variables x e y.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(\n    x = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9),\n    y = c(2, 5, 8, 11, 14, 17, 20, 23, 26, 29)\n)\n\n\n\n\n\n\nDibujar el diagrama de dispersión correspondiente. ¿Qué tipo de modelo de regresión se ajusta mejor a la nube de puntos?\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar un diagrama de dispersión se puede usar la función plot del paquete graphics.\n\nplot(df$x, df$y, xlab = \"X\", ylab = \"Y\", main = \"Diagrama de dispersión\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la función la función geom_point del paquete ggplot2.\n\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = y)) +\n    geom_point(col = \"red\") +\n    labs(title = \"Diagrama de dispersión\", x = \"X\", y = \"Y\")\n\n\n\n\n\n\n\nEl tipo de modelo que mejor se ajusta es lineal, ya que todos los puntos están alineados.\n\n\n\n\n\nCalcular la recta de regresión de \\(Y\\) sobre \\(X\\).\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara ajustar un modelo de regresión se utiliza la función lm del paquete stats. Esta función requiere que se le pase como parámetro la fórmula del modelo de regresión que debe tener la sintaxis y ~ f(x), donde y es la variable dependiente en el modelo, x es la variable independiente, y f(x) es una expresión matemática que describe el modelo.\n\nrecta_y_x &lt;- lm(y ~ x, df) \nsummary(recta_y_x)\n\nWarning in summary.lm(recta_y_x): essentially perfect fit: summary may be\nunreliable\n\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-3.675e-15 -8.783e-16  5.168e-16  9.646e-16  1.944e-15 \n\nCoefficients:\n             Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) 2.000e+00  1.049e-15 1.906e+15   &lt;2e-16 ***\nx           3.000e+00  1.965e-16 1.527e+16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.785e-15 on 8 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 2.33e+32 on 1 and 8 DF,  p-value: &lt; 2.2e-16\n\n\nLa recta de regresión de \\(Y\\) sobre \\(X\\) es \\(y = 2 + 3 x\\).\n\n\n\n\n\nObtener el coeficiente de regresión de la recta anterior e interpretarlo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl coeficiente de regresión es la pendiente de la recta de regresión\n\ncat(paste(\"Coeficiente de regresión de Y sobre X:\", recta_y_x$coefficients[[\"x\"]]))\n\nCoeficiente de regresión de Y sobre X: 3\n\n\nEl coeficiente de regresión de \\(Y\\) sobre \\(X\\) vale 3, lo que indica que \\(Y\\) aumenta 3 unidades por cada unidad que aumenta \\(X\\).\n\n\n\n\n\nDibujar la recta de regresión de \\(Y\\) sobre \\(X\\) sobre el diagrama de dispersión. ¿Cómo son los residuos del modelo de regresión?\n\n\n\n\n\n\nSolución 1\n\n\n\n\n\nPara dibujar la recta de regresión se puede usar la función abline del paquete graphics.\n\nplot(df$x, df$y, xlab = \"X\", ylab = \"Y\", main = \"Diagrama de dispersión\")\nabline(recta_y_x)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución 2\n\n\n\n\n\nOtra alternativa es usar la geometría de ajuste de regresión por mínimos cuadrados geom_smooth del paquete ggplot2.\n\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = y)) +\n    geom_point(col = \"red\") +\n    geom_smooth(method = \"lm\") +\n    labs(title = \"Diagrama de dispersión\", x = \"X\", y = \"Y\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nComo la recta pasa por todos los puntos del diagrama de dispersión, los residuos son nulos.\n\n\n\n\n\nCalcular el coeficiente de determinación del modelo lineal e interpretarlo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste(\"Coeficiente de determinación lineal R²:\", summary(recta_y_x)$r.squared))\n\nWarning in summary.lm(recta_y_x): essentially perfect fit: summary may be\nunreliable\n\n\nCoeficiente de determinación lineal R²: 1\n\n\nComo el coeficiente de determinación lineal vale 1, el ajuste de la recta de regresión es perfecto.\n\n\n\n\n\nCalcular la recta de regresión de \\(X\\) sobre \\(Y\\). ¿Coincide con la recta de regresión de \\(Y\\) sobre \\(X\\)?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nrecta_x_y &lt;- lm(x ~ y, df) \nsummary(recta_x_y)\n\nWarning in summary.lm(recta_x_y): essentially perfect fit: summary may be\nunreliable\n\n\n\nCall:\nlm(formula = x ~ y, data = df)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-1.435e-15 -5.090e-16 -2.062e-17  3.798e-16  1.943e-15 \n\nCoefficients:\n              Estimate Std. Error    t value Pr(&gt;|t|)    \n(Intercept) -6.667e-01  6.179e-16 -1.079e+15   &lt;2e-16 ***\ny            3.333e-01  3.484e-17  9.567e+15   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.494e-16 on 8 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 9.153e+31 on 1 and 8 DF,  p-value: &lt; 2.2e-16\n\n\nLa recta de regresión de \\(X\\) sobre \\(Y\\) es \\(x = -0.6666667 + 0.3333333 x\\), que es la misma que la recta de \\(Y\\) sobre \\(X\\), ya que el ajuste es perfecto, y tanto los residuos en \\(Y\\) como los residuos en \\(X\\) valen cero para esta recta.\n\n\n\n\n\n\n\nEjercicio 5.2 El fichero horas-estudio.csv contiene información sobre las horas de estudio diarias de una muestra de alumnos de ingeniería, y el número de asignaturas suspendidas al final del curso.\n\n\nCrear un data frame con los datos de las horas de estudio y los suspensos a partir del fichero horas-estudio.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(readr)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/horas-estudio.csv\")\n\nRows: 30 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): Horas, Suspensos\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf\n\n# A tibble: 30 × 2\n   Horas Suspensos\n   &lt;dbl&gt;     &lt;dbl&gt;\n 1   3.5         1\n 2   0.6         5\n 3   2.8         1\n 4   2.5         3\n 5   2.6         1\n 6   3.9         0\n 7   1.5         3\n 8   0.7         3\n 9   3.6         1\n10   3.7         1\n# ℹ 20 more rows\n\n\n\n\n\n\n\nDibujar el diagrama de dispersión correspondiente. ¿Qué tipo de modelo de regresión se ajusta mejor a la nube de puntos?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = Horas, y = Suspensos)) +\n    geom_point(col = \"red\") +\n    labs(title = \"Diagrama de dispersión\", x = \"Horas de estudio\", y = \"Asignaturas suspensas\")\n\n\n\n\n\n\n\nEl tipo de modelo que mejor se ajusta es lineal, ya que hay una tendencia lineal en la nube de puntos y además es inversa.\n\n\n\n\n\nCalcular la recta de regresión de los suspensos sobre las horas de estudio.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nrecta_suspensos_horas &lt;- lm(Suspensos ~ Horas, df) \nsummary(recta_suspensos_horas)\n\n\nCall:\nlm(formula = Suspensos ~ Horas, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.03614 -0.53214 -0.02013  0.49187  1.22587 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.8491     0.2622   18.49  &lt; 2e-16 ***\nHoras        -1.2300     0.1106  -11.12  8.7e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6359 on 28 degrees of freedom\nMultiple R-squared:  0.8155,    Adjusted R-squared:  0.8089 \nF-statistic: 123.8 on 1 and 28 DF,  p-value: 8.7e-12\n\n\nLa recta de regresión de los suspensos sobre las horas es \\(\\textsf{suspensos}= 4.8491273 + -1.2299972 \\textsf{horas}\\).\n\n\n\n\n\nObtener el coeficiente de regresión de la recta anterior e interpretarlo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste(\"Coeficiente de regresión de Suspensos sobre Horas:\", recta_suspensos_horas$coefficients[[\"Horas\"]]))\n\nCoeficiente de regresión de Suspensos sobre Horas: -1.22999717844331\n\n\nEl coeficiente de regresión de los suspensos sobre las horas de estudio vale -1.2299972, lo que indica que por cada hora de estudio se obtendrán 1.2299972 suspensos menos al final del curso.\n\n\n\n\n\nDibujar la recta de regresión sobre el diagrama de dispersión. ¿El ajuste es mejor o peor que el del ejercicio anterior?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = Horas, y = Suspensos)) +\n    geom_point(col = \"red\") +\n    geom_smooth(method = \"lm\") +\n    labs(title = \"Diagrama de dispersión\", x = \"Horas de estudio\", y = \"Asignaturas suspensas\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nEn este caso el ajuste no es perfecto, ya que es imposible que la recta pase por todos los puntos como ocurría en el ejercicio anterior. Por tanto, el ajuste es peor.\n\n\n\n\n\nCalcular el coeficiente de determinación del modelo lineal e interpretarlo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste(\"Coeficiente de determinación lineal R²:\", summary(recta_suspensos_horas)$r.squared))\n\nCoeficiente de determinación lineal R²: 0.81549948723949\n\n\nComo el coeficiente de determinación lineal vale 0.8154995 que está bastante próximo a 1, el ajuste es bueno, y el modelo puede utilizarse con fines predictivos.\n\n\n\n\n\nUtilizar la recta de regresión para predecir el número de suspensos correspondiente a 3 horas de estudio diarias. ¿Es fiable esta predicción?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\npredict.lm(recta_suspensos_horas, newdata = list(Horas = 3))\n\n       1 \n1.159136 \n\n\nLa predicción será fiable ya que el coeficiente de determinación está próximo a 1 y el tamaño de la muestra no es muy pequeño.\n\n\n\n\n\nSegún el modelo lineal, ¿cuántas horas diarias tendrá que estudiar como mínimo un alumno si quiere aprobarlo todo?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo ahora queremos predecir el número de horas de estudio, necesitamos calcular la recta de regresión de la horas sobre los suspensos.\n\nrecta_horas_suspensos &lt;- lm(Horas ~ Suspensos, df) \npredict.lm(recta_horas_suspensos, newdata = list(Suspensos = 0))\n\n       1 \n3.607387 \n\n\n\n\n\n\n\n\n\nEjercicio 5.3 Después de tomar un litro de vino se ha medido la concentración de alcohol en la sangre en distintos instantes, obteniendo los siguientes datos\n\\[\n\\begin{array}{lrrrrrrr}\n\\hline\n\\mbox{Tiempo después (minutos)} & 30 & 60 & 90 & 120 & 150 & 180 & 210\\\\\n\\mbox{Alcohol (gramos/litro)} & 1.6 & 1.7 & 1.5 & 1.1 & 0.7 & 0.2 & 2.1\\\\\n\\hline\n\\end{array}\n\\]\n\n\nCrear un data frame con los datos del tiempo y la concentración de alcohol.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(\n    Tiempo = c(30, 60, 90, 120, 150, 180, 210),\n    Alcohol = c(1.6, 1.7, 1.5, 1.1, 0.7, 0.2, 2.1)\n)\ndf\n\n  Tiempo Alcohol\n1     30     1.6\n2     60     1.7\n3     90     1.5\n4    120     1.1\n5    150     0.7\n6    180     0.2\n7    210     2.1\n\n\n\n\n\n\n\nCalcular el coeficiente de correlación lineal. ¿Existe relación lineal entre la concentración de alcohol y el tiempo que pasa?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular el coeficiente de correlación lineal de Pearson se puede utilar la función cor del paquete stats.\n\ncor(df$Tiempo, df$Alcohol)\n\n[1] -0.2730367\n\n\nEl valore del coeficiente de correlación lineal es muy bajo, por lo que aparentemente no hay relación lineal entre la concentración de alcohol en sangre y el tiempo que pasa.\n\n\n\n\n\nDibujar el diagrama de dispersión correspondiente y la recta de regresión de la concentración de alcohol sobre el tiempo. ¿Por qué el ajuste es tan malo?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = Tiempo, y = Alcohol)) +\n    geom_point(col = \"red\") +\n    geom_smooth(method = \"lm\") +\n    labs(title = \"Diagrama de dispersión\", x = \"Tiempo en minutos\", y = \"Concentración de alcohol en sangre (g/l)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nEl ajuste es malo porque hay un dato atípico que no sigue la misma tendencia que el resto.\n\n\n\n\n\nEliminar el dato atípico y calcular la recta de la concentración de alcohol sobre el tiempo. ¿Ha mejorado el modelo?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Eliminamos el dato atípico que está en la fila \ndf &lt;- df[-c(7), ]\nrecta_alcohol_tiempo &lt;- lm(Alcohol ~ Tiempo, df) \nsummary(recta_alcohol_tiempo)\n\n\nCall:\nlm(formula = Alcohol ~ Tiempo, data = df)\n\nResiduals:\n       1        2        3        4        5        6 \n-0.27619  0.12095  0.21810  0.11524  0.01238 -0.19048 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.173333   0.201927  10.763 0.000423 ***\nTiempo      -0.009905   0.001728  -5.731 0.004591 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2169 on 4 degrees of freedom\nMultiple R-squared:  0.8914,    Adjusted R-squared:  0.8643 \nF-statistic: 32.84 on 1 and 4 DF,  p-value: 0.004591\n\n\nLa recta de regresión de la concentración de alcohol en sangre sobre el tiempo es \\(\\textsf{alcohol}= 2.1733333 + -0.0099048 \\textsf{tiempo}\\).\nEl modelo ha mejorado notablemente ya que ahora el coeficiente de determinación lineal \\(R^2=0.8914286\\), que está muy próximo a 1.\n\n\n\n\n\nSegún el modelo de regresión lineal, ¿a qué velocidad metaboliza esta persona el alcohol?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste(\"Coeficiente de regresión de la concentración de alchol sobre el tiempo:\", recta_alcohol_tiempo$coefficients[[\"Tiempo\"]]))\n\nCoeficiente de regresión de la concentración de alchol sobre el tiempo: -0.00990476190476191\n\n\nAsí pues, la velocidad de metabolización del alcohol es 0.0099048 g/l\\(\\cdot\\)min.\n\n\n\n\n\nSi la concentración máxima de alcohol en la sangre que permite la ley para poder conducir es \\(0.3\\) g/l, ¿cuánto tiempo habrá que esperar después de tomarse un litro de vino para poder conducir sin infringir la ley? ¿Es fiable esta predicción?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo ahora queremos predecir el tiempo, necesitamos calcular la recta de regresión del tiempo sobre la concentración de alcohol.\n\nrecta_tiempo_alcohol &lt;- lm(Tiempo ~ Alcohol, df) \npredict.lm(recta_tiempo_alcohol, newdata = list(Alcohol = 0.3))\n\n  1 \n180 \n\n\nAunque el coeficiente de determinación lineal está próximo a 1, el tamaño muestral es demasiado pequeño para que la predicción sea fiable.\n\n\n\n\n\n\n\nEjercicio 5.4 El fichero pib-usa.csv contiene información sobre el producto interior bruto de Estados Unidos en billones de dólares americanos desde 1947 hasta 2022.\n\n\nCrear un data frame con los datos del PIB y los años a partir del fichero pib-usa.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(readr)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/pib-usa.csv\")\n\nRows: 76 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): Año, PIB\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf\n\n# A tibble: 76 × 2\n     Año   PIB\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  1947  244.\n 2  1948  267.\n 3  1949  276.\n 4  1950  282.\n 5  1951  338.\n 6  1952  362.\n 7  1953  390.\n 8  1954  387.\n 9  1955  415.\n10  1956  443.\n# ℹ 66 more rows\n\n\n\n\n\n\n\nDibujar el diagrama de dispersión que represente la evolución anual del PIB. ¿Qué tipo de modelo de regresión se ajusta mejor a la nube de puntos?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = Año, y = PIB)) +\n    geom_point(col = \"red\") +\n    labs(title = \"Evolución del PIB de Estados Unidos\", x = \"Año\", y = \"PIB en billones dólares\")\n\n\n\n\n\n\n\nA la vista de la forma de la nube de puntos parece que la evolución del PIB es exponencial.\n\n\n\n\n\nDibujar el diagrama de dispersión del logaritmo del PIB y los años.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(dplyr)\ndf &lt;- mutate(df, logPIB = log(PIB)) \nggplot(df, aes(x = Año, y = logPIB)) +\n        geom_point(col = \"red\") +\n        labs(title = \"Evolución del PIB de Estados Unidos\", x = \"Año\", y = \"Logaritmo del PIB en billones dólares\")\n\n\n\n\n\n\n\nLa nube de puntos tienen una clara forma lineal, lo que confirma que la evolución del PIB es exponencial.\n\n\n\n\n\nCalcular el modelo de regresión exponencial del PIB sobre los años.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nrecta_logPIB_años &lt;- lm(log(PIB) ~ Año, df) \nsummary(recta_logPIB_años)\n\n\nCall:\nlm(formula = log(PIB) ~ Año, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.39115 -0.13495 -0.03532  0.17693  0.29436 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.215e+02  1.951e+00  -62.27   &lt;2e-16 ***\nAño          6.527e-02  9.832e-04   66.39   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.188 on 74 degrees of freedom\nMultiple R-squared:  0.9835,    Adjusted R-squared:  0.9833 \nF-statistic:  4407 on 1 and 74 DF,  p-value: &lt; 2.2e-16\n\n\nEl modelo de regresión exponencial que mejor explica la evolución del PIB es \\(\\textsf{PIB}= e^{-121.4998223 + 0.065271 \\textsf{Año}}\\).\n\n\n\n\n\n¿Cuál es la tasa de crecimiento porcentual anual del PIB?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste(\"Coeficiente de regresión del logaritmo del PIB sobre los años:\", recta_logPIB_años$coefficients[[\"Año\"]]))\n\nCoeficiente de regresión del logaritmo del PIB sobre los años: 0.0652710244896027\n\n\nEl coeficiente de regresión de los suspensos sobre las horas de estudio vale 0.065271, lo que indica que la tasa de crecimiento anual del PIB es 6.5271024%.\n\n\n\n\n\nDibujar el modelo de regresión exponencial sobre el diagrama de dispersión.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = Año, y = PIB)) +\n        geom_point(col = \"red\") +\n        geom_smooth(method = \"glm\", method.args = list(family=gaussian(link=\"log\")))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n        labs(title = \"Evolución del PIB de Estados Unidos\", x = \"Año\", y = \"Logaritmo del PIB en billones dólares\")\n\n$x\n[1] \"Año\"\n\n$y\n[1] \"Logaritmo del PIB en billones dólares\"\n\n$title\n[1] \"Evolución del PIB de Estados Unidos\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nEn este caso el ajuste no es perfecto, ya que es imposible que la recta pase por todos los puntos como ocurría en el ejercicio anterior. Por tanto, el ajuste es peor.\n\n\n\n\n\n¿Es el modelo de regresión exponencial un buen modelo para explicar la evolución del PIB?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste(\"Coeficiente de determinación exponencial R²:\", summary(recta_logPIB_años)$r.squared))\n\nCoeficiente de determinación exponencial R²: 0.983487569858149\n\n\nComo el coeficiente de determinación lineal vale 0.9834876 que está bastante próximo a 1, el ajuste es bueno, y el modelo exponencial explica muy bien la evolución del PIB.\n\n\n\n\n\nUtilizar el modelo de regresión exponencial para predecir el PIB del año 2024. ¿Es fiable esta predicción?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# El modelo exponencial devuelve el logaritmo del PIB, por lo que hay que aplicar la función exponencial para obtener el PIB.\nexp(predict.lm(recta_logPIB_años, newdata = list(Año = 2024)))\n\n      1 \n40486.8 \n\n\nLa predicción será fiable ya que el coeficiente de determinación está próximo a 1, el tamaño de la muestra no es muy pequeño y el año para el que se realiza la predicción no está lejos del rango de años de la muestra.\n\n\n\n\n\n¿Cuándo se alcanzará un PIB de 50000 billones de dólares?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo ahora queremos predecir el año en el que se alcanzará el PIB dado, necesitamos construir el modelo de regresión de los años sobre el PIB. Como la relación entre el PIB y los años es exponencial, la relación entre los años y el PIB será la inversa, es decir, el modelo logarítmico.\n\nlog_años_PIB &lt;- lm(Año ~ log(PIB), df) \nsummary(log_años_PIB)\n\n\nCall:\nlm(formula = Año ~ log(PIB), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.4049 -2.5367  0.2662  1.7718  6.4965 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1863.498      1.852 1006.29   &lt;2e-16 ***\nlog(PIB)      15.068      0.227   66.39   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.857 on 74 degrees of freedom\nMultiple R-squared:  0.9835,    Adjusted R-squared:  0.9833 \nF-statistic:  4407 on 1 and 74 DF,  p-value: &lt; 2.2e-16\n\n\nEl modelo de regresión logarítmico de los años sobre el PIB es \\(\\textsf{Año}= 1863.4980331 + 15.0677514 \\log(\\textsf{PIB})\\).\n\npredict.lm(log_años_PIB, newdata = list(PIB = 50000))\n\n       1 \n2026.528 \n\n\n\n\n\n\n\n\n\nEjercicio 5.5 El fichero dieta.csv contiene información sobre el los kilos perdidos con una dieta de adelgazamiento.\n\n\nCrear un data frame con los datos de la dieta a partir del fichero dieta.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(readr)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/dieta.csv\")\n\nRows: 40 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): ejercicio\ndbl (2): dias, peso.perdido\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf\n\n# A tibble: 40 × 3\n    dias peso.perdido ejercicio\n   &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;    \n 1    14         2.95 no       \n 2    18         5.65 no       \n 3    22         6.56 no       \n 4    26         3.56 no       \n 5    30         6.17 no       \n 6    34         9.4  no       \n 7    38        12.4  no       \n 8    42        12.9  no       \n 9    46        13.9  no       \n10    50        10.8  no       \n# ℹ 30 more rows\n\n\n\n\n\n\n\nDibujar el diagrama de dispersión de los kilos perdidos en función del número de días con la dieta. ¿Qué tipo de modelo de regresión se ajusta mejor a la nube de puntos?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = dias, y = peso.perdido)) +\n    geom_point(col = \"red\") +\n    labs(title = \"Diagrama de dispersión del peso perdido y los días de dieta\", x = \"Días de dieta\", y = \"Peso perdido en Kg\")\n\n\n\n\n\n\n\nLa nube de puntos es bastante difusa aunque parece apreciarse una tendencia logarítmica o sigmoidal.\n\n\n\n\n\nCalcular los coeficientes de determinación lineal, cuadrático, exponencial, logarítmico, potencial, inverso y sigmoidal. ¿Qué tipo de modelo explica mejor la relación entre los kilos perdidos y el número de días de dieta? ¿Qué porcentaje de la variabilidad de peso perdido explica el mejor modelo de regresión?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(broom)\nlibrary(kableExtra)\n# Construimos un data frame con el ajuste de los modelos.\nmodelos &lt;- tibble(\n        Lineal = list(lm(peso.perdido ~ dias, df)),\n        Cuadratico = list(lm(peso.perdido ~ dias + I(dias^2), df)),\n        Exponencial = list(lm(log(peso.perdido) ~ dias, df)),\n        Logaritmico = list(lm(peso.perdido ~ log(dias), df)),\n        Potencial = list(lm(log(peso.perdido) ~ log(dias), df)),\n        Inverso = list(lm(peso.perdido ~ I(1/dias), df)),\n        Sigmoidal = list(lm(log(peso.perdido) ~ I(1/dias), df)),\n    )  |&gt; \n    # \n    # Reestructuramos el data frame para tener todos los modelos en la misma columna.\n    pivot_longer(everything(), names_to = \"Tipo_Modelo\", values_to = \"Modelo\")  |&gt; \n    # Obtenemos un resumen del ajuste de cada modelo en formato organizado (se obtiene una lista con los parámetros que describen el ajuste de cada modelo).\n    mutate(Resumen = map(Modelo, glance)) |&gt; \n    # Desanidamos el resumen (se obtiene una columna para cada parámetro del resumen del ajuste de los modelos).\n    unnest(Resumen)  |&gt; \n    # Ordenamos el data frame por el coeficiente de determinación.\n    arrange(-r.squared)\n\nmodelos  |&gt;\n    select(Tipo_Modelo, r.squared)  |&gt; \n    kable(col.names = c(\"Tipo de Modelo\", \"R²\")) |&gt;\n    kable_styling(full_width = F)\n\n\n\nTipo de Modelo\nR²\n\n\n\nSigmoidal\n0.6662170\n\n\nPotencial\n0.5684490\n\n\nInverso\n0.5583853\n\n\nCuadratico\n0.5397848\n\n\nLogaritmico\n0.5254856\n\n\nLineal\n0.4356390\n\n\nExponencial\n0.4308936\n\n\n\n\n\nEl mejor modelo es el Sigmoidal que explica el 66.6216965% de la variabilidad del peso perdido.\n\n\n\n\n\nDibujar el diagrama de dispersión de los kilos perdidos en función del número de días con la dieta según si la persona hace ejercicio o no. ¿Qué conclusiones se pueden sacar?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = dias, y = peso.perdido, color = ejercicio)) +\n    geom_point() +\n    labs(title = \"Diagrama de dispersión del peso perdido y los días de dieta\", x = \"Días de dieta\", y = \"Peso perdido en Kg\")\n\n\n\n\n\n\n\nClaramente la nube de puntos de las personas que hacen ejercicio está por encima de la de los que no hacen ejercicio, lo que indica que hacer ejercicio favorece la pérdida de peso. Los más razonable es construir modelos de regresión para cada grupo.\n\n\n\n\n\n¿Qué tipo de modelo explica mejor la relación entre el peso perdido y los días de dieta en el grupo de las personas que hacen ejercicio? ¿Y en el grupo de las que no hacen ejercicio? ¿Han mejorado los modelos con respecto al modelo anterior?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmodelos &lt;- df  |&gt; \n    # Anidamos por la columna ejercicio.\n    nest_by(ejercicio)  |&gt; \n    # Ajustamos los modelos de regresión.\n    mutate(\n        Lineal = list(lm(peso.perdido ~ dias, data)),\n        Cuadratico = list(lm(peso.perdido ~ dias + I(dias^2), data)),\n        Exponencial = list(lm(log(peso.perdido) ~ dias, data)),\n        Logaritmico = list(lm(peso.perdido ~ log(dias), data)),\n        Potencial = list(lm(log(peso.perdido) ~ log(dias), data)),\n        Inverso = list(lm(peso.perdido ~ I(1/dias), data)),\n        Sigmoidal = list(lm(log(peso.perdido) ~ I(1/dias), data)),\n    )  |&gt; \n    # Reestructuramos el data frame para tener todos los modelos en la misma columna.\n    pivot_longer(-c(ejercicio, data), names_to = \"Tipo_Modelo\", values_to = \"Modelo\")  |&gt; \n    # Obtenemos un resumen del ajuste de cada modelo en formato organizado (se obtiene una lista con los parámetros que describen el ajuste de cada modelo).\n    mutate(Resumen = map(Modelo, glance)) |&gt; \n    # Desanidamos el resumen (se obtiene una columna para cada parámetro del resumen del ajuste de los modelos).\n    unnest(Resumen)  |&gt; \n    # Ordenamos el data frame por la columna ejercicio y por el coeficiente de determinación.\n    arrange(ejercicio, -r.squared)  \nmodelos |&gt; \n    select(ejercicio, Tipo_Modelo, r.squared)  |&gt; \n    kable(col.names = c(\"Ejercicio\", \"Tipo de Modelo\", \"R²\")) |&gt;\n    pack_rows(index = table(modelos$ejercicio))  |&gt; \n    kable_styling(full_width = F)\n\n\n\nEjercicio\nTipo de Modelo\nR²\n\n\n\nno\n\n\nno\nSigmoidal\n0.7401212\n\n\nno\nCuadratico\n0.7100610\n\n\nno\nInverso\n0.6796880\n\n\nno\nPotencial\n0.6700051\n\n\nno\nLogaritmico\n0.6494521\n\n\nno\nLineal\n0.5286338\n\n\nno\nExponencial\n0.5222832\n\n\nsi\n\n\nsi\nInverso\n0.8470993\n\n\nsi\nSigmoidal\n0.8305013\n\n\nsi\nLogaritmico\n0.7885173\n\n\nsi\nCuadratico\n0.7791671\n\n\nsi\nPotencial\n0.6704843\n\n\nsi\nLineal\n0.6623502\n\n\nsi\nExponencial\n0.4945564\n\n\n\n\n\nEl mejor modelo en el grupo de los que hacen ejercicio es el inverso y en el grupo de los que no el sigmoidal. Los modelos han mejorado bastante con respecto al modelo anterior, sobre todo el del grupo de personas que hace ejercicio.\n\n\n\n\n\nConstruir el mejor modelo de regresión del peso perdido sobre los días de dieta para el grupo de las personas que hacen ejercicio y para el grupo de las que no.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nConstruimos el modelo inverso para el grupo de las personas que hacen ejercicio.\n\ninverso_ejercicio &lt;- lm(peso.perdido ~ I(1/dias), df[df$ejercicio == \"si\", ])\nsummary(inverso_ejercicio)\n\n\nCall:\nlm(formula = peso.perdido ~ I(1/dias), data = df[df$ejercicio == \n    \"si\", ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1866 -1.3268  0.0011  0.9810  4.1456 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   21.5655     0.7653  28.181 2.42e-16 ***\nI(1/dias)   -255.2249    25.5579  -9.986 9.12e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.811 on 18 degrees of freedom\nMultiple R-squared:  0.8471,    Adjusted R-squared:  0.8386 \nF-statistic: 99.72 on 1 and 18 DF,  p-value: 9.123e-09\n\n\n\nY ahora el modelo sigmoidal para el grupo de las personas que no hacen ejercicio.\n\nsigmoidal_no_ejercicio &lt;- lm(log(peso.perdido) ~ I(1/dias), df[df$ejercicio == \"no\", ])\nsummary(sigmoidal_no_ejercicio)\n\n\nCall:\nlm(formula = log(peso.perdido) ~ I(1/dias), data = df[df$ejercicio == \n    \"no\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.66026 -0.07192  0.04678  0.13142  0.29633 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.8694     0.1021   28.09 2.55e-16 ***\nI(1/dias)   -24.4226     3.4111   -7.16 1.15e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2417 on 18 degrees of freedom\nMultiple R-squared:  0.7401,    Adjusted R-squared:  0.7257 \nF-statistic: 51.26 on 1 and 18 DF,  p-value: 1.146e-06\n\n\n\n\n\n\n\nSegún los mejores modelos de regresión en cada caso, ¿cuántos kilos perderá una persona que hace ejercicio tras 100 días de dieta? ¿Y una que no hace ejercicio?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nHacemos primero la predicción del peso perdido para la persona que hace ejercicio usando el modelo inverso.\n\npredict.lm(inverso_ejercicio, newdata = list(dias = 100))\n\n       1 \n19.01329 \n\n\nY ahora hacemos la predicción del peso perdido para la persona que no hace ejercicio usando el modelo sigmoidal.\n\n# El modelo sigmoidal devuelve el logaritmo del peso perdido por lo que hay que aplicar la función exponencial para obtener el peso perdido.\nexp(predict.lm(sigmoidal_no_ejercicio, newdata = list(dias = 100)))\n\n       1 \n13.80634",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regresión</span>"
    ]
  },
  {
    "objectID": "05-regresion.html#ejercicios-propuestos",
    "href": "05-regresion.html#ejercicios-propuestos",
    "title": "\n5  Regresión\n",
    "section": "\n5.2 Ejercicios propuestos",
    "text": "5.2 Ejercicios propuestos\n\nEjercicio 5.6 El conjunto de datos neonatos contiene información sobre una muestra de 320 recién nacidos en un hospital durante un año que cumplieron el tiempo normal de gestación.\n\nCrear un data frame a con los datos de los neonatos a partir del fichero anterior.\nConstruir la recta de regresión del peso de los recién nacidos sobre el número de cigarros fumados al día por las madres. ¿Existe una relación lineal fuerte entre el peso y el número de cigarros?\nDibujar la recta de regresión calculada en el apartado anterior. ¿Por qué la recta no se ajusta bien a la nube de puntos?\nCalcular y dibujar la recta de regresión del peso de los recién nacidos sobre el número de cigarros fumados al día por las madres en el grupo de las madres que si fumaron durante el embarazo. ¿Es este modelo mejor o pero que la recta del apartado anterior?\nSegún este modelo, ¿cuánto disminuirá el peso del recién nacido por cada cigarro más diario que fume la madre?\nSegún el modelo anterior, ¿qué peso tendrá un recién nacido de una madre que ha fumado 5 cigarros diarios durante el embarazo? ¿Y si la madre ha fumado 30 cigarros diarios durante el embarazo? ¿Son fiables estas predicciones?\n¿Existe la misma relación lineal entre el peso de los recién nacidos y el número de cigarros fumados al día por las madres que fumaron durante el embarazo en el grupo de las madres menores de 20 y en el grupo de las madres mayores de 20? ¿Qué se puede concluir?\n\n\n\nEjercicio 5.7 El conjunto de datos edad.estatura contiene la edad y la estatura de 30 personas.\n\nCrear un data frame con los datos de las edades y las estaturas a partir del fichero anterior.\nCalcular la recta de regresión de la estatura sobre la edad. ¿Es un buen modelo la recta de regresión?\nDibujar el diagrama de dispersión de la estatura sobre la edad. ¿Alrededor de qué edad se observa un cambio en la tendencia?\nRecodificar la variable edad en dos grupos para mayores y menores de 20 años.\nCalcular la recta de regresión de la estatura sobre la edad para cada grupo de edad. ¿En qué grupo explica mejor la recta de regresión la relación entre la estatura y la edad?\nDibujar las rectas de regresión anteriores.\n¿Qué estatura se espera que tenga una persona de 14 años? ¿Y una de 38?\n\n\n\nEjercicio 5.8 El conjunto de datos gapminder del paquete gapminder contiene información sobre la esperanza de vida, la población, y el PIB per cápita en dólares PPP de los principales países en un rango de años.\n\nInstalar el paquete gapminder y cargarlo.\n¿Qué tipo de modelo explica mejor la evolución de la población con los años? Construir ese modelo.\n¿Qué tipo de modelo explica mejor la relación entre la esperanza de vida y el PIB per cápita?\n¿Qué tipo de modelo explica mejor la relación entre la esperanza de vida y el PIB r cápita para cada continente? Construir el mejor modelo en cada caso y utilizarlo para predecir la esperanza de vida de una persona de cada continente con un PIB per cápita de 1000 dólares PPP.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regresión</span>"
    ]
  },
  {
    "objectID": "06-distribuciones-probabilidad.html",
    "href": "06-distribuciones-probabilidad.html",
    "title": "\n6  Distribuciones de probabilidad\n",
    "section": "",
    "text": "6.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "06-distribuciones-probabilidad.html#ejercicios-resueltos",
    "href": "06-distribuciones-probabilidad.html#ejercicios-resueltos",
    "title": "\n6  Distribuciones de probabilidad\n",
    "section": "",
    "text": "library(tidyverse) \n# Incluye los siguientes paquetes:\n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - ggplot2: para la representación gráfica.\n# - purrr: para aplicar funciones a vectores. \nlibrary(extraDistr) # para distribuciones de probabilidad adicionales.\nlibrary(knitr) # para el formateo de tablas.\nlibrary(kableExtra) # para personalizar el formato de las tablas.\n\nEjercicio 6.1 Sea \\(X\\) la variable que mide el resultado obtenido al lanzar un dado.\n\n\n¿Qué tipo de modelo de distribución de probabilidad sigue \\(X\\)? Construir su función de probabilidad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSe trata de una distribución uniforme discreta \\(U(1, 6)\\). Para calcular probabilidades con el modelo uniforme discreto se utiliza la función ddunif(x, min, max) del paquete extraDistr, donde min es el mínimo valor que puede tomar la variable, max es el máximo valor que puede tomar la variable y x es el valor de la variable.\n\nlibrary(extraDistr)\nlibrary(kableExtra)\nx &lt;- 1:6\nf &lt;- ddunif(x, 1, 6)\ndf &lt;- data.frame(x, f)\ndf |&gt; \n    kable() |&gt; \n    kable_styling(full_width = F)\n\n\n\nx\nf\n\n\n\n1\n0.1666667\n\n\n2\n0.1666667\n\n\n3\n0.1666667\n\n\n4\n0.1666667\n\n\n5\n0.1666667\n\n\n6\n0.1666667\n\n\n\n\n\n\n\n\n\n\nDibujar la gráfica de la función de probabilidad del modelo de probabilidad anterior.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = f)) +\n    geom_point(color = \"steelblue\") +\n    labs(title = \"Función de probabilidad uniforme U(1,6)\", x = \"Número obtenido\", y = \"Probabilidad\")\n\n\n\n\n\n\n\n\n\n\n\n\nSimular el experimento aleatorio del lanzamiento de un dado. Repetir el lanzamiento un millón de veces y dibujar el diagrama de barras de la distribución de frecuencias resultante. ¿Se parece a la distribución de probabilidad anterior?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Fijamos una semilla de aleatorización para obtener resultados reproducibles.\nset.seed(123)\ndata.frame(x = rdunif(10^6, 1, 6))  |&gt; \n    ggplot(aes(x = x)) +\n    geom_bar(aes(y = after_stat(count/sum(count))), fill = \"steelblue\") +\n    labs(title = \"Distribución de frecuencias del lanzamiento de un dado\", x = \"Número obtenido\", y = \"Frecuencia relativa\")\n\n\n\n\n\n\n\nLa distribución experimental obtenida es casi idéntica a la distribución teórica del modelo uniforme \\(U(1,6)\\).\n\n\n\n\n\n\n\nEjercicio 6.2 Un test consta de 10 preguntas de opción múltiple con cuatro posibles respuestas para cada pregunta.\n\n\n¿Qué tipo de modelo de distribución de probabilidad sigue la variable que mide el número de aciertos al responder todas las preguntas aleatoriamente? Construir su función de probabilidad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSe trata de una distribución binomial \\(B(10, 0.25)\\). Para calcular probabilidades con el modelo binomial se utiliza la función dbinom(x, n, p) del paquete stats, donde n es el número de repeticiones, p es la probabilidad de éxito, y x es el valor de la variable.\n\nlibrary(kableExtra)\nx &lt;- 0:10\nf &lt;- dbinom(x, 10, 0.25)\ndf &lt;- data.frame(x, f)\ndf |&gt; \n    kable() |&gt; \n    kable_styling(full_width = F)\n\n\n\nx\nf\n\n\n\n0\n0.0563135\n\n\n1\n0.1877117\n\n\n2\n0.2815676\n\n\n3\n0.2502823\n\n\n4\n0.1459980\n\n\n5\n0.0583992\n\n\n6\n0.0162220\n\n\n7\n0.0030899\n\n\n8\n0.0003862\n\n\n9\n0.0000286\n\n\n10\n0.0000010\n\n\n\n\n\n\n\n\n\n\nDibujar la gráfica de la función de probabilidad del modelo de probabilidad anterior. ¿Cómo es la asimetría de la distribución de probabilidad? ¿Cómo afecta a la asimetría de la distribución el número de respuestas posibles en cada pregunta del test?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = f)) +\n    geom_point(color = \"steelblue\") +\n    labs(title = \"Función de probabilidad B(10,0.25)\", x = \"Número de preguntas acertadas\", y = \"Probabilidad\")\n\n\n\n\n\n\n\nLa distribución es asimétrica hacia la derecha. A medida que aumenta el número de posibles respuestas, la probabilidad de acertar disminuye y la distribución binomial se hace más asimétrica hacia la derecha.\n\n\n\n\n\nDibujar la gráfica de la función de distribución del modelo de probabilidad anterior.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular probabilidades acumuladas con el modelo binomial se utiliza la función pbinom(x, n, p) del paquete stats, donde n es el número de repeticiones, p es la probabilidad de éxito, y x es el valor de la variable.\n\nlibrary(ggplot2)\ndf$F &lt;- pbinom(x, 10, 0.25)\nggplot(df, aes(x = x, y = F)) +\n    geom_point(color = \"steelblue\") +\n    labs(title = \"Función de distribución B(10,0.25)\", x = \"Número de preguntas acertadas\", y = \"Probabilidad acumulada\")\n\n\n\n\n\n\n\nLa distribución es asimétrica hacia la derecha.\n\n\n\n\n\n¿Cuál es la probabilidad de sacar 3 puntos o menos en el test si se contestan todas las preguntas al azar?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\npbinom(3, 10, 0.25)\n\n[1] 0.7758751\n\n\n\n\n\n\n\n¿Cuál es la probabilidad de aprobar el test si se contestan todas las preguntas al azar?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEn este caso se trata de una probabilidad acumulada hacia la derecha, es decir, por encima del valor dado. Para ello hay que añadir el parámetro lower.tail = FALSE a la función pbinom.\n\n\n\n\n\n\nAdvertencia\n\n\n\nLas funciones de distribución en \\(R\\) incluyen la probabilidad del valor dado cuando la cola de acumulación es hacia la izquierda, es decir, se calcula \\(P(X\\leq x)\\), pero no lo incluyen cuando la cola de acumulación es hacia la derecha, es decir, se calcula \\(P(X&gt;x)\\).\n\n\n\npbinom(4, 10, 0.25, lower.tail = FALSE)\n\n[1] 0.07812691\n\n# o bien\n1 - pbinom(4, 10, 0.25)\n\n[1] 0.07812691\n\n\n\n\n\n\n\n¿Cuál es la probabilidad de tener un notable si se contestan todas las preguntas al azar?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl notable se corresponde con una nota de 7 u 8, por lo que hay que calcular la probabilidad \\(P(7\\leq X\\leq 8)\\).\n\npbinom(8, 10, 0.25) - pbinom(6, 10, 0.25)\n\n[1] 0.003476143\n\n\n\n\n\n\n\n\n\nEjercicio 6.3 El número medio de llamadas telefónicas que llegan a un servicio de teleasistencia es de 4 por minuto en horario laborable.\n\n\n¿Qué tipo de modelo de distribución de probabilidad sigue la variable que mide el número de llamadas que llegan al servicio de teleasistencia en un minuto? Construir su función de probabilidad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSe trata de una distribución de Poisson \\(P(4)\\). Para calcular probabilidades con el modelo Poisson se utiliza la función dpois(x, lambda) del paquete stats, donde lambda es el número medio de sucesos en el intervalo considerado y x es el valor de la variable.\n\nlibrary(kableExtra)\nx &lt;- 0:15\nf &lt;- dpois(x, 4)\ndf &lt;- data.frame(x, f)\ndf |&gt; \n    kable() |&gt; \n    kable_styling(full_width = F)\n\n\n\nx\nf\n\n\n\n0\n0.0183156\n\n\n1\n0.0732626\n\n\n2\n0.1465251\n\n\n3\n0.1953668\n\n\n4\n0.1953668\n\n\n5\n0.1562935\n\n\n6\n0.1041956\n\n\n7\n0.0595404\n\n\n8\n0.0297702\n\n\n9\n0.0132312\n\n\n10\n0.0052925\n\n\n11\n0.0019245\n\n\n12\n0.0006415\n\n\n13\n0.0001974\n\n\n14\n0.0000564\n\n\n15\n0.0000150\n\n\n\n\n\n\n\n\n\n\nDibujar la gráfica de la función de probabilidad del modelo de probabilidad anterior. ¿Cómo es la asimetría de la distribución de probabilidad?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = f)) +\n    geom_point(color = \"steelblue\") +\n    labs(title = \"Función de probabilidad P(4)\", x = \"Número de llamadas en 1 minuto\", y = \"Probabilidad\")\n\n\n\n\n\n\n\nLa distribución es asimétrica hacia la derecha.\n\n\n\n\n\n¿Cuál es la probabilidad de que lleguen menos de 2 llamadas en un minuto?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nppois(1, 4)\n\n[1] 0.09157819\n\n\n\n\n\n\n\nSi la empresa que da el servicio tiene operadores para atener como máximo 30 llamadas cada 5 minutos, ¿cuál es la probabilidad de que en un intervalo de 5 minutos no se puedan atender todas las llamadas?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo el intervalo de tiempo ahora es de 5 minutos, el número medio de llamadas en este intervalo de tiempo es 4 = 20, y por tanto, hay que trabajar con un modelo de Poisson \\(P(20)\\).\nPor otro lado, como ahora queremos calcular una probabilidad acumulada hacia la derechea, es decir, por encima del valor, hay que añadir el parámetro lower.tail = FALSE a la función ppois.\n\nppois(30, 20, lower.tail = FALSE)\n\n[1] 0.01347468\n\n\n\n\n\n\n\n\n\nEjercicio 6.4 La ley de los casos raros establece que la función de probabilidad de un modelo de Poison \\(P(\\lambda)\\) se obtiene en el límite cuando \\(n\\) tiende a \\(\\infty\\) y \\(p\\) tiende a \\(0\\) de la función de probabilidad de un modelo Binomial \\(B(n,p)\\), donde \\(\\lambda = np\\).\n\n\nAproximar un modelo binomial \\(B(10, 0.2)\\) mediante el correspondiente modelo Poisson aplicando la ley de los casos raros y comparar las gráficas de las distribuciones de probabilidad de ambos modelos. ¿Es una buena aproximación?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSegún la ley de los casos raros \\(B(10, 0.3) \\approx P(3)\\).\n\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(ggplot2)\nx &lt;- 0:10\nfbinom &lt;- dbinom(x, 10, 0.3)\nfpois &lt;- dpois(x, 3)\ndf &lt;- data.frame(x, fbinom, fpois)\ndf  |&gt; \n    pivot_longer(-x, names_to = \"Distribución\", values_to = \"Probabilidad\")  |&gt; \n    ggplot(aes(x = x, y = Probabilidad, color = Distribución)) + \n    geom_point() +\n    labs(title = \"Función de probabilidad de los modelos B(10, 0.3) y P(3)\")\n\n\n\n\n\n\n\nVamos a calcular el error en la aproximación.\n\ndf  |&gt; \n    mutate(error = abs(fbinom - fpois))  |&gt; \n    summarize(error = sum(error))\n\n      error\n1 0.1725254\n\n\nAsí pues, la aproximación no es buena pues el error es mayor del 17%.\n\n\n\n\n\nAproximar \\(B(30, 0.1)\\) mediante el correspondiente modelo Poisson aplicando la ley de los casos raros y comparar las gráficas de las distribuciones de probabilidad de ambos modelos. ¿Es una buena aproximación?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSegún la ley de los casos raros \\(B(30, 0.1) \\approx P(3)\\).\n\nx &lt;- 0:30\nfbinom &lt;- dbinom(x, 30, 0.1)\nfpois &lt;- dpois(x, 3)\ndf &lt;- data.frame(x, fbinom, fpois)\ndf  |&gt; \n    pivot_longer(-x, names_to = \"Distribución\", values_to = \"Probabilidad\")  |&gt; \n    ggplot(aes(x = x, y = Probabilidad, color = Distribución)) + \n    geom_point() +\n    labs(title = \"Función de probabilidad de los modelos B(30, 0.1) y P(3)\")\n\n\n\n\n\n\n\nVamos a calcular el error en la aproximación.\n\ndf  |&gt; \n    mutate(error = abs(fbinom - fpois))  |&gt; \n    summarize(error = sum(error))\n\n       error\n1 0.05236218\n\n\nAhora la aproximación es mucho mejor, ya que el error es menor del 5%.\n\n\n\n\n\nDefinir una función para repetir los procedimientos de los apartados anteriores para cualquier modelo binomial, y utilizarla para una binomial \\(B(100, 0.03)\\).\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncasos_raros &lt;- function (n, p){\n    # Definimos el rango del modelo binomial.\n    x &lt;- 0:n\n    # Función de probabilidad del modelo binomial.\n    fbinom &lt;- dbinom(x, n, p)\n    # Función de distribución del modelo Poisson equivalente.\n    fpois &lt;- dpois(x, n*p)\n    # Creamos un data frame con las dos funciones de probabilidad.\n    df &lt;- data.frame(x, fbinom, fpois)\n    # Dibujamos las gráficas de las funciones de probabilidad.\n    grafico &lt;- df  |&gt; \n        pivot_longer(-x, names_to = \"Distribución\", values_to = \"Probabilidad\")  |&gt; \n        ggplot(aes(x = x, y = Probabilidad, color = Distribución)) + \n        geom_point() +\n        labs(title = paste0(\"Función de probabilidad de los modelos B(\", n, \",\", p, \") y P(\", n*p, \")\"))\n    # Calculamos el error de la aproximación.\n    error &lt;- df  |&gt; \n        mutate(error = abs(fbinom - fpois))  |&gt; \n        summarize(error = sum(error))\n    return(list(grafico, error))\n}\n\ncasos_raros(100, 0.03) \n\n[[1]]\n\n\n\n\n\n\n\n\n\n[[2]]\n       error\n1 0.01521393\n\n\n\n\n\n\n\nDibujar una gráfica con los errores en las aproximaciones de un modelo binomial \\(B(n,p)\\) mediante un modelo Poisson \\(P(3)\\) para valores de $n desde \\(n=4\\) hasta \\(n=100\\). ¿A partir de que \\(n\\) la ley de los casos raros da un error menor del 5%?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(purrr)\nerror_casos_raros &lt;- function (n){\n    # Definimos el rango del modelo binomial.\n    x &lt;- 0:n\n    # Función de probabilidad del modelo binomial.\n    fbinom &lt;- dbinom(x, n, 3/n)\n    # Función de distribución del modelo Poisson equivalente.\n    fpois &lt;- dpois(x, 3)\n    # Calculamos los errores para cada n.\n    error = abs(fbinom - fpois)\n    # Devolvemos la suma de los errores\n    return(sum(error))\n}\n\ndata.frame(n = 4:100)  |&gt; \n    mutate(error = map_dbl(n, error_casos_raros))  |&gt; \n    ggplot(aes(x = n, y = error)) +\n    geom_point(color = \"steelblue\") +\n    geom_hline(yintercept = 0.05, color = \"red\") +\n    labs(title = \"Error en la aproximación de un modelo B(n,p) con otro P(np)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 6.5 La vida media de un tipo de batería es de 50 días.\n\n\n¿Qué tipo de modelo de distribución de probabilidad sigue la variable que mide la duración de este tipo de baterías? Construir su función de densidad.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSe trata de una distribución exponencial \\(Exp(1/50)\\). Para calcular probabilidades con el modelo exponencial se utiliza la función dexp(x, lambda) del paquete stats, donde lambda es el inverso de la media y x es el valor de la variable.\n\nx &lt;- seq(0,300,0.1)\nf &lt;- dexp(x, 1/50)\ndf &lt;- data.frame(x, f)\nggplot(df, aes(x = x, y = f)) +\n    geom_line(color = \"steelblue\") +\n    labs(title = \"Función de densidad Exp(1/50)\", x = \"Días de duración\", y = \"Densidad de probabilidad\")\n\n\n\n\n\n\n\n\n\n\n\n\nCalcula la probabilidad de que la batería dure menos de 50 días.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular probabilidades con el modelo exponencial se utiliza la función pexp(x, lambda) del paquete stats, donde lambda es el inverso de la media y x es el valor de la variable.\n\npexp(50, 1/50)\n\n[1] 0.6321206\n\n\n\n\n\n\n\nCalcula la probabilidad de que la batería dure más de 100 días.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEn este caso hay que calcular una probabilidad acumulada hacia la derecha, es decir, por encima del valor dado. Para ello hay añadir el parámetro lower.tail = FALSE a la función pexp.\n\npexp(100, 1/50, lower.tail = FALSE)\n\n[1] 0.1353353\n\n\n\n\n\n\n\nCalcula la probabilidad de que la batería dure entre 50 y 100 días.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\npexp(100, 1/50) - pexp(50, 1/50)\n\n[1] 0.2325442\n\n\n\n\n\n\n\nCalcular los cuartiles de la distribución del tiempo de duración de las baterías.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular percentiles con el modelo exponencial se utiliza la función qexp(x, lambda) del paquete stats, donde lambda es el inverso de la media y x es la probabilidad acumulada del percentil.\n\ncuartiles &lt;- qexp(c(0.25, 0.5, 0.75), 1/50)\nnames(cuartiles) &lt;- c(\"C1\", \"C2\", \"C3\")\ncuartiles\n\n      C1       C2       C3 \n14.38410 34.65736 69.31472 \n\n\n\n\n\n\n\n\n\nEjercicio 6.6 Se sabe que el nivel de colesterol en hombres de una determinada población sigue una distribución Normal \\(N(220, 20)\\) en mg/dl.\n\n\nDibujar la función de densidad de este modelo.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular densidades de probabilidad de una distribución normal se utiliza la función dnorm(x, mean, sd) del paquete stats, donde mean es la media, sd es la desviación típica y x es el valor de la variable.\n\nx &lt;- seq(160,280,0.1)\nf &lt;- dnorm(x, 220, 20)\ndf &lt;- data.frame(x, f)\nggplot(df, aes(x = x, y = f)) +\n    geom_line(color = \"steelblue\") +\n    labs(title = \"Función de densidad N(220,20)\", x = \"Nivel de colesterol\", y = \"Densidad de probabilidad\")\n\n\n\n\n\n\n\n\n\n\n\n\nDibujar la gráfica de la función de distribución del modelo de probabilidad anterior.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular probabilidades acumuladas con el modelo normal se utiliza la función pnorm(x, mean, sd) del paquete stats, donde mean es la media, sd es la desviación típica y x es el valor de la variable.\n\ndf$F &lt;- pnorm(x, 220, 20)\nggplot(df, aes(x = x, y = F)) +\n    geom_line(color = \"steelblue\") +\n    labs(title = \"Función de distribución N(220,20)\", x = \"Nivel de colesterol\", y = \"Probabilidad acumulada\")\n\n\n\n\n\n\n\n\n\n\n\n\nCalcular la probabilidad de tener un nivel de colesterol por debajo de 220 mg/dl.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\npnorm(220, 220, 20)\n\n[1] 0.5\n\n\n\n\n\n\n\nCalcular la probabilidad de tener un nivel de colesterol por encima de 260 mg/dl.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEn este caso hay que calcular una probabilidad acumulada hacia la derecha, es decir, por encima del valor dado, y hay añadir el parámetro lower.tail = FALSE a la función pnorm.\n\npnorm(260, 220, 20, lower.tail = FALSE)\n\n[1] 0.02275013\n\n\n\n\n\n\n\n¿Qué porcentaje de la población presentará un nivel de colesterol entre \\(\\mu-\\sigma\\) y \\(\\mu+\\sigma\\)?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo \\(\\mu=200\\) y \\(\\sigma=20\\), se tiene \\((\\mu-\\sigma, \\mu+\\sigma) = (200, 240)\\).\n\npnorm(240, 220, 20) - pnorm(200, 220, 20)\n\n[1] 0.6826895\n\n\nPor tanto, habrá un 68.27 % de la población.\n\n\n\n\n\n¿Qué porcentaje de la población presentará un nivel de colesterol entre \\(\\mu-2\\sigma\\) y \\(\\mu+2\\sigma\\)?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo \\(\\mu=200\\) y \\(\\sigma=20\\), se tiene \\((\\mu-2\\sigma, \\mu+2\\sigma) = (180, 260)\\).\n\npnorm(260, 220, 20) - pnorm(180, 220, 20)\n\n[1] 0.9544997\n\n\nPor tanto, habrá un 95.45 % de la población.\n\n\n\n\n\n¿Qué porcentaje de la población presentará un nivel de colesterol entre \\(\\mu-3\\sigma\\) y \\(\\mu+3\\sigma\\)?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo \\(\\mu=200\\) y \\(\\sigma=20\\), se tiene \\((\\mu-3\\sigma, \\mu+3\\sigma) = (160, 280)\\).\n\npnorm(280, 220, 20) - pnorm(160, 220, 20)\n\n[1] 0.9973002\n\n\nPor tanto, habrá un 99.73 % de la población.\n\n\n\n\n\nCalcular el rango intercuartílico de la distribución.\n\n\n\n\n\n\nSolución\n\n\n\n\n\nPara calcular percentiles con el modelo normal se utiliza la función qnorm(x, mean, sd) del paquete stats, donde mean es la media, sd es la desviación típica y x es la probabilidad acumulada del percentil.\n\nqnorm(0.75, 220, 20) - qnorm(0.25, 220, 20)\n\n[1] 26.97959\n\n\n\n\n\n\n\n\n\nEjercicio 6.7 El teorema central del límite establece que la suma de \\(n\\) variables aleatorias independientes, con media y varianza finitas, se aproxima a una distribución normal. En este ejercicio comprobaremos su certeza experimentalmente.\n\n\nGenerar una muestra aleatoria de tamaño 1000000 de una variable aleatoria uniforme discreta U(1,10) y dibujar la gráfica de su distribución de frecuencias.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(ggplot2)\nset.seed(123)\ndf &lt;- data.frame(x1 = rdunif(10^6, 1, 10))  \nggplot(df, aes(x = x1)) +\n    geom_bar(aes(y = after_stat(count/sum(count))), fill = \"steelblue\") +\n    labs(title = \"Distribución de frecuencias U(1,10)\", x = \"X\", y = \"Frecuencia relativa\")\n\n\n\n\n\n\n\n\n\n\n\n\nGenerar otra muestra aleatoria de tamaño 1000000 de una variable aleatoria uniforme discreta U(1,10) y dibujar la gráfica de su distribución de frecuencias de la suma de esta variable y la anterior.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf  |&gt; \n    mutate(x2 = rdunif(10^6, 1, 10), suma = x1 + x2)  |&gt; \n    ggplot(aes(x = suma)) +\n    geom_bar(aes(y = after_stat(count/sum(count))), fill = \"steelblue\") +\n    labs(title = \"Distribución de frecuencias de la suma de dos variables U(1,10) independientes\", x = \"Suma\", y = \"Frecuencia relativa\")\n\n\n\n\n\n\n\n\n\n\n\n\nDefinir una función que genere \\(n\\) muestras independientes de tamaño 1000000 de una variable uniforme discreta \\(U(1,10)\\) y devuelva su suma. Utilizar la función para dibujar el diagrama de barras de la distribución de frecuencias de la suma de 30 variables uniformes discretas \\(U(1,10)\\).\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndistribucion_suma &lt;- function(n) {\n    df &lt;- data.frame(suma = rep(0, 10^6))\n    for (i in 1:n) {\n        df[[paste0(\"x\", i)]] &lt;- rdunif(10^6, 1, 10)\n        df$suma &lt;- df$suma + df[[paste0(\"x\", i)]]\n    }\n    return(df)\n}\n\nggplot(distribucion_suma(30), aes(x = suma)) + \n    geom_bar(aes(y = after_stat(count/sum(count))), fill = \"steelblue\") +\n    labs(title = paste0(\"Distribución de frecuencias de la suma de 30 variables U(1,10) independientes\"), x = \"Suma\", y = \"Frecuencia relativa\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "06-distribuciones-probabilidad.html#ejercicios-propuestos",
    "href": "06-distribuciones-probabilidad.html#ejercicios-propuestos",
    "title": "\n6  Distribuciones de probabilidad\n",
    "section": "\n6.2 Ejercicios propuestos",
    "text": "6.2 Ejercicios propuestos\n\nEjercicio 6.8 Una máquina de chips produce un 0.02% de chips defectuosos. Si la máquina produce 120 chips cada hora.\n\nCalcular la probabilidad de que la máquina produzca algún chip defectuoso en 5 minutos.\nCalcular la probabilidad de que produzca más de 1 chip defectuoso en 10 minutos.\nCalcular la probabilidad de que produzca entre 1 y 3 chips defectuosos (ambos incluidos) en 10 minutos.\n\n\n\nEjercicio 6.9 Las ventas medias de un libro en un comercio electrónico son de 15 unidades diarias.\n\n¿Cuál es la probabilidad de que un día concreto no se venda ningún libro?\n¿Cuál es la probabilidad de que un día concreto se vendan entre 10 y 20 libros?\nSi en el almacén que hace los envíos se dispone de un stock de 125 libros, ¿cuál es la probabilidad de que no puedan satisfacer todos los pedidos en una semana?\n\n\n\nEjercicio 6.10 Dibujar las gráficas de las funciones de probabilidad y distribución de una variable geométrica \\(Geom(0.2)\\).\n\n\nEjercicio 6.11 Generar 10 muestras aleatorias de una distribución y calcular la suma de sus cuadrados. Dibujar el diagrama de barras de la distribución de frecuencias de la muestra obtenida sumando los cuadrados. Compararla con la función de probabilidad de una distribución Chi-cuadrado con 10 grados de libertad.\n\n\nEjercicio 6.12 Dibujar las gráficas de las funciones de densidad y distribución de una variable T de Student \\(T(12)\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "07-intervalos-confianza-una-poblacion.html",
    "href": "07-intervalos-confianza-una-poblacion.html",
    "title": "\n7  Intervalos de confianza para medias y proporciones de una población\n",
    "section": "",
    "text": "7.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Intervalos de confianza para medias y proporciones de una población</span>"
    ]
  },
  {
    "objectID": "07-intervalos-confianza-una-poblacion.html#ejercicios-resueltos",
    "href": "07-intervalos-confianza-una-poblacion.html#ejercicios-resueltos",
    "title": "\n7  Intervalos de confianza para medias y proporciones de una población\n",
    "section": "",
    "text": "library(tidyverse)\n# Incluye los siguientes paquetes:\n# - dplyr: para el preprocesamiento y manipulación de datos.\n# - ggplot2: para la representación gráfica.\n# - purrr: para aplicar funciones a vectores.\nlibrary(broom) # para convertir las listas con los resúmenes de los modelos de regresión a formato organizado.\nlibrary(tidymodels) # para realizar contrastes de hipótesis en formato tidy.\nlibrary(samplingbook) # para el cálculo de tamaños muestrales.\nlibrary(knitr) # para el formateo de tablas.\n\nEjercicio 7.1 Se sabe que para que un fármaco sea efectivo, la concentración de su principio activo debe ser de al menos \\(16\\) mg/mm\\(^3\\). Una farmacia va a comprar un lote de este medicamento, pero antes quiere asegurarse de que los medicamentos del lote son efectivos y para ello analiza la concentración de principio activo en una muestra aleatoria de \\(10\\) envases tomados del lote, obteniendo los siguientes resultados en mg/mm\\(^{3}\\):\n\\[\n17.6 \\quad 19.2 \\quad 21.3 \\quad 15.1 \\quad 17.6 \\quad 18.9 \\quad 16.2 \\quad 18.3 \\quad 19.0 \\quad 16.4\n\\]\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(concentracion = c(17.6, 19.2, 21.3, 15.1, 17.6, 18.9, 16.2, 18.3, 19.0, 16.4 ))\n\n\n\n\n\n\nCalcular la concentración media de principio activo de la muestra. ¿Puede afirmarse que los medicamentos del lote son efectivos?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nmean(df$concentracion)\n\n[1] 17.96\n\n\nA pesar de la concentración media está por encima de \\(16\\) mg/mm\\(^3\\), se trata de una estimación puntual, y por tanto, no podemos garantizar que la media poblacional esté por encima de \\(16\\) mg/mm\\(^3\\). ¿Puede afirmarse con este nivel de confianza que los medicamentos del lote son efectivos?\n\n\n\n\n\nCalcular el intervalo de confianza para la media de la concentración del lote con nivel de confianza del \\(95\\%\\) (nivel de significación \\(\\alpha =0.05\\)). ¿Puede afirmarse ahora que los medicamentos del lote son efectivos?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara calcular el intervalo de confianza para la media de una población podemos utilizar la función t.test del paquete base stats.\nSi queremos mostrar la salida del test en formato de tabla podemos utilizar la función tidy del paquete broom.\nTambién podemos usar la función t_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nstats\ntidymodels\n\n\n\n\nt1 &lt;- t.test(df$concentracion)\nt1$conf.int\n\n[1] 16.68158 19.23842\nattr(,\"conf.level\")\n[1] 0.95\n\n\nPara mostrar la salida en formato de tabla.\n\nlibrary(broom)\nlibrary(knitr)\ntidy(t1) |&gt; \n    select(estimate, conf.low, conf.high) |&gt; \n    kable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n17.96\n16.68158\n19.23842\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    t_test(response = concentracion) |&gt; \n    select(estimate, lower_ci, upper_ci) |&gt; \n    kable()\n\n\n\nestimate\nlower_ci\nupper_ci\n\n\n17.96\n16.68158\n19.23842\n\n\n\n\n\n\n\nComo el intervalo entero está por encima de \\(16\\) mg/mm\\(^3\\), podemos afirmar con una confianza del \\(95\\%\\) que la concentración media de principio activo del lote está por encima de \\(16\\) mg/mm\\(^3\\) y por tanto podemos concluir que los medicamentos del lote son efectivos.\n\n\n\n\n\n¿Puede afirmarse que los medicamentos del lote son efectivos con un \\(99\\%\\) de confianza?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nt2 &lt;- t.test(df$concentracion, conf.level = 0.99)\nt2$conf.int\n\n[1] 16.1234 19.7966\nattr(,\"conf.level\")\n[1] 0.99\n\n\nComo el intervalo entero sigue estando por encima de \\(16\\) mg/mm\\(^3\\), podemos afirmar con una confianza del \\(99\\%\\) que los medicamentos del lote son efectivos.\n\n\n\n\n\nSi definimos la precisión del intervalo como la inversa de su amplitud, ¿cómo afecta a la precisión del intervalo de confianza el tomar niveles de significación cada vez más altos? ¿Cuál puede ser la explicación?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ncat(paste0(\"Amplitud intervalo 95%: \", t1$conf.int[2] - t1$conf.int[1]))\n\nAmplitud intervalo 95%: 2.55684921520655\n\ncat(paste0(\"Amplitud intervalo 99%: \", t2$conf.int[2] - t2$conf.int[1]))\n\nAmplitud intervalo 99%: 3.67319282263829\n\n\nComo se ve, al aumentar el nivel de confianza del intervalo, la precisión disminuye. Ello es debido a que para tener más confianza de capturar el verdadero valor de la media en el intervalo, debemos hacer mayor el intervalo.\n\n\n\n\n\n¿Qué tamaño muestral sería necesario para obtener una estimación del contenido medio de principio activo con un margen de error de \\(\\pm 0.5\\) mg/mm\\(^3\\) y una confianza del 95%?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl tamaño muestral necesario para construir un intervalo de confianza para la media depende del nivel de confianza deseado (\\(0.95\\) en este caso), del error o semiamplitud del intervalo deseado (\\(0.5\\) en este caso) y de la desviación típica poblacional, que no se conoce, pero se puede estimar mediante la cuasidesviación típica muestral.\n\nlibrary(samplingbook)\nsample.size.mean(e = 0.5, S = sd(df$concentracion), level = 0.95)\n\n\nsample.size.mean object: Sample size for mean estimate\nWithout finite population correction: N=Inf, precision e=0.5 and standard deviation S=1.7871\n\nSample size needed: 50\n\n\n\n\n\n\n\n\n\nEjercicio 7.2 Una central de productos lácteos recibe diariamente la leche de dos granjas \\(X\\) e \\(Y\\). Para analizar la calidad de la leche, durante una temporada, se controla el porcentaje de materia grasa de la leche que proviene de ambas granjas, con los siguientes resultados:\n\\[\n\\begin{array}{c|c}\nX & Y \\\\\n\\hline\n\\begin{array}[t]{rr}\n3.4 & 3.4 \\\\\n3.2 & 3.5 \\\\\n3.3 & 3.3 \\\\\n3.2 & 3.2 \\\\\n3.3 & 3.0 \\\\\n3.1 & 3.2 \\\\\n\\end{array}\n&\n\\begin{array}[t]{rr}\n2.8 & 2.9 \\\\\n3.0 & 3.2 \\\\\n3.2 & 3.1 \\\\\n2.9 & 2.9 \\\\\n3.1 & 3.2 \\\\\n2.9 & 3.1 \\\\\n3.3 & 3.2 \\\\\n3.2 & 3.3 \\\\\n\\end{array}\n\\end{array}\n\\]\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- tibble(\n    grasa = c(3.4, 3.2, 3.3, 3.2, 3.3, 3.1, 3.4, 3.5, 3.3, 3.2, 3.0, 3.2, 2.8, 3.0, 3.2, 2.9, 3.1, 2.9, 3.3, 3.2, 2.9, 3.2, 3.1, 2.9, 3.2, 3.1, 3.2, 3.3),\n    granja = factor(c(rep(\"X\", 12), rep(\"Y\", 16)))\n)\n\n\n\n\n\n\nCalcular el contenido medio de materia grasa de la muestra de leche cada granja y los respectivos intervalos de confianza con un \\(95\\%\\) de confianza. Dibujar los intervalos de confianza obtenidos.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara calcular el intervalo de confianza para la media de una población podemos utilizar la función t.test del paquete base stats.\nTambién podemos usar la función t_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\nOtra opción es utilizar la función mean_ci del paquete qwraps2.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nstats\ntidymodels\n\n\n\n\nlibrary(knitr)\ndf |&gt; \n    group_by(granja) |&gt;\n    summarise(\"Media\" = mean(grasa, na.rm = T), \n    \"IC 95% Inf\" = t.test(grasa)$conf.int[1], \n    \"IC 95% Sup\" = t.test(grasa)$conf.int[2]) |&gt; \n    kable()\n\n\n\ngranja\nMedia\nIC 95% Inf\nIC 95% Sup\n\n\n\nX\n3.258333\n3.170719\n3.345948\n\n\nY\n3.081250\n2.995950\n3.166550\n\n\n\n\n\nOtra opción es anidando los data frames de cada granja y aplicar el test t para cada grupo.\n\ntabla_ic &lt;- df |&gt; \n    nest(data = -granja) |&gt; \n    mutate(test = map(data, ~ tidy(t.test(.x$grasa)))) |&gt; \n    unnest(test) |&gt; \n    select(granja, estimate, conf.low, conf.high) \n\ntabla_ic |&gt; \n    kable()\n\n\n\ngranja\nestimate\nconf.low\nconf.high\n\n\n\nX\n3.258333\n3.170719\n3.345948\n\n\nY\n3.081250\n2.995950\n3.166550\n\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    nest(data = -granja) |&gt; \n    mutate(test = map(data, ~ t_test(x = .x, response = grasa))) |&gt; \n    unnest(test) |&gt; \n    select(granja, estimate, lower_ci, upper_ci) |&gt; \n    kable()\n\n\n\ngranja\nestimate\nlower_ci\nupper_ci\n\n\n\nX\n3.258333\n3.170719\n3.345948\n\n\nY\n3.081250\n2.995950\n3.166550\n\n\n\n\n\n\n\n\nAhora dibujamos los intervalos de confianza.\n\ntabla_ic  |&gt; \n    ggplot(aes(x = granja, y = estimate, color = granja)) +\n    geom_point(size = 3) +\n    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n    labs(title = \"Intervalos de confianza del 95% para la media\", x = \"Granja\", y = \"Porcentaje de grasa\")\n\n\n\n\n\n\n\n\n\n\n\n\nA la vista de los intervalos de confianza obtenidos ¿Existen diferencias estadísticamente significativas entre los contenidos medios de grasa de la leche de las dos granjas? En tal caso, ¿qué granja produce leche con más grasa?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo los intervalos no se solapan, es decir, no tienen valores en común, podemos concluir que los contenidos medios de grasa de las leches de las dos granjas son significativamente diferentes con un \\(95\\%\\) de confianza. Además se aprecia que el intervalo de la granja \\(X\\) tiene valores mayores que el de la granja \\(Y\\), por lo que la leche de la granja \\(X\\) tiene más contenido de grasa que la de la granja \\(Y\\).\n\n\n\n\n\nRepetir los cálculos anteriores tomando una confianza del \\(99\\%\\). ¿Existen diferencias estadísticamente significativas entre el contenido medio de grasa de las leches de las dos granjas con este nivel de confianza?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nstats\ntidymodels\n\n\n\n\ntabla_ic_99 &lt;- df |&gt; \n    nest(data = -granja) |&gt; \n    mutate(test = map(data, ~ tidy(t.test(.x$grasa, conf.level = 0.99)))) |&gt; \n    unnest(test) |&gt; \n    select(granja, estimate, conf.low, conf.high) \n\ntabla_ic_99 |&gt; \n    kable()\n\n\n\ngranja\nestimate\nconf.low\nconf.high\n\n\n\nX\n3.258333\n3.134701\n3.381966\n\n\nY\n3.081250\n2.963324\n3.199176\n\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    nest(data = -granja) |&gt; \n    mutate(test = map(data, ~ t_test(x = .x, response = grasa, conf_level = 0.99))) |&gt; \n    unnest(test) |&gt; \n    select(granja, estimate, lower_ci, upper_ci) |&gt; \n    kable()\n\n\n\ngranja\nestimate\nlower_ci\nupper_ci\n\n\n\nX\n3.258333\n3.134701\n3.381966\n\n\nY\n3.081250\n2.963324\n3.199176\n\n\n\n\n\n\n\n\nAhora dibujamos los intervalos de confianza.\n\ntabla_ic_99  |&gt; \n    ggplot(aes(x = granja, y = estimate, color = granja)) +\n    geom_point(size = 3) +\n    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n    labs(title = \"Intervalos de confianza del 99% para la media\", x = \"Granja\", y = \"Porcentaje de grasa\")\n\n\n\n\n\n\n\nComo se ve, ahora los dos intervalos se solapan y por tanto las medias del contenido de grasa de las leches de las dos granjas podrían ser iguales. Por tanto, no existen diferencias estadísticamente significativas entre el contenido medio de grasa de las leches de las dos granjas con un \\(99º%\\) de confianza.\n\n\n\n\n\n\n\nEjercicio 7.3 El conjunto de datos biblioteca.csv contiene los resultados de una encuesta realizada en una universidad, sobre si el alumnado utiliza habitualmente (al menos una vez a la semana) la biblioteca.\n\n\nCrear conjunto de datos con los datos de la muestra a partir del fichero biblioteca.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/biblioteca.csv\")\n\n\n\n\n\n\nCalcular el intervalo de confianza con \\(\\alpha=0.01\\) para la proporción del alumnado que utiliza habitualmente la biblioteca. ¿Cómo es la precisión del intervalo?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara calcular el intervalo de confianza para la proporción de una población podemos utilizar la función prop.test del paquete base stats.\nSi queremos mostrar la salida del test en formato de tabla podemos utilizar la función tidy del paquete broom.\nTambién podemos usar la función prop_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nstats\ntidymodels\n\n\n\n\nlibrary(broom)\nlibrary(knitr)\nfrec &lt;- table(df$respuesta)\ntidy(prop.test(frec[\"si\"], nrow(df), conf.level = 0.99)) |&gt; \nselect(estimate, conf.low, conf.high) |&gt; \nkable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n0.4705882\n0.261705\n0.6896622\n\n\n\n\n\n\n\nlibrary(tidymodels)\nlibrary(knitr)\ndf  |&gt; \n    prop_test(response = respuesta, conf_level = 0.99) |&gt; \n    mutate(estimate = nrow(df[df$respuesta == \"si\", ]) / nrow(df)) |&gt; \n    select(estimate, lower_ci, upper_ci) |&gt; \n    kable()\n\n\n\nestimate\nlower_ci\nupper_ci\n\n\n0.4705882\n0.3103378\n0.738295\n\n\n\n\n\n\n\nSe trata de un intervalo poco preciso, ya que su amplitud es bastante grande.\n\n\n\n\n\n¿Qué tamaño muestral sería necesario para obtener una estimación de la proporción de alumnos que utilizan regularmente la biblioteca con un margen de error de un \\(1\\%\\) y una confianza del \\(95\\%\\)?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl tamaño muestral necesario para construir un intervalo de confianza para la media depende del nivel de confianza deseado (\\(0.95\\) en este caso), del error o semiamplitud del intervalo deseado (\\(0.01\\) en este caso) y de proporción poblacional, que no se conoce, pero se puede estimar mediante la proporción muestral.\n\nlibrary(samplingbook)\nsample.size.prop(e = 0.01, P = frec[\"si\"]/nrow(df), level = 0.95)\n\n\nsample.size.prop object: Sample size for proportion estimate\nWithout finite population correction: N=Inf, precision e=0.01 and expected proportion P=0.4706\n\nSample size needed: 9571\n\n\n\n\n\n\n\nCalcular los intervalo de confianza para las proporciones de chicas y chicos que utilizan regularmente la biblioteca. ¿Existe una diferencia estadísticamente significativa entre la proporción de chicas y chicos que utilizan regularmente la biblioteca? En tal caso, ¿quiénes utilizan más la biblioteca?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nstats\ntidymodels\n\n\n\n\ndf |&gt; \n    group_by(sexo) |&gt; \n    count(respuesta) |&gt; \n    mutate(test = map(n, \\(x) tidy(prop.test(x, sum(n))))) |&gt;     \n    unnest(test) |&gt;\n    filter(respuesta == \"si\") |&gt; \n    select(sexo, respuesta, n, estimate, conf.low, conf.high) |&gt;  \n    kable() \n\n\n\nsexo\nrespuesta\nn\nestimate\nconf.low\nconf.high\n\n\n\nH\nsi\n3\n0.1875000\n0.0497313\n0.4630766\n\n\nM\nsi\n13\n0.7222222\n0.4640580\n0.8928742\n\n\n\n\n\n\n\n\ndf |&gt; \n    nest(data = -sexo) |&gt;  \n    mutate(test = map(data, ~ prop_test(x = .x, response = respuesta, success = \"si\"))) |&gt;  \n    mutate(estimate = map(data, ~ nrow(.x[.x$respuesta == \"si\", ]) / nrow(.x))) |&gt;    \n    unnest(c(test, estimate)) |&gt;\n    select(sexo, estimate, lower_ci, upper_ci) |&gt;  \n    kable() \n\nNo `p` argument was hypothesized, so the test will assume a null hypothesis `p\n= .5`.\nNo `p` argument was hypothesized, so the test will assume a null hypothesis `p\n= .5`.\n\n\n\n\nsexo\nestimate\nlower_ci\nupper_ci\n\n\n\nH\n0.1875000\n0.0497313\n0.4630766\n\n\nM\n0.7222222\n0.4640580\n0.8928742\n\n\n\n\n\n\n\n\nComo los intervalos de confianza para las proporciones de chicos y chicas que utilizan regularmente la biblioteca no se solapan, es decir, no tienen valores en común, podemos concluir que existe una diferencia estadísticamente significativa entre ambas proporciones con un \\(95\\%\\) de confianza. Como además el intervalo de confianza para la proporción de chicas está claramente por encima del de chicos, se concluye que hay más chicas utilizan regularmente la biblioteca.\n\n\n\n\n\n\n\nEjercicio 7.4 En un sondeo preelectoral se ha tomado una muestra de \\(500\\) personas y se ha observado que \\(220\\) votarían al partido \\(A\\) y \\(180\\) votarían al partido \\(B\\).\n\n\nCalcular el intervalo de confianza para el porcentaje de voto al partido \\(A\\).\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(broom)\nlibrary(knitr)\ntidy(prop.test(220, 500)) |&gt; \nselect(estimate, conf.low, conf.high) |&gt; \nmutate(across(everything(), ~ .x * 100)) |&gt; \nkable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n44\n39.613\n48.48059\n\n\n\n\n\n\n\n\n\nCalcular el intervalo de confianza para el porcentaje de voto al partido \\(B\\).\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ntidy(prop.test(180, 500)) |&gt; \nselect(estimate, conf.low, conf.high) |&gt; \nmutate(across(everything(), ~ .x * 100)) |&gt; \nkable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n36\n31.81744\n40.40109\n\n\n\n\n\n\n\n\n\nA la vista de los intervalos de confianza, ¿se puede asegurar con un \\(95\\%\\) de confianza qué partido ganará las elecciones?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo ambos intervalos se solapan, no existe una diferencia estadísticamente significativa entre los porcentajes de votos a ambos partidos, y por tanto, no se puede asegurar con un \\(95\\%\\) de confianza qué partido ganará las elecciones.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Intervalos de confianza para medias y proporciones de una población</span>"
    ]
  },
  {
    "objectID": "07-intervalos-confianza-una-poblacion.html#ejercicios-propuestos",
    "href": "07-intervalos-confianza-una-poblacion.html#ejercicios-propuestos",
    "title": "\n7  Intervalos de confianza para medias y proporciones de una población\n",
    "section": "\n7.2 Ejercicios propuestos",
    "text": "7.2 Ejercicios propuestos\n\nEjercicio 7.5 El conjunto de datos neonatos contiene información sobre una muestra de 320 recién nacidos en un hospital durante un año que cumplieron el tiempo normal de gestación.\n\nCalcular el intervalo de confianza del \\(99\\%\\) para el peso medio de los recién nacidos. ¿Entre qué valores estará el peso medio?\nCalcular el intervalo de confianza para la puntuación media del Apgar al minuto de nacer y compararlo con el de la puntuación Apgar a los 5 minutos. ¿Existe una diferencia estadísticamente significativa entre las medias de las dos puntuaciones?\nCalcular el intervalo de confianza para el porcentaje de niños con peso menor o igual que \\(2.5\\) Kg en el grupo de las madres que han fumado durante el embarazo y en el de las que no. ¿Podemos afirmar con un \\(95\\%\\) de confianza que el que la madre fume influye significativamente en el peso de los recién nacidos?\n\n\n\nEjercicio 7.6 En una fábrica de componentes electrónicos, hay dos máquinas que producen un mismo tipo de chips. Se ha tomado una muestra de chips de cada máquina y se ha observado que en la primera máquina hubo 12 chips defectuosos de un total de 200, mientras que en la segunda máquina hubo un total de 10 chips defectuosos de un total de 300. ¿Se puede afirmar con un \\(90\\%\\) de confianza que la segunda máquina produce menos chips defectuosos que la primera?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Intervalos de confianza para medias y proporciones de una población</span>"
    ]
  },
  {
    "objectID": "08-intervalos-confianza-comparacion-dos-poblaciones.html",
    "href": "08-intervalos-confianza-comparacion-dos-poblaciones.html",
    "title": "\n8  Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n",
    "section": "",
    "text": "8.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones</span>"
    ]
  },
  {
    "objectID": "08-intervalos-confianza-comparacion-dos-poblaciones.html#ejercicios-resueltos",
    "href": "08-intervalos-confianza-comparacion-dos-poblaciones.html#ejercicios-resueltos",
    "title": "\n8  Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n",
    "section": "",
    "text": "library(tidyverse)\n# Incluye los siguientes paquetes:\n# - dplyr: para el preprocesamiento y manipulación de datos.\nlibrary(broom) # para convertir las listas con los resúmenes de los modelos de regresión a formato organizado.\nlibrary(knitr) # para el formateo de tablas.\n\nEjercicio 8.1 Para ver si una campaña de publicidad sobre un fármaco ha influido en sus ventas, se tomó una muestra de 8 farmacias y se midió el número de unidades de dicho fármaco vendidas durante un mes, antes y después de la campaña, obteniéndose los siguientes resultados:\n\\[\n\\begin{array}{|c|c|c|c|c|c|c|c|c|}\n\\hline\n\\mbox{Antes} & 147 & 163 & 121 & 205 & 132 & 190 & 176 & 147 \\\\\n\\hline\n\\mbox{Después} & 150 & 171 & 132 & 208 & 141 & 184 & 182 & 145\\\\\n\\hline\n\\end{array}\n\\]\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(\n    antes = c(147, 163, 121, 205, 132, 190, 176, 147),\n    despues = c(150, 171, 132, 208, 141, 184, 182, 145))\n\n\n\n\n\n\nCalcular las ventas medias antes y después de la campaña de publicidad. ¿Ha aumentado la campaña las ventas medias?, ¿crees que los resultados son estadísticamente significativos?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(kableExtra)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::group_rows() masks kableExtra::group_rows()\n✖ dplyr::lag()        masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf |&gt; \n    # Calculamos la media de las columnas antes y despues del data frame.\n    summarize(across(antes:despues, ~ mean(.x, na.rm = TRUE))) |&gt; \n    # Renombramos los nombres de las columnas del data frame resultante.\n    rename(`Ventas medias antes` = antes, `Ventas medias despues` = despues) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kbl()\n\n\n\nVentas medias antes\nVentas medias despues\n\n\n160.125\n164.125\n\n\n\n\nA pesar de que las ventas medias después de la campaña de publicidad han aumentado en la muestra, no podemos concluir que las medias poblacionales han aumentado significativamente ya que se trata de estimaciones puntuales que no tienen en cuenta el error en la estimación.\n\n\n\n\n\nCalcular el intervalo de confianza para la media de la diferencia entre las ventas de después y antes de la campaña de publicidad. ¿Existen pruebas suficientes para afirmar con un \\(95\\%\\) de confianza que la campaña de publicidad ha aumentado las ventas?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(broom)\n# Añadimos al data frame una nueva variable con la diferencia entre las ventas de después y antes\ndf$incremento &lt;- df$despues - df$antes\n# Aplicamos el test de la t de student para una muestra.\ntidy(t.test(df$incremento)) |&gt; \n    # Obtenemos la estimación de la media de la diferencia entre las ventas de después y antes y el intervalo de confianza del 95%.\n    select(estimate, conf.low, conf.high) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n4\n-0.8129585\n8.812959\n\n\n\n\nPodemos llegar a este mismo intervalo de confianza sin necesitad de calcular previamente la diferencia entre las ventas de después y antes, pasándole directamente las dos variables a comparar a la función t.test añadiendo el parámetro paired = TRUE.\n\n# Aplicamos el test de la t de student para muestras pareadas.\ntidy(t.test(df$despues, df$antes, paired = TRUE)) |&gt; \n    # Obtenemos la estimación de la media de la diferencia entre las ventas de después y antes y el intervalo de confianza del 95%.\n    select(estimate, conf.low, conf.high) |&gt; \n    kable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n4\n-0.8129585\n8.812959\n\n\n\n\nComo el intervalo contiene tanto valores negativos como positivos, y en particular contiene el 0, no podemos concluir que existen diferencias significativas entre las ventas medias de después y antes, y por tanto no hay pruebas suficientes para afirmar con un \\(95\\%\\) de confianza que la campaña de publicidad es efectiva.\n\n\n\n\n\nSi añadimos a la muestra dos nuevas farmacia con unas ventas antes de \\(155\\) y \\(160\\) unidades y unas ventas después de \\(170\\) y \\(180\\) unidades respectivamente, ¿qué efecto tendrán sobre el intervalo de confianza para la media de la diferencia entre las ventas de después y antes de la campaña de publicidad? ¿Podemos afirmar ahora con un \\(95\\%\\) de confianza que la campaña de publicidad ha aumentado las ventas? En tal caso, ¿en cuanto se incrementarán las ventas medias?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nComo las ventas se han incrementado bastante en estas dos nuevas farmacias, la media de la diferencia entre las ventas de después y antes de la campaña de publicidad y el correspondiente intervalo de confianza se desplazará hacia la derecha, es decir, aumentará.\n\n# Añadimos al data frame los datos de la nueva farmacia.\ndf &lt;- rbind(df, c(155, 170, 170-155), c(160, 180, 180 - 160))\n# Volvemos a calcular el intervalo de confianza para la media de la diferencia entre las ventas de después y antes.\ntidy(t.test(df$incremento)) |&gt; \n    select(estimate, conf.low, conf.high) |&gt; \n    kable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n6.7\n1.178915\n12.22108\n\n\n\n\nComo ahora el intervalo es completamente positivo, podemos afirmar con un \\(95\\%\\) de confianza que la media de la diferencia entre las ventas de después y antes de la campaña de publicidad es positiva, es decir ha habido un incremento estadísticamente significativo de las ventas después de la campaña y el incremento medio estará entre \\(1.1789\\) y \\(12.2211\\) unidades más al mes.\n\n\n\n\n\n\n\nEjercicio 8.2 Una central de productos lácteos recibe diariamente la leche de dos granjas \\(X\\) e \\(Y\\). Para analizar la calidad de la leche, durante una temporada, se controla el porcentaje de materia grasa de la leche que proviene de ambas granjas, con los siguientes resultados:\n\\[\n\\begin{array}{c|c}\nX & Y \\\\\n\\hline\n\\begin{array}[t]{rr}\n3.4 & 3.4 \\\\\n3.2 & 3.5 \\\\\n3.3 & 3.3 \\\\\n3.2 & 3.2 \\\\\n3.3 & 3.0 \\\\\n3.1 & 3.2 \\\\\n\\end{array}\n&\n\\begin{array}[t]{rr}\n2.8 & 2.9 \\\\\n3.0 & 3.2 \\\\\n3.2 & 3.1 \\\\\n2.9 & 2.9 \\\\\n3.1 & 3.2 \\\\\n2.9 & 3.1 \\\\\n3.3 & 3.2 \\\\\n3.2 & 3.3 \\\\\n\\end{array}\n\\end{array}\n\\]\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- tibble(\n    grasa = c(3.4, 3.2, 3.3, 3.2, 3.3, 3.1, 3.4, 3.5, 3.3, 3.2, 3.0, 3.2, 2.8, 3.0, 3.2, 2.9, 3.1, 2.9, 3.3, 3.2, 2.9, 3.2, 3.1, 2.9, 3.2, 3.1, 3.2, 3.3),\n    granja = factor(c(rep(\"X\", 12), rep(\"Y\", 16)))\n)\n\n\n\n\n\n\nCalcular el intervalo de confianza para el cociente de varianzas del porcentaje de materia grasa de la leche procedente de ambas granjas. ¿Existen diferencias estadísticamente significativas entre las varianzas de la grasa de las leches de las dos granjas?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(broom)\nlibrary(knitr)\n# Aplicamos el test F de Fisher para la comparación de varianzas.\ntidy(var.test(grasa ~ granja, data = df)) |&gt; \n# Obtenemos la estimación del cociente de varianzas de la grasa de la leche de las granjas y el intervalo de confianza del 95%.\n    select(estimate, conf.low, conf.high) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n0.7420547\n0.2467078\n2.470994\n\n\n\n\nComo el intervalo de confianza contiene el valor \\(1\\), no podemos afirmar que haya diferencias estadísticamente significativas entre las varianzas del porcentaje de materia grasa de las leches de las dos granjas, y por tanto podemos asumir que la variabilidad es parecida en ambas granjas.\n\n\n\n\n\nCalcular el intervalo de confianza para la diferencia en el porcentaje medio de materia grasa de la leche procedente de las dos granjas. ¿Se puede concluir que existen diferencias significativas en el porcentaje medio de grasa de la leche de las dos granjas? En tal caso, ¿qué leche tiene mayor porcentaje de grasa?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Aplicamos el test de la t de student para muestras independientes con varianzas iguales.\ntidy(t.test(grasa ~ granja, equal.var = TRUE, data = df)) |&gt; \n# Obtenemos la estimación de la diferencia de las medias de la grasa de la leche de las granjas y el intervalo de confianza del 95%.\n    select(estimate, conf.low, conf.high) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kable()\n\n\n\nestimate\nconf.low\nconf.high\n\n\n0.1770833\n0.0609291\n0.2932376\n\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLa función t.test calcula el intervalo de confianza para la diferencia de medias de primer nivel (en este caso \\(X\\)) y el segundo nivel (en este caso \\(Y\\)) del factor granja. Si se desea obtener el intervalo para diferencia de medias entre \\(Y\\) y \\(X\\) es necesario reordenar los niveles del factor.\n\n\nComo el intervalo de confianza es completamente positivo, y por tanto no contiene el \\(0\\), podemos afirmar con un \\(95\\%\\) de confianza que existen diferencias estadísticamente entre el porcentaje de grasa de ambas granjas. Como además el intervalo es para la diferencia entre las medias del porcentaje de leche de la granja \\(X\\) y de la granja \\(Y\\), podemos concluir que el porcentaje medio de grasa de la leche de la granja \\(X\\) es significativamente mayor que el de la granja \\(Y\\).\n\n\n\n\n\n\n\nEjercicio 8.3 El conjunto de datos biblioteca.csv contiene los resultados de una encuesta realizada en una universidad, sobre si el alumnado utiliza habitualmente (al menos una vez a la semana) la biblioteca.\n\n\nCrear conjunto de datos con los datos de la muestra a partir del fichero biblioteca.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/biblioteca.csv\")\n\n\n\n\n\n\nCalcular el intervalo de confianza para la diferencia entre las proporciones de chicos y chicas que utilizan habitualmente la biblioteca. ¿Existen diferencias significativas entre las proporciones de chicos y chicas que usan habitualmente la biblioteca? En tal caso, ¿quienes utilizan más la biblioteca?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Calculamos las frecuencias absolutas y los tamaños muestrales de las muestras de ambos sexos.\ndf2 &lt;- df |&gt; \n    group_by(sexo) |&gt; \n    count(respuesta, name = \"frec\") |&gt; \n    mutate(n = sum(frec)) |&gt; \n    filter(respuesta == \"si\")\n\n# Aplicamos el test de comparación de proporciones.\ntidy(prop.test(df2$frec, df2$n)) |&gt; \n# Obtenemos la estimación de la diferencia de las proporciones de chicos y chicas que utilizan habitualmente la biblioteca y el intervalo de confianza del 95%.\n    select(estimate1, estimate2, conf.low, conf.high) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kable()\n\n\n\nestimate1\nestimate2\nconf.low\nconf.high\n\n\n0.1875\n0.7222222\n-0.8755141\n-0.1939304\n\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLa función prop.test calcula el intervalo de confianza para la diferencia de proporciones de la primera muestra (en este caso chicos) la segunda (en este caso chicas). Si se desea obtener el intervalo para diferencia de proporciones entre chicas y chicos es necesario introducir primero las frecuencias de las chicas.\n\n\nComo el intervalo de confianza es completamente negativo, y por tanto no contiene el \\(0\\), podemos afirmar con un \\(95\\%\\) de confianza que existen diferencias estadísticamente significativas entre la proporción de chicos y chicas que utilizan habitualmente la biblioteca. Como además el intervalo de confianza es para la diferencia entre la proporción de chicos y chicas, se puede concluir que la proporción de chicas que usan habitualmente la biblioteca es significativamente mayor que la de chicos.\n\n\n\n\n\n\n\nEjercicio 8.4 Un profesor universitario ha tenido dos grupos de clase a lo largo del año: uno con horario de mañana y otro de tarde. En el de mañana, sobre un total de 80 alumnos, han aprobado 55; y en el de tarde, sobre un total de 90 alumnos, han aprobado 32.\n\n\n¿Existen diferencias significativas en el porcentaje de aprobados de los dos grupos? En tal caso, ¿en qué turno hay un porcentaje mayor de aprobados y cuánto mayor es?\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n# Aplicamos el test de comparación de proporciones.\ntidy(prop.test(c(55, 32), c(80, 90))) |&gt; \n# Obtenemos la estimación de la diferencia de las proporciones de chicos y chicas que utilizan habitualmente la biblioteca y el intervalo de confianza del 95%.\n    select(estimate1, estimate2, conf.low, conf.high) |&gt; \n    # Multiplicamos por 100 todas las columnas para obtener porcentajes.\n    mutate(across(everything(), ~ .x * 100)) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kable()\n\n\n\nestimate1\nestimate2\nconf.low\nconf.high\n\n\n68.75\n35.55556\n17.83764\n48.55125\n\n\n\n\nComo el intervalo de confianza es completamente positivo, y por tanto no contiene el \\(0\\), podemos afirmar con un \\(95\\%\\) de confianza que existen diferencias estadísticamente significativas entre el porcentaje de aprobados en los turnos de mañana y tarde. Como además el intervalo de confianza es para la diferencia entre el porcentaje de aprobados en la mañana y el porcentaje de aprobados en la tarde, se puede concluir que la proporción de aprobados en la mañana es significativamente mayor que en la tarde, en particular, entre un \\(17.83\\%\\) y un \\(48.55\\%\\) mayor.\n\n\n\n\n\n¿Puede concluirse que las diferencias son debidas al turno horario?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nNo puede concluirse que la diferencia entre el porcentaje de aprobados de la mañana y la tarde sea debido al factor horario, ya que las diferencias podrían deberse a otros factores como el tipo de alumnos, el profesor, la metodología, el examen, etc. Para poder concluir que la causa de la diferencia en el porcentaje de aprobados es el turno horario, el resto de factores deberían ser iguales en la mañana y la tarde.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones</span>"
    ]
  },
  {
    "objectID": "09-contrastes-hipotesis-parametricos-una-y-dos-poblaciones.html",
    "href": "09-contrastes-hipotesis-parametricos-una-y-dos-poblaciones.html",
    "title": "\n9  Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n",
    "section": "",
    "text": "9.1 Ejercicios Resueltos\nPara la realización de esta práctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones</span>"
    ]
  },
  {
    "objectID": "09-contrastes-hipotesis-parametricos-una-y-dos-poblaciones.html#ejercicios-resueltos",
    "href": "09-contrastes-hipotesis-parametricos-una-y-dos-poblaciones.html#ejercicios-resueltos",
    "title": "\n9  Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n",
    "section": "",
    "text": "library(tidyverse)\n# Incluye los siguientes paquetes:\n# - dplyr: para el preprocesamiento y manipulación de datos.\nlibrary(broom) # para convertir las listas con los resúmenes de los modelos de regresión a formato organizado.\nlibrary(tidymodels) # para realizar contrastes de hipótesis en formato tidy.\nlibrary(pwr) # para el cálculo de tamaños muestrales.\nlibrary(knitr) # para el formateo de tablas.\n\nEjercicio 9.1 Para averiguar si en una determinada población existen menos hombres que mujeres se plantea el siguiente contraste de hipótesis sobre la proporción de hombres que hay en la población:\n\\[\\begin{align*}\nH_0 &: p=0.5\\\\\nH_1 &: p&lt;0.5\n\\end{align*}\\]\nPara ello se ha tomado una muestra aleatoria con reemplazamiento de \\(10\\) personas.\n\n\nSuponiendo cierta la hipótesis nula, ¿qué distribución sigue la variable que mide el número de hombres en la muestra de tamaño 10?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSuponiendo cierta la hipótesis nula, es decir, que la proporción de hombres en la población es \\(0.5\\), el número de hombres en una muestra aleatoria con reemplazamiento de 10 personas sigue una distribución Binomial \\(B(10, 0.5)\\).\n\n\n\n\n\nSuponiendo cierta la hipótesis nula, ¿cuál es la probabilidad de que en la muestra se obtengan 0 hombres? ¿Se aceptaría la hipótesis nula en tal caso?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que calcular la probabilidad de \\(0\\) hombres con la distribución \\(B(10, 0.5)\\).\n\npbinom(0, 10, 0.5)\n\n[1] 0.0009765625\n\n\nComo se ve, la probabilidad de obtener 0 hombres en una muestra aleatoria con reemplazamiento de 10 personas tomadas de una población con el mismo número de hombres y mujeres es muy baja, por lo que, en este caso rechazaríamos la hipótesis nula sin dudarlo.\n\n\n\n\n\nSuponiendo cierta la hipótesis nula, si se decide rechazarla cuando en la muestra haya 2 o menos hombres, ¿cuál es el riesgo de equivocarse?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que calcular la probabilidad de haya \\(2\\) o menos hombres con la distribución \\(B(10, 0.5)\\).\n\npbinom(2, 10, 0.5)\n\n[1] 0.0546875\n\n\nLa probabilidad de cometer un error de tipo I (rechazar la hipótesis nula cuando es cierta) es \\(0.0547\\).\n\n\n\n\n\nSi el máximo riesgo de error de tipo I \\(\\alpha\\) que se tolera es \\(0.05\\), ¿qué número de hombres en la muestra formarían la región de rechazo de la hipótesis nula?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSi el máximo riesgo de error de tipo I se establece en \\(\\alpha=0.05\\), solo podría rechazarse la hipótesis nula si en la muestra aleatoria con reemplazamiento de \\(10\\) personas se obtuviese \\(0\\) o \\(1\\) hombres. Si se obtuviesen \\(2\\) hombres ya no se podría rechazar la hipótesis nula porque la probabilidad de equivocarnos es mayor de \\(0.05\\) como se ha visto en el apartado anterior.\n\n\n\n\n\nSuponiendo que la proporción real de hombres en la población fuese de \\(0.4\\), ¿cuál es la potencia del contraste para la región de rechazo del apartado anterior?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nLa potencia de un contraste es \\(1-\\beta\\), donde \\(\\beta\\) es la probabilidad de cometer un error de tipo II (aceptar la hipótesis nula cuando es falsa).\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que calcular la probabilidad de haya \\(1\\) o menos hombres con la distribución \\(B(10, 0.4)\\).\n\npbinom(1, 10, 0.4)\n\n[1] 0.0463574\n\n\nLa potencia del contraste suponiendo que la proporción real de hombres en la población es \\(0.4\\), es \\(0.0464\\) que es muy baja.\n\n\n\n\n\nSi en lugar de una muestra de tamaño 10 se tomase una muestra de tamaño 100, y haciendo uso de la aproximación de una distribución binomial mediante una normal, ¿qué número de hombres en la muestra formarían la región de rechazo para un riesgo \\(\\alpha=0.05\\)? ¿Qué potencia tendría ahora el contraste si la proporción real de hombres fuese de \\(0.4\\)? ¿Es mejor o peor contraste que el anterior?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nSi tomamos una muestra de \\(100\\) personas, entonces el número de hombres en la muestra si en la población hay el mismo número de hombres que de mujeres sigue una distribución binomial \\(B(100,0.5)\\), que puede aproximarse mediante una distribución normal \\(N(50,5)\\), así que tenemos que calcular el percentil \\(5\\) de esta distribución.\n\nqnorm(0.05, 50, 5)\n\n[1] 41.77573\n\n\nPor tanto, para un riesgo \\(\\alpha=0.05\\), rechazaremos la hipótesis nula si en la muestra se obtienen \\(41\\) o menos hombres.\nSi la proporción real de hombres fuese de \\(0.4\\), la potencia del contraste es la probabilidad de obtener \\(41\\) o menos hombres con una distribución binomial \\(B(100, 0.4)\\).\n\npbinom(41, 100, 0.4)\n\n[1] 0.6225327\n\n\nAhora la potencia del contraste ha aumentado hasta \\(0.6225\\) que es mucho mayor que la del contraste anterior.\n\n\n\n\n\n\n\nEjercicio 9.2 Se sabe que para que un fármaco sea efectivo, la concentración de su principio activo debe ser de al menos \\(16\\) mg/mm\\(^3\\). Una farmacia va a comprar un lote de este medicamento, pero antes quiere asegurarse de que los medicamentos del lote son efectivos y para ello analiza la concentración de principio activo en una muestra aleatoria de \\(10\\) envases tomados del lote, obteniendo los siguientes resultados en mg/mm\\(^{3}\\):\n\\[\n17.6 \\quad 19.2 \\quad 21.3 \\quad 15.1 \\quad 17.6 \\quad 18.9 \\quad 16.2 \\quad 18.3 \\quad 19.0 \\quad 16.4\n\\]\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\ndf &lt;- data.frame(concentracion = c(17.6, 19.2, 21.3, 15.1, 17.6, 18.9, 16.2, 18.3, 19.0, 16.4 ))\n\n\n\n\n\n\nRealizar un contraste de hipótesis para ver si la concentración media de principio activo es diferente de \\(18\\) mg/mm\\(^3\\).\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara realizar un contraste de hipótesis para la media de una población podemos utilizar la función t.test del paquete base stats.\nSi queremos mostrar la salida del test en formato de tabla podemos utilizar la función tidy del paquete broom.\nOtra opción es utilizar la función t_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que realizar el contraste bilateral\n\\[\\begin{align*}\nH_0 &: \\mu=18\\\\\nH_1 &: \\mu\\neq 18\n\\end{align*}\\]\n\n\nstats\ntidymodels\n\n\n\n\nt.test(df$concentracion, mu = 18)\n\n\n    One Sample t-test\n\ndata:  df$concentracion\nt = -0.07078, df = 9, p-value = 0.9451\nalternative hypothesis: true mean is not equal to 18\n95 percent confidence interval:\n 16.68158 19.23842\nsample estimates:\nmean of x \n    17.96 \n\n\nPara mostrar la salida en formato tabla.\n\nlibrary(broom)\nlibrary(knitr)\ntidy(t.test(df$concentracion, mu = 18)) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n17.96\n-0.0707795\n0.9451211\n9\n16.68158\n19.23842\nOne Sample t-test\ntwo.sided\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    t_test(response = concentracion, mu = 18) |&gt; \n    kable() \n\n\n\n\n\n\n\n\n\n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n-0.0707795\n9\n0.9451211\ntwo.sided\n17.96\n16.68158\n19.23842\n\n\n\n\n\n\n\nComo el p-valor del contraste es \\(0.9451\\) que es mucho mayor que el riesgo \\(\\alpha=0.05\\), no rechazamos la hipótesis nula.\nObsérvese que el valor de la media muestral es \\(17.96\\) que está muy cerca del valor que establece la hipótesis nula, por lo que sería una locura rechazar la hipótesis nula con esta muestra.\n\n\n\n\n\nRealizar un contraste de hipótesis para ver si la concentración media de principio activo es diferente de \\(19.5\\) mg/mm\\(^3\\).\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que realizar el contraste bilateral\n\\[\\begin{align*}\nH_0 &: \\mu=19.5\\\\\nH_1 &: \\mu\\neq 19.5\n\\end{align*}\\]\n\n\nstats\ntidymodels\n\n\n\n\ntidy(t.test(df$concentracion, mu = 19.5)) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n17.96\n-2.725012\n0.0234149\n9\n16.68158\n19.23842\nOne Sample t-test\ntwo.sided\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    t_test(response = concentracion, mu = 19.5) |&gt; \n    kable() \n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n-2.725012\n9\n0.0234149\ntwo.sided\n17.96\n16.68158\n19.23842\n\n\n\n\n\n\n\nComo el p-valor del contraste es \\(0.0234\\) que es menor que el riesgo \\(\\alpha=0.05\\), rechazamos la hipótesis nula y concluimos que la concentración media es significativamente diferente de \\(19\\).\nObsérvese que ahora el valor de la media muestral es \\(17.96\\) está mucho más lejos del valor que establece la hipótesis nula, por lo que tiene más lógica rechazar la hipótesis nula.\n\n\n\n\n\nSi el fabricante del lote asegura haber aumentado la concentración de principio activo con respecto a anteriores lotes, en los que la media era de \\(17\\) mg/mm\\(^3\\), ¿podemos aceptar la afirmación del fabricante?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nAhora tenemos que realizar el contraste unilateral\n\\[\\begin{align*}\nH_0 &: \\mu=17\\\\\nH_1 &: \\mu&gt; 17\n\\end{align*}\\]\n\n\nstats.\ntidymodels\n\n\n\n\ntidy(t.test(df$concentracion, mu = 17, alternative = \"greater\")) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n17.96\n1.698709\n0.0617985\n9\n16.92404\nInf\nOne Sample t-test\ngreater\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    t_test(response = concentracion, mu = 19.5, alternative = \"greater\") |&gt; \n    kable() \n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n-2.725012\n9\n0.9882925\ngreater\n17.96\n16.92404\nInf\n\n\n\n\n\n\n\nComo el p-valor del contraste es \\(0.0618\\) que es mayor que el riesgo \\(\\alpha=0.05\\), no podemos rechazar la hipótesis nula y concluimos que con esta muestra no hay pruebas significativas de que la afirmación del fabricante sea cierta.\n\n\n\n\n\n¿Cuál sería el tamaño muestral requerido para poder detectar una diferencia de \\(0.5\\) mg/mm\\(^{3}\\) más con un nivel de significación \\(\\alpha=0.05\\) y una potencia \\(1-\\beta=0.8\\)?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nAhora tenemos que realizar el contraste unilateral\n\nlibrary(pwr)\nefecto &lt;- 0.5 / sd(df$concentracion)\npower.t.test(d = efecto, sig.level = 0.05, power = 0.8, type = \"one.sample\", alternative = \"two.sided\")\n\n\n     One-sample t test power calculation \n\n              n = 102.2077\n          delta = 0.2797806\n             sd = 1\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\n\n\n\n\n\n\n\nEjercicio 9.3 El conjunto de datos biblioteca.csv contiene los resultados de una encuesta realizada en una universidad, sobre si el alumnado utiliza habitualmente (al menos una vez a la semana) la biblioteca.\n\n\nCrear conjunto de datos con los datos de la muestra a partir del fichero biblioteca.csv.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/biblioteca.csv\")\n\n\n\n\n\n\nContrastar si el porcentaje de alumnos que utiliza habitualmente la biblioteca es superior al \\(40\\%\\).\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara realizar un contraste de hipótesis para la proporción de una población podemos utilizar la función prop.test del paquete base stats.\nSi queremos mostrar la salida del test en formato de tabla podemos utilizar la función tidy del paquete broom.\nOtra opción es utilizar la función prop_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que realizar el contraste unilateral\n\\[\\begin{align*}\nH_0 &: p = 0.4\\\\\nH_1 &: p &gt; 0.4\n\\end{align*}\\]\n\n\nstats\ntidymodels\n\n\n\n\nlibrary(broom)\nlibrary(knitr)\nfrec &lt;- table(df$respuesta)\ntidy(prop.test(frec[\"si\"], nrow(df), p = 0.4, alternative = \"greater\")) |&gt; \nkable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.4705882\n0.442402\n0.2529827\n1\n0.3238772\n1\n1-sample proportions test with continuity correction\ngreater\n\n\n\n\n\n\n\nlibrary(tidymodels)\nlibrary(knitr)\ndf  |&gt; \n    prop_test(response = respuesta, p = 0.4, alternative = \"greater\", success = \"si\") |&gt;\n    kable()\n\n\n\nstatistic\nchisq_df\np_value\nalternative\n\n\n0.442402\n1\n0.2529827\ngreater\n\n\n\n\n\n\n\nComo el p-valor del contraste es \\(0.253\\), que es mayor que el riesgo \\(\\alpha=0.05\\), no rechazamos la hipótesis nula.\n\n\n\n\n\n\n\nEjercicio 9.4 Un estudio trata de averiguar si existen diferencias significativas en la edad media a la que los niños de África y Europa comienzan a andar por sí solos. Los investigadores obtuvieron los siguientes datos para la edad al comenzar a andar (expresada en meses):\n\\[\\begin{align*}\n\\textrm{África}:& \\ 9.5-10.5-9.0-9.8-10.0-13.0-10.0-13.5-10.0-9.8\\\\\n\\textrm{Europa}:& \\ 12.5-9.5-13.5-13.8-12.0-13.8-12.5-9.5-12.0-13.5-12.0-12.0\n\\end{align*}\\]\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- tibble(\n    edad = c(9.5, 10.5, 9.0, 9.8, 10.0, 13.0, 10.0, 13.5, 10.0, 9.8, 12.5, 9.5, 13.5, 13.8, 12.0, 13.8, 12.5, 9.5, 12.0, 13.5, 12.0, 12.0),\n    continente = factor(c(rep(\"África\", 10), rep(\"Europa\", 12)))\n)\n\n\n\n\n\n\nRealizar un contraste de hipótesis con un nivel de significación de \\(0.05\\) para ver si existen diferencias estadísticamente significativas entre las edades medias a las que comienzan a andar los niños de África y los de Europa.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara realizar un contraste de hipótesis para la diferencia de medias de dos población independientes utilizar la función t.test del paquete base stats. Este test da resultados diferentes dependiendo de si las dos poblaciones que se comparan tienen varianzas diferentes o no, por lo que previamente debemos realizar un contraste de comparación de varianzas mediante la función var.test del paquete stats. Si se acepta la hipótesis de igualdad de varianzas mediante este test, en la función t.test hay que añadir el parámetro var.equal = TRUE.\nSi queremos mostrar la salida del test en formato de tabla podemos utilizar la función tidy del paquete broom.\nOtra opción es utilizar la función t_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que realizar el contraste bilateral\n\\[\\begin{align*}\nH_0 &: \\mu_A = \\mu_E \\\\\nH_1 &: \\mu_A \\neq \\mu_E\n\\end{align*}\\]\nRealizamos primero el test F para la comparación de las varianzas de las dos poblaciones.\n\nvar.test(edad ~ continente, data = df)\n\n\n    F test to compare two variances\n\ndata:  edad by continente\nF = 1.0558, num df = 9, denom df = 11, p-value = 0.9164\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.2942791 4.1305381\nsample estimates:\nratio of variances \n          1.055843 \n\n\nComo el p-valor del contraste es \\(0.9164\\), que es mayor que el riesgo \\(\\alpha=0.05\\), no se rechaza la hipótesis nula y concluimos que no hay una diferencia estadísticamente significativas entre las varianzas de las dos poblaciones.\nA continuación realizamos el contraste de comparación de medias.\n\n\nstats\ntidymodels\n\n\n\n\nt.test(edad ~ continente, data = df, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  edad by continente\nt = -2.6982, df = 20, p-value = 0.01383\nalternative hypothesis: true difference in means between group África and group Europa is not equal to 0\n95 percent confidence interval:\n -3.0260864 -0.3872469\nsample estimates:\nmean in group África mean in group Europa \n            10.51000             12.21667 \n\n\nPara mostrar la salida en formato tabla.\n\nlibrary(broom)\nlibrary(knitr)\ntidy(t.test(edad ~ continente, data = df, var.equal = TRUE)) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n-1.706667\n10.51\n12.21667\n-2.698189\n0.0138327\n20\n-3.026086\n-0.3872469\nTwo Sample t-test\ntwo.sided\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \n    t_test(edad ~ continente, var.equal = TRUE) |&gt; \n    kable() \n\nWarning: The statistic is based on a difference or ratio; by default, for\ndifference-based statistics, the explanatory variable is subtracted in the\norder \"África\" - \"Europa\", or divided in the order \"África\" / \"Europa\" for\nratio-based statistics. To specify this order yourself, supply `order =\nc(\"África\", \"Europa\")`.\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n-2.698189\n20\n0.0138327\ntwo.sided\n-1.706667\n-3.026086\n-0.3872469\n\n\n\n\n\n\n\nComo el p-valor del contraste es \\(0.0138\\) que es menor que el riesgo \\(\\alpha=0.05\\), podemos rechazar la hipótesis nula y se concluye que existe una diferencia estadísticamente significativa entre las edades medias a las que comienzan a andar los niños de África y Europa.\nAunque se ha planteado un contraste bilateral, observando el intervalo de confianza para la diferencia entre la edad media de los niños de África y los de Europa, que es completamente negativo, se puede concluir con un \\(95\\%\\) de confianza que los niños de África comienzan a andar entre \\(0.3872\\) meses y \\(3.261\\) meses antes que los niños de Europa en promedio.\n\n\n\n\n\n\n\nEjercicio 9.5 El conjunto de datos hipertension.csv contiene datos de la presión arterial de una muestra de individuos hipertensos, antes y después de aplicarles tres tratamientos (Placebo, IECA y Antagonista del Calcio + Diurético).\n\n\nCrear un conjunto de datos con los datos de la muestra.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nlibrary(tidyverse)\ndf &lt;- read_csv(\"https://aprendeconalf.es/estadistica-practicas-r/datos/hipertension.csv\")\nglimpse(df)\n\nRows: 100\nColumns: 15\n$ ...1      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ NOMBRE    &lt;chr&gt; \"SGL\", \"JCZ\", \"APZ\", \"NDG\", \"CLO\", \"LFZ\", \"OAR\", \"SGH\", \"ZLZ…\n$ EDAD      &lt;dbl&gt; 57, 40, 30, 44, 38, 48, 41, 31, 39, 31, 34, 27, 32, 59, 29, …\n$ SEXO      &lt;chr&gt; \"Mujer\", \"Mujer\", \"Hombre\", \"Hombre\", \"Mujer\", \"Hombre\", \"Mu…\n$ ESTATURA  &lt;dbl&gt; 165, 154, 156, 181, 184, 179, 159, 153, 172, 154, 170, 154, …\n$ PESO      &lt;dbl&gt; 93, 80, 74, 88, 86, 73, 70, 57, 55, 50, 64, 57, 54, 77, 91, …\n$ ESTRES    &lt;dbl&gt; 42, 30, 21, 33, 36, 22, 31, 12, 21, 24, 32, 20, 30, 26, 18, …\n$ PAD_INI   &lt;dbl&gt; 80, 92, 87, 84, 88, 70, 91, 84, 69, 84, 88, 85, 83, 88, 75, …\n$ PAD_FIN   &lt;dbl&gt; 84, 89, 83, 79, 80, 82, 80, 73, 67, 77, 75, 83, 80, 72, 72, …\n$ PAS_INI   &lt;dbl&gt; 180, 167, 148, 167, 170, 148, 173, 140, 155, 153, 166, 153, …\n$ PAS_FIN   &lt;dbl&gt; 155, 140, 130, 141, 142, 128, 132, 123, 115, 135, 128, 133, …\n$ TAB_INI   &lt;chr&gt; \"si\", \"no\", \"no\", \"si\", \"si\", \"si\", \"no\", \"no\", \"no\", \"no\", …\n$ TAB_FIN   &lt;chr&gt; \"si\", \"no\", \"no\", \"no\", \"si\", \"si\", \"no\", \"no\", \"no\", \"no\", …\n$ CAR_ISQUE &lt;chr&gt; \"si\", \"no\", \"no\", \"si\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ FARMACO   &lt;chr&gt; \"Antagonista Calcio + Diurético\", \"Antagonista Calcio + Diur…\n\n\n\n\n\n\n\nRealizar un contraste de hipótesis para ver si hay la media de la presión sistólica ha disminuido significativamente.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nPara realizar un contraste de hipótesis para la diferencia de medias de dos población pareadas utilizar la función t.test del paquete base stats añadiendo el parámetro paired = TRUE.\nSi queremos mostrar la salida del test en formato de tabla podemos utilizar la función tidy del paquete broom.\nOtra opción es utilizar la función t_test de la colección de paquetes tidymodels, que ofrece ya la salida en formato tidy.\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que realizar el contraste de hipótesis unilateral\n\\[\\begin{align*}\nH_0 &: \\mu_I = \\mu_F \\\\\nH_1 &: \\mu_I \\neq \\mu_F\n\\end{align*}\\]\n\n\nstats\ntidymodels\n\n\n\n\nt.test(df$PAS_INI, df$PAS_FIN, paired = TRUE, alternative = \"greater\")\n\n\n    Paired t-test\n\ndata:  df$PAS_INI and df$PAS_FIN\nt = 31.743, df = 99, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 26.99975      Inf\nsample estimates:\nmean difference \n          28.49 \n\n\nPara mostrar la salida en formato tabla.\n\nlibrary(broom)\nlibrary(knitr)\ntidy(t.test(df$PAS_INI, df$PAS_FIN, paired = TRUE, alternative = \"greater\")) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n28.49\n31.74278\n0\n99\n26.99975\nInf\nPaired t-test\ngreater\n\n\n\n\n\n\n\nlibrary(tidymodels)\ndf |&gt; \nmutate(PAS_DIF = PAS_INI - PAS_FIN) |&gt; \n    t_test(response = PAS_DIF, alternative = \"greater\") |&gt; \n    kable() \n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n31.74278\n99\n0\ngreater\n28.49\n26.99975\nInf\n\n\n\n\n\n\n\nComo el p-valor del contraste es prácticamente \\(0\\), que es mucho menor que el riesgo \\(\\alpha=0.05\\), podemos rechazar con contundencia la hipótesis nula y se concluye que existe una diferencia estadísticamente muy significativa entre las medias de la presión arterial sistólica antes y después del tratamiento.\n\n\n\n\n\nRealizar el mismo contraste de antes, pero para cada tratamiento por separado.\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nstats\ntidymodels\n\n\n\n\ndf |&gt; \n    nest(data = -FARMACO) |&gt; \n    mutate(test = map(data, ~ tidy(t.test(.x$PAS_INI, .x$PAS_FIN, paired = TRUE, alternative = \"greater\")))) |&gt; \n    unnest(test) |&gt;\n    select(-data) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFARMACO\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\nAntagonista Calcio + Diurético\n26.63636\n99.52715\n0\n32\n26.18303\nInf\nPaired t-test\ngreater\n\n\nPlacebo\n18.63636\n58.37322\n0\n32\n18.09557\nInf\nPaired t-test\ngreater\n\n\nIECA\n39.85294\n145.42329\n0\n33\n39.38915\nInf\nPaired t-test\ngreater\n\n\n\n\n\n\n\n\ndf |&gt; \nmutate(PAS_DIF = PAS_INI - PAS_FIN) |&gt; \nnest(data = -FARMACO) |&gt; \n    mutate(test = map(data, ~ t_test(x = .x, response = PAS_DIF, paired = TRUE, alternative = \"greater\"))) |&gt; \n    unnest(test) |&gt;\n    select(-data) |&gt; \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nFARMACO\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n\nAntagonista Calcio + Diurético\n99.52715\n32\n0\ngreater\n26.63636\n26.18303\nInf\n\n\nPlacebo\n58.37322\n32\n0\ngreater\n18.63636\n18.09557\nInf\n\n\nIECA\n145.42329\n33\n0\ngreater\n39.85294\n39.38915\nInf\n\n\n\n\n\n\n\n\nComo se puede observar, todos los p-valores son menores que el nivel de significación \\(\\alpha=0.05\\), por lo que se puede concluir que existe una diferencia estadísticamente muy significativa entre las medias de la presión arterial sistólica antes y después de cada tratamiento. Si observamos los intervalos de confianza, se observa que la mayor diferencia entre se da para el tratamiento IECA, después el Antagonista del Calcio y finalmente el Placebo.\n\n\n\n\n\n\n\nEjercicio 9.6 Un profesor universitario ha tenido dos grupos de clase a lo largo del año: uno con horario de mañana y otro de tarde. En el de mañana, sobre un total de \\(80\\) alumnos, han aprobado \\(55\\); y en el de tarde, sobre un total de \\(90\\) alumnos, han aprobado \\(32\\). ¿Se puede afirmar que hay diferencias significativas entre los porcentajes de aprobados en ambos grupos?\n\n\n\n\n\n\nSolución\n\n\n\n\n\nTenemos que realizar el contraste bilateral\n\\[\\begin{align*}\nH_0 &: p_M = p_T \\\\\nH_1 &: p_M \\neq p_T\n\\end{align*}\\]\n\nlibrary(broom)\nlibrary(knitr) \n# Aplicamos el test de comparación de proporciones.\ntidy(prop.test(c(55, 32), c(80, 90))) |&gt; \n    # Multiplicamos por 100 todas las columnas para obtener porcentajes.\n    mutate(across(c(estimate1, estimate2, conf.low, conf.high), ~ .x * 100)) |&gt; \n    # Mostramos por pantalla en formato tabla.\n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n68.75\n35.55556\n17.37244\n3.07e-05\n1\n17.83764\n48.55125\n2-sample test for equality of proportions with continuity correction\ntwo.sided\n\n\n\n\nComo el p-valor del contraste es prácticamente \\(0\\), que es mucho menor que el riesgo \\(\\alpha=0.05\\), podemos rechazar con contundencia la hipótesis nula y se concluye que existe una diferencia estadísticamente muy significativa entre los porcentajes de aprobados en la mañana y la tarde. Si observamos el intervalo de confianza para diferencia entre la proporción de aprobados en la mañana y la tarde, que es completamente positivo, se concluye con un \\(95\\%\\) de confianza que el porcentaje de aprobados en la mañana es significativamente mayor que en la tarde.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones</span>"
    ]
  },
  {
    "objectID": "09-contrastes-hipotesis-parametricos-una-y-dos-poblaciones.html#ejercicios-propuestos",
    "href": "09-contrastes-hipotesis-parametricos-una-y-dos-poblaciones.html#ejercicios-propuestos",
    "title": "\n9  Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones\n",
    "section": "\n9.2 Ejercicios propuestos",
    "text": "9.2 Ejercicios propuestos\n\nEjercicio 9.7 El fichero pulso.csv contiene información sobre el pulso de un grupo de pacientes que han realizado distintos ejercicios: pulso en reposo (pulse1), pulso después de hacer ejercicio (pulse2), tipo de ejercicio (ran, 1=correr, 2=andar), sexo (sex, 1=hombre, 2=mujer) y peso (weight).\n\nContrastar si el pulso en reposo está por debajo de \\(75\\) pulsaciones.\n¿Qué tamaño muestral sería necesario para detectar una diferencia de 2 pulsaciones más en la media de las pulsaciones en reposo, con un nivel de significación \\(0.05\\) y una potencia de \\(0.9\\)?\nContrastar si el pulso después de correr está por encima de \\(85\\) pulsaciones.\nContrastar si el porcentaje de personas con taquicardia leve (número de pulsaciones en reposo por encima de \\(90\\)) supera el \\(5\\%\\).\n¿Se puede afirmar que el ejercicio aumenta las pulsaciones con una significación de \\(0.05\\)? ¿y con una significación \\(0.01\\)?\n¿Existe una diferencia significativa entre las medias de las pulsaciones después de andar y después de correr?\n¿Existe una diferencia significativa entre la media de las pulsaciones en reposo de hombres y mujeres? ¿Y entre las medias de las pulsaciones después de correr?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Intervalos de confianza para la comparación de medias y proporciones de dos poblaciones</span>"
    ]
  }
]